{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "KurdishMTTransformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTkGRRVgdsrG",
        "outputId": "f61d3cde-d6aa-481a-c4d4-d64953beab5c"
      },
      "source": [
        "!pip install -q sudachipy sudachidict_core"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 70 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 473 kB 18.6 MB/s \n",
            "\u001b[?25h  Building wheel for sudachipy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sudachidict-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFPG6C8ReXKQ",
        "outputId": "fe0a7bcf-f054-47ec-f907-e705ce54c299"
      },
      "source": [
        "pip install torchtext==0.6.0"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 26.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.9.0+cu102)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed sentencepiece-0.1.96 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye4x02K0elYn",
        "outputId": "47faff9f-af6c-467b-b67e-3e9df7525f11"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import pandas as pd\n",
        "import copy\n",
        "from datetime import datetime\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "# from janome.tokenizer import Tokenizer\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "else:\n",
        "    device = 'cpu'\n",
        "print(f'Running on device: {device}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "W8bC9QKtdzrj",
        "outputId": "8e214e1d-692e-4a30-ebfb-f8136e90258d"
      },
      "source": [
        "df = pd.read_csv('kurd-eng-full.csv')\n",
        "df.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ku</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>بە ناوی خوای بەخشندەی میهرەبان .</td>\n",
              "      <td>in the name of allah , most benevolent , ever-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>‌سوپاس و ستایش هەر شایستەی خوایە و بۆ خوایە، ک...</td>\n",
              "      <td>all praise be to allah , lord of all the worlds ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>بەخشندەی میهرەبان‌، کانگای ڕەحمەت و میهرەبانیە .</td>\n",
              "      <td>most beneficent , ever-merciful ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>خاوەن و سەرداری ڕۆژی پاداشت و سزایە .</td>\n",
              "      <td>king of the day of judgement .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>خوایە، تەنها هەر تۆ دەپەرستین و هەر لەتۆش داوا...</td>\n",
              "      <td>you alone we worship , and to you alone turn f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                                 en\n",
              "0           0  ...  in the name of allah , most benevolent , ever-...\n",
              "1           1  ...  all praise be to allah , lord of all the worlds ,\n",
              "2           2  ...                  most beneficent , ever-merciful ,\n",
              "3           3  ...                     king of the day of judgement .\n",
              "4           4  ...  you alone we worship , and to you alone turn f...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbeCkV8Rerie"
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "EPOCHS = 70\n",
        "\n",
        "D_MODEL = 512\n",
        "HEADS = 8\n",
        "N = 6"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA5_TXVdd7eC"
      },
      "source": [
        "#Tokenization using Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXdm8UWZeaH2"
      },
      "source": [
        "JA = spacy.blank('fa')\n",
        "EN = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1x7rArejjc"
      },
      "source": [
        "def tokenize_ku(sentence):\n",
        "    return [tok.text for tok in JA.tokenizer(str(sentence))]\n",
        "\n",
        "def tokenize_en(sentence):\n",
        "    return [tok.text for tok in EN.tokenizer(str(sentence))]"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXjYrUX_eC_Y"
      },
      "source": [
        "#Creating Field Datatorch text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_MZWjQAe4jk"
      },
      "source": [
        "JA_TEXT = Field(tokenize=tokenize_ku) \n",
        "EN_TEXT = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmmEQvPLeK2u"
      },
      "source": [
        "#Splitting the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFnw3To0e8AQ"
      },
      "source": [
        "train, val, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
        "train.to_csv('train.csv', index=False)\n",
        "val.to_csv('val.csv', index=False) \n",
        "test.to_csv('test.csv', index=False)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKOiC8UafEs5"
      },
      "source": [
        "data_fields = [('ku', JA_TEXT), ('en', EN_TEXT)]\n",
        "\n",
        "train, val, test = TabularDataset.splits(path='./',\n",
        "                        train='train.csv', \n",
        "                        validation='val.csv',\n",
        "                        test = 'test.csv',\n",
        "                        format='csv',\n",
        "              \n",
        "                        fields = data_fields )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKA30jD0eRcK"
      },
      "source": [
        "#Creating Vocabulary dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuSODroAfLWT"
      },
      "source": [
        "\n",
        "JA_TEXT.build_vocab(train, val) \n",
        "EN_TEXT.build_vocab(train, val)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyo5YjoHfPQf"
      },
      "source": [
        "train_iter = BucketIterator(\n",
        "    train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.en),\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHT9-eFMfT6E",
        "outputId": "afcb3179-97d4-4371-abae-98f51cdc7928"
      },
      "source": [
        "batch = next(iter(train_iter)) \n",
        "print(batch.en)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  14,    7,   19,  ...,   16,  319,   25],\n",
            "        [2413,  274,   12,  ...,   23,  175, 4184],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ChYK1i9fWlk"
      },
      "source": [
        "global max_src_in_batch, max_tgt_in_batch\n",
        "\n",
        "def batch_size_fn(new, count, sofar):\n",
        "    global max_src_in_batch, max_tgt_in_batch\n",
        "    if count == 1:\n",
        "        max_src_in_batch = 0\n",
        "        max_tgt_in_batch = 0\n",
        "    max_src_in_batch = max(max_src_in_batch,  len(new.ku))\n",
        "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.en) + 2)\n",
        "    src_elements = count * max_src_in_batch\n",
        "    tgt_elements = count * max_tgt_in_batch\n",
        "    return max(src_elements, tgt_elements)\n",
        "\n",
        "class MyIterator(data.Iterator):\n",
        "    def create_batches(self):\n",
        "        if self.train:\n",
        "            def pool(d, random_shuffler):\n",
        "                for p in data.batch(d, self.batch_size * 100):\n",
        "                    p_batch = data.batch(\n",
        "                        sorted(p, key=self.sort_key),\n",
        "                        self.batch_size, self.batch_size_fn)\n",
        "                    for b in random_shuffler(list(p_batch)):\n",
        "                        yield b\n",
        "            self.batches = pool(self.data(), self.random_shuffler)\n",
        "            \n",
        "        else:\n",
        "            self.batches = []\n",
        "            for b in data.batch(self.data(), self.batch_size,\n",
        "                                          self.batch_size_fn):\n",
        "                self.batches.append(sorted(b, key=self.sort_key))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wb_FkgmfkXO",
        "outputId": "45d19286-3850-46fb-cbee-7a5a84a6cd35"
      },
      "source": [
        "train_iter = MyIterator(\n",
        "    train,\n",
        "    batch_size=3000,\n",
        "    device=0,\n",
        "    repeat=False,\n",
        "    sort_key=lambda x: (len(x.ku), len(x.en)),\n",
        "    batch_size_fn=batch_size_fn,\n",
        "    train=True,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aadtCa9-fq6q"
      },
      "source": [
        "class Embedder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super(Embedder, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.embed(x)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4viCWaAemJs"
      },
      "source": [
        "# create constant 'pe' matrix with values dependant on pos and i"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdaIHVeKfyY_"
      },
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_len = 512):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = \\\n",
        "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                pe[pos, i + 1] = \\\n",
        "                math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
        "                \n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x * math.sqrt(self.d_model)\n",
        "        seq_len = x.size(1)\n",
        "        x = x + torch.autograd.Variable(self.pe[:,:seq_len], \\\n",
        "        requires_grad=False).to(device)\n",
        "        return x"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY3dFUife0ec"
      },
      "source": [
        "# creates mask with 0s wherever there is padding in the input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laYwscU5f2vR"
      },
      "source": [
        "def create_masks(input_seq, target_seq):\n",
        "\n",
        "    input_pad = JA_TEXT.vocab.stoi['<pad>']\n",
        "    input_msk = (input_seq != input_pad).unsqueeze(1)\n",
        "    \n",
        "    target_pad = EN_TEXT.vocab.stoi['<pad>']\n",
        "    target_msk = (target_seq != target_pad).unsqueeze(1)\n",
        "    size = target_seq.size(1) # get seq_len for matrix\n",
        "    nopeak_mask = np.triu(np.ones((1, size, size)), k=1).astype(np.uint8)\n",
        "    nopeak_mask = torch.autograd.Variable(torch.from_numpy(nopeak_mask) == 0).to(device)\n",
        "    target_msk = target_msk & nopeak_mask\n",
        "    return input_msk, target_msk"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJabIz4ef6jc"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, heads, d_model, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.d_k = d_model // heads\n",
        "        self.h = heads\n",
        "        \n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "    \n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        bs = q.size(0)\n",
        "        \n",
        "        \n",
        "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
        "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
        "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
        "\n",
        "       \n",
        "        k = k.transpose(1,2)\n",
        "        q = q.transpose(1,2)\n",
        "        v = v.transpose(1,2)\n",
        "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
        "        \n",
        "        concat = scores.transpose(1,2).contiguous()\\\n",
        "        .view(bs, -1, self.d_model)\n",
        "        \n",
        "        output = self.out(concat)\n",
        "    \n",
        "        return output"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00V_e3OTgAvE"
      },
      "source": [
        "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
        "\n",
        "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
        "\n",
        "    if mask is not None:\n",
        "        mask = mask.unsqueeze(1)\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    scores = F.softmax(scores, dim=-1)\n",
        "\n",
        "    if dropout is not None:\n",
        "        scores = dropout(scores)\n",
        "\n",
        "    output = torch.matmul(scores, v)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYN7l0IXgDqG"
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
        "\n",
        "        super().__init__() \n",
        "\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model) \n",
        "    def forward(self, x):\n",
        "        x = self.dropout(F.relu(self.linear_1(x)))\n",
        "        x = self.linear_2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbDK60vKgHKE"
      },
      "source": [
        "class Norm(nn.Module):\n",
        "    def __init__(self, d_model, eps = 1e-6):\n",
        "\n",
        "        super().__init__()\n",
        "    \n",
        "        self.size = d_model\n",
        "        # create two learnable parameters to calibrate normalisation\n",
        "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
        "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
        "        self.eps = eps\n",
        "    def forward(self, x):\n",
        "\n",
        "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
        "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
        "\n",
        "        return norm"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOEUpsl7gJ57"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout = 0.1):\n",
        "\n",
        "        super().__init__()\n",
        "        self.norm_1 = Norm(d_model)\n",
        "        self.norm_2 = Norm(d_model)\n",
        "        self.attn = MultiHeadAttention(heads, d_model)\n",
        "        self.ff = FeedForward(d_model)\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x, mask):\n",
        " \n",
        "        x2 = self.norm_1(x)\n",
        "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
        "        x2 = self.norm_2(x)\n",
        "        x = x + self.dropout_2(self.ff(x2))\n",
        "\n",
        "        return x"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCEtuQ2vgPeS"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "        self.norm_1 = Norm(d_model)\n",
        "        self.norm_2 = Norm(d_model)\n",
        "        self.norm_3 = Norm(d_model)\n",
        "        \n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "        self.dropout_3 = nn.Dropout(dropout)\n",
        "        \n",
        "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
        "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
        "        self.ff = FeedForward(d_model).to(device)\n",
        "\n",
        "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
        "\n",
        "            x2 = self.norm_1(x)\n",
        "            x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
        "            x2 = self.norm_2(x)\n",
        "            x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs,\n",
        "            src_mask))\n",
        "            x2 = self.norm_3(x)\n",
        "            x = x + self.dropout_3(self.ff(x2))\n",
        "\n",
        "            return x"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBehpsKlgS8i"
      },
      "source": [
        "def get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqrhI-d4gWOE"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, heads):\n",
        "\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
        "        self.norm = Norm(d_model)\n",
        "    def forward(self, src, mask):\n",
        "\n",
        "        x = self.embed(src)\n",
        "        x = self.pe(x)\n",
        "        for i in range(N):\n",
        "            x = self.layers[i](x, mask)\n",
        "        return self.norm(x)\n",
        "    \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, heads):\n",
        "\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model)\n",
        "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
        "        self.norm = Norm(d_model)\n",
        "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
        "\n",
        "        x = self.embed(trg)\n",
        "        x = self.pe(x)\n",
        "        for i in range(self.N):\n",
        "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
        "        return self.norm(x)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBTQuThqgZrt"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
        "\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
        "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
        "        self.out = nn.Linear(d_model, trg_vocab)\n",
        "    def forward(self, src, trg, src_mask, trg_mask):\n",
        "\n",
        "        e_outputs = self.encoder(src, src_mask)\n",
        "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
        "        output = self.out(d_output)\n",
        "        return output"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AML9IeCygdEO"
      },
      "source": [
        "src_vocab = len(JA_TEXT.vocab)\n",
        "trg_vocab = len(EN_TEXT.vocab)\n",
        "\n",
        "model = Transformer(src_vocab, trg_vocab, D_MODEL, N, HEADS)\n",
        "\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFZ0788wggnR"
      },
      "source": [
        "input_pad = JA_TEXT.vocab.stoi['<pad>']\n",
        "target_pad = EN_TEXT.vocab.stoi['<pad>']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_z0F_Ejgjjq",
        "outputId": "668cd3b3-3152-481c-a408-4448d6e65112"
      },
      "source": [
        "MultiHeadAttention(HEADS, D_MODEL)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiHeadAttention(\n",
              "  (q_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (v_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (k_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (out): Linear(in_features=512, out_features=512, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAxZy5scgmNc",
        "outputId": "03ddf6e8-a703-4bac-e401-f91b6471f206"
      },
      "source": [
        "iters = []\n",
        "for epoch in range(1):\n",
        "  for i, batch in enumerate(train_iter):\n",
        "    iters.append(i+1)\n",
        "len(iters)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lne6F-Pkg1zu"
      },
      "source": [
        "def train_model(model, epochs, print_every=50):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    start = datetime.now()\n",
        "    temp = start\n",
        "    \n",
        "    total_loss = 0\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "       \n",
        "        for i, batch in enumerate(train_iter):\n",
        "            src = batch.ku.transpose(0, 1)\n",
        "            trg = batch.en.transpose(0, 1)\n",
        "            # the Kurdish sentence we input has all words except\n",
        "            # the last, as it is using each word to predict the next\n",
        "            \n",
        "            trg_input = trg[:, :-1]\n",
        "            \n",
        "            # the words we are trying to predict\n",
        "            \n",
        "            targets = trg[:, 1:].contiguous().view(-1)\n",
        "            \n",
        "            # create function to make masks using mask code above\n",
        "            \n",
        "            src_mask, trg_mask = create_masks(src, trg_input)\n",
        "            \n",
        "            preds = model(src, trg_input, src_mask, trg_mask)\n",
        "            \n",
        "            optim.zero_grad()\n",
        "            \n",
        "            loss = F.cross_entropy(\n",
        "                preds.view(-1, preds.size(-1)),\n",
        "                targets,\n",
        "                ignore_index=target_pad\n",
        "            )\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            Loss_hist = []\n",
        "            Perplexity_hist = []\n",
        "            if (i + 1) % print_every == 0:\n",
        "                loss_avg = total_loss / print_every\n",
        "                perplexity  = math.exp(loss_avg)\n",
        "                print(\"time = {}, epoch {}, iter = {}, loss = {}, perplexity = {}, {} per {} iters\".format(\n",
        "                    (datetime.now() - start) // 60,\n",
        "                    epoch + 1,\n",
        "                    i + 1,\n",
        "                    loss_avg,\n",
        "                    perplexity,\n",
        "                    datetime.now() - temp,\n",
        "                    print_every\n",
        "                ))\n",
        "                if i+1 == 450:\n",
        "                    Loss_hist.append(loss_avg)\n",
        "                    Perplexity_hist.append(perplexity)\n",
        "                total_loss = 0\n",
        "                temp = datetime.now()\n",
        "    \n",
        "        print()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXjRalI9g_Kj",
        "outputId": "3457d8d2-d575-4638-e38f-f551af0d8544"
      },
      "source": [
        "model.to(device)\n",
        "train_model(model, EPOCHS)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time = 0:00:00.227568, epoch 1, iter = 50, loss = 9.119859247207641, perplexity = 9134.915761031612, 0:00:13.654142 per 50 iters\n",
            "time = 0:00:00.446801, epoch 1, iter = 100, loss = 6.936057500839233, perplexity = 1028.706535045561, 0:00:13.153775 per 50 iters\n",
            "time = 0:00:00.671047, epoch 1, iter = 150, loss = 6.374636135101318, perplexity = 586.7718864003892, 0:00:13.454571 per 50 iters\n",
            "time = 0:00:00.889265, epoch 1, iter = 200, loss = 6.363563547134399, perplexity = 580.3106404422775, 0:00:13.092934 per 50 iters\n",
            "time = 0:00:01.103558, epoch 1, iter = 250, loss = 6.178848066329956, perplexity = 482.4359019862641, 0:00:12.857426 per 50 iters\n",
            "time = 0:00:01.318293, epoch 1, iter = 300, loss = 6.0575751781463625, perplexity = 427.3379610937259, 0:00:12.884011 per 50 iters\n",
            "time = 0:00:01.537996, epoch 1, iter = 350, loss = 5.920366582870483, perplexity = 372.54825865721625, 0:00:13.182025 per 50 iters\n",
            "time = 0:00:01.755900, epoch 1, iter = 400, loss = 5.852427549362183, perplexity = 348.07833303138347, 0:00:13.074069 per 50 iters\n",
            "time = 0:00:01.971600, epoch 1, iter = 450, loss = 5.6878565979003906, perplexity = 295.26008084055997, 0:00:12.941836 per 50 iters\n",
            "time = 0:00:02.188380, epoch 1, iter = 500, loss = 5.644430809020996, perplexity = 282.7125929601446, 0:00:13.006635 per 50 iters\n",
            "time = 0:00:02.404266, epoch 1, iter = 550, loss = 5.514490232467652, perplexity = 248.26338836990436, 0:00:12.952955 per 50 iters\n",
            "time = 0:00:02.623015, epoch 1, iter = 600, loss = 5.4814002895355225, perplexity = 240.18279746552244, 0:00:13.124797 per 50 iters\n",
            "time = 0:00:02.841931, epoch 1, iter = 650, loss = 5.4039208030700685, perplexity = 222.27621119374842, 0:00:13.134807 per 50 iters\n",
            "time = 0:00:03.059240, epoch 1, iter = 700, loss = 5.370706148147583, perplexity = 215.01464630313046, 0:00:13.038353 per 50 iters\n",
            "time = 0:00:03.276141, epoch 1, iter = 750, loss = 5.25528037071228, perplexity = 191.57519039802187, 0:00:13.013896 per 50 iters\n",
            "time = 0:00:03.493115, epoch 1, iter = 800, loss = 5.280351877212524, perplexity = 196.43898559460763, 0:00:13.018235 per 50 iters\n",
            "time = 0:00:03.708534, epoch 1, iter = 850, loss = 5.221605005264283, perplexity = 185.23124273625407, 0:00:12.924959 per 50 iters\n",
            "time = 0:00:03.926704, epoch 1, iter = 900, loss = 5.160305557250976, perplexity = 174.21768094866394, 0:00:13.090065 per 50 iters\n",
            "time = 0:00:04.144005, epoch 1, iter = 950, loss = 5.204202585220337, perplexity = 182.0356569545761, 0:00:13.037913 per 50 iters\n",
            "time = 0:00:04.361322, epoch 1, iter = 1000, loss = 5.056958217620849, perplexity = 157.11188857745458, 0:00:13.038792 per 50 iters\n",
            "\n",
            "time = 0:00:04.607296, epoch 2, iter = 50, loss = 5.354707946777344, perplexity = 211.60216823254973, 0:00:14.758226 per 50 iters\n",
            "time = 0:00:04.826882, epoch 2, iter = 100, loss = 5.024417057037353, perplexity = 152.08157538315942, 0:00:13.175008 per 50 iters\n",
            "time = 0:00:05.043318, epoch 2, iter = 150, loss = 5.001983652114868, perplexity = 148.70785136633936, 0:00:12.985919 per 50 iters\n",
            "time = 0:00:05.261389, epoch 2, iter = 200, loss = 4.9158604717254635, perplexity = 136.4366591949409, 0:00:13.084162 per 50 iters\n",
            "time = 0:00:05.474358, epoch 2, iter = 250, loss = 4.887725448608398, perplexity = 132.6515079770411, 0:00:12.777970 per 50 iters\n",
            "time = 0:00:05.687532, epoch 2, iter = 300, loss = 4.911507034301758, perplexity = 135.8439817649438, 0:00:12.790209 per 50 iters\n",
            "time = 0:00:05.906859, epoch 2, iter = 350, loss = 4.835685548782348, perplexity = 125.92488127174956, 0:00:13.159473 per 50 iters\n",
            "time = 0:00:06.122196, epoch 2, iter = 400, loss = 4.935136785507202, perplexity = 139.09216702352563, 0:00:12.920031 per 50 iters\n",
            "time = 0:00:06.339834, epoch 2, iter = 450, loss = 4.942607507705689, perplexity = 140.13517713171956, 0:00:13.058103 per 50 iters\n",
            "time = 0:00:06.558633, epoch 2, iter = 500, loss = 4.8727038383483885, perplexity = 130.67376039008286, 0:00:13.126890 per 50 iters\n",
            "time = 0:00:06.777318, epoch 2, iter = 550, loss = 4.852604646682739, perplexity = 128.07354211231853, 0:00:13.120964 per 50 iters\n",
            "time = 0:00:06.994800, epoch 2, iter = 600, loss = 4.8759520053863525, perplexity = 131.09890068085826, 0:00:13.048767 per 50 iters\n",
            "time = 0:00:07.212518, epoch 2, iter = 650, loss = 4.811505250930786, perplexity = 122.9164985100048, 0:00:13.062887 per 50 iters\n",
            "time = 0:00:07.427356, epoch 2, iter = 700, loss = 4.956401052474976, perplexity = 142.08153066892208, 0:00:12.890065 per 50 iters\n",
            "time = 0:00:07.644767, epoch 2, iter = 750, loss = 4.788401174545288, perplexity = 120.10918145060357, 0:00:13.044472 per 50 iters\n",
            "time = 0:00:07.862103, epoch 2, iter = 800, loss = 4.7519911098480225, perplexity = 115.81465480454142, 0:00:13.039982 per 50 iters\n",
            "time = 0:00:08.077969, epoch 2, iter = 850, loss = 4.809335050582885, perplexity = 122.65003432708897, 0:00:12.951779 per 50 iters\n",
            "time = 0:00:08.293629, epoch 2, iter = 900, loss = 4.872545433044434, perplexity = 130.6530626127115, 0:00:12.939449 per 50 iters\n",
            "time = 0:00:08.515460, epoch 2, iter = 950, loss = 4.682670612335205, perplexity = 108.05826931617736, 0:00:13.309715 per 50 iters\n",
            "time = 0:00:08.732317, epoch 2, iter = 1000, loss = 4.714670209884644, perplexity = 111.57200975970113, 0:00:13.011229 per 50 iters\n",
            "\n",
            "time = 0:00:08.982058, epoch 3, iter = 50, loss = 4.89674674987793, perplexity = 133.8536113098796, 0:00:14.984293 per 50 iters\n",
            "time = 0:00:09.196265, epoch 3, iter = 100, loss = 4.545280771255493, perplexity = 94.1868684625704, 0:00:12.852249 per 50 iters\n",
            "time = 0:00:09.411741, epoch 3, iter = 150, loss = 4.597547883987427, perplexity = 99.24066740750236, 0:00:12.928390 per 50 iters\n",
            "time = 0:00:09.629970, epoch 3, iter = 200, loss = 4.565220928192138, perplexity = 96.08381929630183, 0:00:13.093644 per 50 iters\n",
            "time = 0:00:09.847718, epoch 3, iter = 250, loss = 4.598242492675781, perplexity = 99.30962478374546, 0:00:13.064683 per 50 iters\n",
            "time = 0:00:10.064908, epoch 3, iter = 300, loss = 4.5276523685455325, perplexity = 92.54105358006801, 0:00:13.031171 per 50 iters\n",
            "time = 0:00:10.283665, epoch 3, iter = 350, loss = 4.484342212677002, perplexity = 88.61863941922405, 0:00:13.125238 per 50 iters\n",
            "time = 0:00:10.503887, epoch 3, iter = 400, loss = 4.43388295173645, perplexity = 84.25795210122395, 0:00:13.213145 per 50 iters\n",
            "time = 0:00:10.719083, epoch 3, iter = 450, loss = 4.489737801551819, perplexity = 89.0980814370436, 0:00:12.911515 per 50 iters\n",
            "time = 0:00:10.937689, epoch 3, iter = 500, loss = 4.483326330184936, perplexity = 88.52865900746828, 0:00:13.116196 per 50 iters\n",
            "time = 0:00:11.152116, epoch 3, iter = 550, loss = 4.588976421356201, perplexity = 98.39366494605869, 0:00:12.865400 per 50 iters\n",
            "time = 0:00:11.371336, epoch 3, iter = 600, loss = 4.435481996536255, perplexity = 84.39279212025767, 0:00:13.153085 per 50 iters\n",
            "time = 0:00:11.585946, epoch 3, iter = 650, loss = 4.49224974155426, perplexity = 89.32217180489444, 0:00:12.876421 per 50 iters\n",
            "time = 0:00:11.805949, epoch 3, iter = 700, loss = 4.493411064147949, perplexity = 89.42596391752647, 0:00:13.200048 per 50 iters\n",
            "time = 0:00:12.021768, epoch 3, iter = 750, loss = 4.46625786781311, perplexity = 87.0304334985268, 0:00:12.949025 per 50 iters\n",
            "time = 0:00:12.240240, epoch 3, iter = 800, loss = 4.354202671051025, perplexity = 77.80476460751814, 0:00:13.107535 per 50 iters\n",
            "time = 0:00:12.460312, epoch 3, iter = 850, loss = 4.318157835006714, perplexity = 75.05024593379252, 0:00:13.204147 per 50 iters\n",
            "time = 0:00:12.674182, epoch 3, iter = 900, loss = 4.43770733833313, perplexity = 84.58080404572739, 0:00:12.831990 per 50 iters\n",
            "time = 0:00:12.889852, epoch 3, iter = 950, loss = 4.345629014968872, perplexity = 77.14054477916696, 0:00:12.940117 per 50 iters\n",
            "time = 0:00:13.106088, epoch 3, iter = 1000, loss = 4.425512766838073, perplexity = 83.55564080101999, 0:00:12.973991 per 50 iters\n",
            "\n",
            "time = 0:00:13.352821, epoch 4, iter = 50, loss = 4.551326518058777, perplexity = 94.75802321029309, 0:00:14.803828 per 50 iters\n",
            "time = 0:00:13.569329, epoch 4, iter = 100, loss = 4.225488286018372, perplexity = 68.40789801501604, 0:00:12.989508 per 50 iters\n",
            "time = 0:00:13.784936, epoch 4, iter = 150, loss = 4.260794291496277, perplexity = 70.8662495648742, 0:00:12.936257 per 50 iters\n",
            "time = 0:00:14.001830, epoch 4, iter = 200, loss = 4.217052488327027, perplexity = 67.83325004168148, 0:00:13.013440 per 50 iters\n",
            "time = 0:00:14.218927, epoch 4, iter = 250, loss = 4.184863090515137, perplexity = 65.68450746902651, 0:00:13.025693 per 50 iters\n",
            "time = 0:00:14.436881, epoch 4, iter = 300, loss = 4.137870707511902, perplexity = 62.66923814269502, 0:00:13.077073 per 50 iters\n",
            "time = 0:00:14.657225, epoch 4, iter = 350, loss = 4.119441776275635, perplexity = 61.52488802451056, 0:00:13.220434 per 50 iters\n",
            "time = 0:00:14.877102, epoch 4, iter = 400, loss = 4.253280520439148, perplexity = 70.3357722283453, 0:00:13.192413 per 50 iters\n",
            "time = 0:00:15.092711, epoch 4, iter = 450, loss = 4.227751469612121, perplexity = 68.56289297235176, 0:00:12.936367 per 50 iters\n",
            "time = 0:00:15.311571, epoch 4, iter = 500, loss = 4.125486135482788, perplexity = 61.897892699410406, 0:00:13.131497 per 50 iters\n",
            "time = 0:00:15.526598, epoch 4, iter = 550, loss = 4.124034686088562, perplexity = 61.80811620932509, 0:00:12.901447 per 50 iters\n",
            "time = 0:00:15.741132, epoch 4, iter = 600, loss = 4.102288126945496, perplexity = 60.47851191239592, 0:00:12.871903 per 50 iters\n",
            "time = 0:00:15.955947, epoch 4, iter = 650, loss = 4.121152896881103, perplexity = 61.6302546499515, 0:00:12.888682 per 50 iters\n",
            "time = 0:00:16.174028, epoch 4, iter = 700, loss = 4.063038296699524, perplexity = 58.15072209576496, 0:00:13.083976 per 50 iters\n",
            "time = 0:00:16.392484, epoch 4, iter = 750, loss = 3.9774807024002077, perplexity = 53.38237858165655, 0:00:13.106343 per 50 iters\n",
            "time = 0:00:16.607262, epoch 4, iter = 800, loss = 4.1228542184829715, perplexity = 61.73519677835825, 0:00:12.885936 per 50 iters\n",
            "time = 0:00:16.823579, epoch 4, iter = 850, loss = 4.105697178840638, perplexity = 60.68503812732413, 0:00:12.978881 per 50 iters\n",
            "time = 0:00:17.041735, epoch 4, iter = 900, loss = 4.148533186912537, perplexity = 63.341022683357394, 0:00:13.089157 per 50 iters\n",
            "time = 0:00:17.259581, epoch 4, iter = 950, loss = 4.091779508590698, perplexity = 59.846293998460276, 0:00:13.070593 per 50 iters\n",
            "time = 0:00:17.473689, epoch 4, iter = 1000, loss = 4.079693512916565, perplexity = 59.12734530494092, 0:00:12.846328 per 50 iters\n",
            "\n",
            "time = 0:00:17.718816, epoch 5, iter = 50, loss = 4.166622858047486, perplexity = 64.49726746673478, 0:00:14.707422 per 50 iters\n",
            "time = 0:00:17.933876, epoch 5, iter = 100, loss = 3.8604066133499146, perplexity = 47.484655338738456, 0:00:12.903444 per 50 iters\n",
            "time = 0:00:18.147763, epoch 5, iter = 150, loss = 3.916193714141846, perplexity = 50.208970911167675, 0:00:12.833011 per 50 iters\n",
            "time = 0:00:18.361303, epoch 5, iter = 200, loss = 4.02748429775238, perplexity = 56.1195534278937, 0:00:12.812282 per 50 iters\n",
            "time = 0:00:18.582813, epoch 5, iter = 250, loss = 3.7654097032547, perplexity = 43.181393793790335, 0:00:13.290320 per 50 iters\n",
            "time = 0:00:18.800296, epoch 5, iter = 300, loss = 3.843789463043213, perplexity = 46.70211548171604, 0:00:13.048736 per 50 iters\n",
            "time = 0:00:19.017795, epoch 5, iter = 350, loss = 3.8577466011047363, perplexity = 47.35851341798441, 0:00:13.049774 per 50 iters\n",
            "time = 0:00:19.237105, epoch 5, iter = 400, loss = 3.825723648071289, perplexity = 45.86597918736737, 0:00:13.157598 per 50 iters\n",
            "time = 0:00:19.455306, epoch 5, iter = 450, loss = 3.8168946504592896, perplexity = 45.46281097120935, 0:00:13.091944 per 50 iters\n",
            "time = 0:00:19.675295, epoch 5, iter = 500, loss = 3.7343085527420046, perplexity = 41.85907221369485, 0:00:13.199177 per 50 iters\n",
            "time = 0:00:19.892758, epoch 5, iter = 550, loss = 3.7380155658721925, perplexity = 42.01453231229488, 0:00:13.047628 per 50 iters\n",
            "time = 0:00:20.109694, epoch 5, iter = 600, loss = 3.866519865989685, perplexity = 47.77583013908364, 0:00:13.015995 per 50 iters\n",
            "time = 0:00:20.328776, epoch 5, iter = 650, loss = 3.764969539642334, perplexity = 43.162391097965504, 0:00:13.144701 per 50 iters\n",
            "time = 0:00:20.541998, epoch 5, iter = 700, loss = 3.8489252662658693, perplexity = 46.942585331264034, 0:00:12.793198 per 50 iters\n",
            "time = 0:00:20.756737, epoch 5, iter = 750, loss = 3.7613983011245726, perplexity = 43.00852281805473, 0:00:12.884182 per 50 iters\n",
            "time = 0:00:20.971011, epoch 5, iter = 800, loss = 3.882219099998474, perplexity = 48.53179256539829, 0:00:12.855207 per 50 iters\n",
            "time = 0:00:21.188849, epoch 5, iter = 850, loss = 3.823315210342407, perplexity = 45.75564675035501, 0:00:13.070190 per 50 iters\n",
            "time = 0:00:21.406164, epoch 5, iter = 900, loss = 3.813097400665283, perplexity = 45.290504673682214, 0:00:13.038711 per 50 iters\n",
            "time = 0:00:21.624985, epoch 5, iter = 950, loss = 3.8053169870376586, perplexity = 44.93949309226346, 0:00:13.128314 per 50 iters\n",
            "time = 0:00:21.843140, epoch 5, iter = 1000, loss = 3.860195813179016, perplexity = 47.47464662023484, 0:00:13.089131 per 50 iters\n",
            "\n",
            "time = 0:00:22.088080, epoch 6, iter = 50, loss = 3.8692752933502197, perplexity = 47.907654501443496, 0:00:14.696279 per 50 iters\n",
            "time = 0:00:22.308040, epoch 6, iter = 100, loss = 3.572435851097107, perplexity = 35.60321173618114, 0:00:13.197402 per 50 iters\n",
            "time = 0:00:22.521968, epoch 6, iter = 150, loss = 3.5632714653015136, perplexity = 35.27842069661761, 0:00:12.835604 per 50 iters\n",
            "time = 0:00:22.741612, epoch 6, iter = 200, loss = 3.5749515390396116, perplexity = 35.69289106196355, 0:00:13.178453 per 50 iters\n",
            "time = 0:00:22.957031, epoch 6, iter = 250, loss = 3.626968221664429, perplexity = 37.59865286383184, 0:00:12.924980 per 50 iters\n",
            "time = 0:00:23.172969, epoch 6, iter = 300, loss = 3.6866582250595092, perplexity = 39.91124944197218, 0:00:12.956106 per 50 iters\n",
            "time = 0:00:23.392564, epoch 6, iter = 350, loss = 3.5765513467788694, perplexity = 35.750038525609746, 0:00:13.175553 per 50 iters\n",
            "time = 0:00:23.610457, epoch 6, iter = 400, loss = 3.5084352493286133, perplexity = 33.39597051124013, 0:00:13.073442 per 50 iters\n",
            "time = 0:00:23.827757, epoch 6, iter = 450, loss = 3.5293620824813843, perplexity = 34.10220627971462, 0:00:13.037864 per 50 iters\n",
            "time = 0:00:24.043283, epoch 6, iter = 500, loss = 3.5293668603897093, perplexity = 34.10236921731916, 0:00:12.931387 per 50 iters\n",
            "time = 0:00:24.261450, epoch 6, iter = 550, loss = 3.527785177230835, perplexity = 34.04847270908628, 0:00:13.089862 per 50 iters\n",
            "time = 0:00:24.480540, epoch 6, iter = 600, loss = 3.590519027709961, perplexity = 36.25288729731621, 0:00:13.145247 per 50 iters\n",
            "time = 0:00:24.695470, epoch 6, iter = 650, loss = 3.5416485023498536, perplexity = 34.5237848468415, 0:00:12.895637 per 50 iters\n",
            "time = 0:00:24.909514, epoch 6, iter = 700, loss = 3.5163754510879515, perplexity = 33.662196801552724, 0:00:12.842463 per 50 iters\n",
            "time = 0:00:25.127226, epoch 6, iter = 750, loss = 3.5059135723114014, perplexity = 33.31186275080676, 0:00:13.062564 per 50 iters\n",
            "time = 0:00:25.347013, epoch 6, iter = 800, loss = 3.482678337097168, perplexity = 32.546776682414006, 0:00:13.186942 per 50 iters\n",
            "time = 0:00:25.564859, epoch 6, iter = 850, loss = 3.505298867225647, perplexity = 33.29139207171775, 0:00:13.070627 per 50 iters\n",
            "time = 0:00:25.778284, epoch 6, iter = 900, loss = 3.517479782104492, perplexity = 33.69939154343907, 0:00:12.805278 per 50 iters\n",
            "time = 0:00:25.994881, epoch 6, iter = 950, loss = 3.672218050956726, perplexity = 39.339065213861524, 0:00:12.995645 per 50 iters\n",
            "time = 0:00:26.210888, epoch 6, iter = 1000, loss = 3.5651598262786863, perplexity = 35.34510202899541, 0:00:12.960293 per 50 iters\n",
            "\n",
            "time = 0:00:26.453697, epoch 7, iter = 50, loss = 3.5492396545410156, perplexity = 34.78685740041648, 0:00:14.568395 per 50 iters\n",
            "time = 0:00:26.667865, epoch 7, iter = 100, loss = 3.3495212030410766, perplexity = 28.48908988813264, 0:00:12.849941 per 50 iters\n",
            "time = 0:00:26.883739, epoch 7, iter = 150, loss = 3.2486759424209595, perplexity = 25.756214619074978, 0:00:12.952295 per 50 iters\n",
            "time = 0:00:27.101855, epoch 7, iter = 200, loss = 3.393430304527283, perplexity = 29.767890259963078, 0:00:13.086831 per 50 iters\n",
            "time = 0:00:27.319292, epoch 7, iter = 250, loss = 3.2821146774291994, perplexity = 26.632031350049708, 0:00:13.046019 per 50 iters\n",
            "time = 0:00:27.535182, epoch 7, iter = 300, loss = 3.301588053703308, perplexity = 27.15572945328637, 0:00:12.953227 per 50 iters\n",
            "time = 0:00:27.754512, epoch 7, iter = 350, loss = 3.2750483846664427, perplexity = 26.444504958160636, 0:00:13.159645 per 50 iters\n",
            "time = 0:00:27.975605, epoch 7, iter = 400, loss = 3.3146080923080445, perplexity = 27.51160985999358, 0:00:13.265423 per 50 iters\n",
            "time = 0:00:28.194405, epoch 7, iter = 450, loss = 3.2690359592437743, perplexity = 26.285986362405055, 0:00:13.127874 per 50 iters\n",
            "time = 0:00:28.409146, epoch 7, iter = 500, loss = 3.302874879837036, perplexity = 27.190696649152795, 0:00:12.884235 per 50 iters\n",
            "time = 0:00:28.623649, epoch 7, iter = 550, loss = 3.3376855850219727, perplexity = 28.153891455733707, 0:00:12.870051 per 50 iters\n",
            "time = 0:00:28.843290, epoch 7, iter = 600, loss = 3.26007625579834, perplexity = 26.051523646509793, 0:00:13.178308 per 50 iters\n",
            "time = 0:00:29.058078, epoch 7, iter = 650, loss = 3.2919150590896606, perplexity = 26.894318579819494, 0:00:12.887117 per 50 iters\n",
            "time = 0:00:29.277313, epoch 7, iter = 700, loss = 3.3335877513885497, perplexity = 28.03875755331647, 0:00:13.153948 per 50 iters\n",
            "time = 0:00:29.491470, epoch 7, iter = 750, loss = 3.3140535831451414, perplexity = 27.49635864909888, 0:00:12.849249 per 50 iters\n",
            "time = 0:00:29.708207, epoch 7, iter = 800, loss = 3.2827253913879395, perplexity = 26.648300870850843, 0:00:13.004010 per 50 iters\n",
            "time = 0:00:29.927063, epoch 7, iter = 850, loss = 3.1775849580764772, perplexity = 23.98874970316698, 0:00:13.131211 per 50 iters\n",
            "time = 0:00:30.145737, epoch 7, iter = 900, loss = 3.2837825870513915, perplexity = 26.676488236124708, 0:00:13.120209 per 50 iters\n",
            "time = 0:00:30.362457, epoch 7, iter = 950, loss = 3.226792392730713, perplexity = 25.198699668526054, 0:00:13.002980 per 50 iters\n",
            "time = 0:00:30.577398, epoch 7, iter = 1000, loss = 3.3495403814315794, perplexity = 28.489636268262913, 0:00:12.896333 per 50 iters\n",
            "\n",
            "time = 0:00:30.818631, epoch 8, iter = 50, loss = 3.410348196029663, perplexity = 30.275784332187246, 0:00:14.473861 per 50 iters\n",
            "time = 0:00:31.038216, epoch 8, iter = 100, loss = 3.112956471443176, perplexity = 22.487429662954725, 0:00:13.174997 per 50 iters\n",
            "time = 0:00:31.252454, epoch 8, iter = 150, loss = 3.0565489149093628, perplexity = 21.254080806987208, 0:00:12.854150 per 50 iters\n",
            "time = 0:00:31.468623, epoch 8, iter = 200, loss = 3.0353873491287233, perplexity = 20.80903670082573, 0:00:12.969952 per 50 iters\n",
            "time = 0:00:31.685264, epoch 8, iter = 250, loss = 3.084128427505493, perplexity = 21.848416062724777, 0:00:12.997565 per 50 iters\n",
            "time = 0:00:31.900390, epoch 8, iter = 300, loss = 2.966353344917297, perplexity = 19.42096873365199, 0:00:12.906672 per 50 iters\n",
            "time = 0:00:32.116754, epoch 8, iter = 350, loss = 3.054894070625305, perplexity = 21.218937699056486, 0:00:12.981665 per 50 iters\n",
            "time = 0:00:32.330777, epoch 8, iter = 400, loss = 3.1352144575119016, perplexity = 22.99356645636425, 0:00:12.841256 per 50 iters\n",
            "time = 0:00:32.546411, epoch 8, iter = 450, loss = 3.029329833984375, perplexity = 20.68336665424882, 0:00:12.937906 per 50 iters\n",
            "time = 0:00:32.762476, epoch 8, iter = 500, loss = 3.058094358444214, perplexity = 21.2869531834177, 0:00:12.963768 per 50 iters\n",
            "time = 0:00:32.982566, epoch 8, iter = 550, loss = 3.109489874839783, perplexity = 22.409609778671353, 0:00:13.205250 per 50 iters\n",
            "time = 0:00:33.201882, epoch 8, iter = 600, loss = 3.009104232788086, perplexity = 20.269235274436824, 0:00:13.158784 per 50 iters\n",
            "time = 0:00:33.417393, epoch 8, iter = 650, loss = 3.022717247009277, perplexity = 20.547047301825025, 0:00:12.930537 per 50 iters\n",
            "time = 0:00:33.636962, epoch 8, iter = 700, loss = 2.9914896154403685, perplexity = 19.91532658491444, 0:00:13.174007 per 50 iters\n",
            "time = 0:00:33.852678, epoch 8, iter = 750, loss = 3.0049399757385253, perplexity = 20.185004469638137, 0:00:12.942782 per 50 iters\n",
            "time = 0:00:34.070303, epoch 8, iter = 800, loss = 3.017111926078796, perplexity = 20.432196695491708, 0:00:13.057322 per 50 iters\n",
            "time = 0:00:34.290182, epoch 8, iter = 850, loss = 3.0626667833328245, perplexity = 21.384509041405597, 0:00:13.192596 per 50 iters\n",
            "time = 0:00:34.506071, epoch 8, iter = 900, loss = 3.1439007472991944, perplexity = 23.194165205992416, 0:00:12.953182 per 50 iters\n",
            "time = 0:00:34.725058, epoch 8, iter = 950, loss = 3.024345417022705, perplexity = 20.580528637363198, 0:00:13.139062 per 50 iters\n",
            "time = 0:00:34.943103, epoch 8, iter = 1000, loss = 3.0006101083755494, perplexity = 20.09779501649437, 0:00:13.082516 per 50 iters\n",
            "\n",
            "time = 0:00:35.188798, epoch 9, iter = 50, loss = 3.0909405279159547, perplexity = 21.997757754540928, 0:00:14.741596 per 50 iters\n",
            "time = 0:00:35.406837, epoch 9, iter = 100, loss = 2.8447330617904663, perplexity = 17.196967528455836, 0:00:13.082220 per 50 iters\n",
            "time = 0:00:35.625260, epoch 9, iter = 150, loss = 2.837225375175476, perplexity = 17.068341531532052, 0:00:13.105212 per 50 iters\n",
            "time = 0:00:35.845240, epoch 9, iter = 200, loss = 2.832920551300049, perplexity = 16.995023251758628, 0:00:13.198652 per 50 iters\n",
            "time = 0:00:36.056548, epoch 9, iter = 250, loss = 2.8945650959014895, perplexity = 18.075638562288603, 0:00:12.678304 per 50 iters\n",
            "time = 0:00:36.275532, epoch 9, iter = 300, loss = 2.7926361036300658, perplexity = 16.323994875676938, 0:00:13.138917 per 50 iters\n",
            "time = 0:00:36.490999, epoch 9, iter = 350, loss = 2.8163442182540894, perplexity = 16.71563014033315, 0:00:12.927876 per 50 iters\n",
            "time = 0:00:36.709074, epoch 9, iter = 400, loss = 2.9024272203445434, perplexity = 18.218311603736264, 0:00:13.084320 per 50 iters\n",
            "time = 0:00:36.927719, epoch 9, iter = 450, loss = 2.779478964805603, perplexity = 16.1106245584116, 0:00:13.118576 per 50 iters\n",
            "time = 0:00:37.144241, epoch 9, iter = 500, loss = 2.8278527069091797, perplexity = 16.909112992282502, 0:00:12.991087 per 50 iters\n",
            "time = 0:00:37.364403, epoch 9, iter = 550, loss = 2.8399440908432005, perplexity = 17.114808635876738, 0:00:13.209543 per 50 iters\n",
            "time = 0:00:37.579332, epoch 9, iter = 600, loss = 2.8115967988967894, perplexity = 16.636462104858158, 0:00:12.895556 per 50 iters\n",
            "time = 0:00:37.795865, epoch 9, iter = 650, loss = 2.814437084197998, perplexity = 16.683781572221132, 0:00:12.991863 per 50 iters\n",
            "time = 0:00:38.011719, epoch 9, iter = 700, loss = 2.8485620498657225, perplexity = 17.26294073676324, 0:00:12.951085 per 50 iters\n",
            "time = 0:00:38.228577, epoch 9, iter = 750, loss = 2.8315435695648192, perplexity = 16.9716375197092, 0:00:13.011316 per 50 iters\n",
            "time = 0:00:38.439307, epoch 9, iter = 800, loss = 2.84941605091095, perplexity = 17.277689603073373, 0:00:12.643695 per 50 iters\n",
            "time = 0:00:38.658452, epoch 9, iter = 850, loss = 2.837679834365845, perplexity = 17.076100159061667, 0:00:13.148522 per 50 iters\n",
            "time = 0:00:38.875526, epoch 9, iter = 900, loss = 2.739252848625183, perplexity = 15.475418295747, 0:00:13.024342 per 50 iters\n",
            "time = 0:00:39.092261, epoch 9, iter = 950, loss = 2.7676026010513306, perplexity = 15.920420622067217, 0:00:13.003846 per 50 iters\n",
            "time = 0:00:39.310487, epoch 9, iter = 1000, loss = 2.8967744159698485, perplexity = 18.115617580274264, 0:00:13.093381 per 50 iters\n",
            "\n",
            "time = 0:00:39.553429, epoch 10, iter = 50, loss = 2.7608142995834353, perplexity = 15.812713993523692, 0:00:14.576343 per 50 iters\n",
            "time = 0:00:39.771291, epoch 10, iter = 100, loss = 2.506795382499695, perplexity = 12.265560582050602, 0:00:13.071621 per 50 iters\n",
            "time = 0:00:39.986865, epoch 10, iter = 150, loss = 2.687191686630249, perplexity = 14.69036279524902, 0:00:12.934260 per 50 iters\n",
            "time = 0:00:40.204708, epoch 10, iter = 200, loss = 2.576967115402222, perplexity = 13.157173397489277, 0:00:13.070479 per 50 iters\n",
            "time = 0:00:40.419885, epoch 10, iter = 250, loss = 2.646224298477173, perplexity = 14.10069798268732, 0:00:12.910409 per 50 iters\n",
            "time = 0:00:40.638817, epoch 10, iter = 300, loss = 2.725597324371338, perplexity = 15.265529676975703, 0:00:13.135755 per 50 iters\n",
            "time = 0:00:40.856831, epoch 10, iter = 350, loss = 2.7286728715896604, perplexity = 15.312551806634833, 0:00:13.080743 per 50 iters\n",
            "time = 0:00:41.071342, epoch 10, iter = 400, loss = 2.6116591835021974, perplexity = 13.621632901351342, 0:00:12.869697 per 50 iters\n",
            "time = 0:00:41.288609, epoch 10, iter = 450, loss = 2.6049343156814575, perplexity = 13.530336542623713, 0:00:13.035838 per 50 iters\n",
            "time = 0:00:41.508075, epoch 10, iter = 500, loss = 2.712454986572266, perplexity = 15.066217511954706, 0:00:13.167698 per 50 iters\n",
            "time = 0:00:41.724576, epoch 10, iter = 550, loss = 2.5555489110946654, perplexity = 12.878366796144874, 0:00:12.989928 per 50 iters\n",
            "time = 0:00:41.941319, epoch 10, iter = 600, loss = 2.6336337089538575, perplexity = 13.924274848613566, 0:00:13.004344 per 50 iters\n",
            "time = 0:00:42.154418, epoch 10, iter = 650, loss = 2.658069438934326, perplexity = 14.268715864030645, 0:00:12.784955 per 50 iters\n",
            "time = 0:00:42.371704, epoch 10, iter = 700, loss = 2.588944773674011, perplexity = 13.315713096038607, 0:00:13.037004 per 50 iters\n",
            "time = 0:00:42.588678, epoch 10, iter = 750, loss = 2.580876317024231, perplexity = 13.208708105228519, 0:00:13.018297 per 50 iters\n",
            "time = 0:00:42.806352, epoch 10, iter = 800, loss = 2.746407117843628, perplexity = 15.586530594224628, 0:00:13.060259 per 50 iters\n",
            "time = 0:00:43.020390, epoch 10, iter = 850, loss = 2.6034230828285216, perplexity = 13.50990449620772, 0:00:12.842187 per 50 iters\n",
            "time = 0:00:43.239448, epoch 10, iter = 900, loss = 2.6408540391921997, perplexity = 14.025176544773894, 0:00:13.142576 per 50 iters\n",
            "time = 0:00:43.458687, epoch 10, iter = 950, loss = 2.649793815612793, perplexity = 14.151120604428783, 0:00:13.154150 per 50 iters\n",
            "time = 0:00:43.675722, epoch 10, iter = 1000, loss = 2.6012703561782837, perplexity = 13.480852646321726, 0:00:13.021903 per 50 iters\n",
            "\n",
            "time = 0:00:43.923099, epoch 11, iter = 50, loss = 2.713186922073364, perplexity = 15.077249048112956, 0:00:14.842457 per 50 iters\n",
            "time = 0:00:44.140131, epoch 11, iter = 100, loss = 2.4676087737083434, perplexity = 11.7942104791357, 0:00:13.021761 per 50 iters\n",
            "time = 0:00:44.355647, epoch 11, iter = 150, loss = 2.5057082200050353, perplexity = 12.252233170453504, 0:00:12.930836 per 50 iters\n",
            "time = 0:00:44.573455, epoch 11, iter = 200, loss = 2.508167986869812, perplexity = 12.28240790381611, 0:00:13.068310 per 50 iters\n",
            "time = 0:00:44.790606, epoch 11, iter = 250, loss = 2.367695913314819, perplexity = 10.672772938427999, 0:00:13.028954 per 50 iters\n",
            "time = 0:00:45.006877, epoch 11, iter = 300, loss = 2.343470582962036, perplexity = 10.41732809857931, 0:00:12.976067 per 50 iters\n",
            "time = 0:00:45.221440, epoch 11, iter = 350, loss = 2.413824410438538, perplexity = 11.176623509487973, 0:00:12.873568 per 50 iters\n",
            "time = 0:00:45.439055, epoch 11, iter = 400, loss = 2.394004111289978, perplexity = 10.957280391757248, 0:00:13.056713 per 50 iters\n",
            "time = 0:00:45.655507, epoch 11, iter = 450, loss = 2.4923167276382445, perplexity = 12.08925120499885, 0:00:12.986998 per 50 iters\n",
            "time = 0:00:45.873621, epoch 11, iter = 500, loss = 2.4205628395080567, perplexity = 11.252190710418942, 0:00:13.086645 per 50 iters\n",
            "time = 0:00:46.087918, epoch 11, iter = 550, loss = 2.397172691822052, perplexity = 10.992054480246917, 0:00:12.857648 per 50 iters\n",
            "time = 0:00:46.308209, epoch 11, iter = 600, loss = 2.4409846544265745, perplexity = 11.48434328678529, 0:00:13.217281 per 50 iters\n",
            "time = 0:00:46.526067, epoch 11, iter = 650, loss = 2.354860372543335, perplexity = 10.536657552284494, 0:00:13.071301 per 50 iters\n",
            "time = 0:00:46.740403, epoch 11, iter = 700, loss = 2.4385357666015626, perplexity = 11.456253826338699, 0:00:12.860035 per 50 iters\n",
            "time = 0:00:46.955910, epoch 11, iter = 750, loss = 2.525554599761963, perplexity = 12.49782463248226, 0:00:12.930135 per 50 iters\n",
            "time = 0:00:47.175746, epoch 11, iter = 800, loss = 2.5890566897392273, perplexity = 13.317203421647996, 0:00:13.190043 per 50 iters\n",
            "time = 0:00:47.390843, epoch 11, iter = 850, loss = 2.5314746737480163, perplexity = 12.572032119146233, 0:00:12.905648 per 50 iters\n",
            "time = 0:00:47.608062, epoch 11, iter = 900, loss = 2.408927330970764, perplexity = 11.122024492955337, 0:00:13.032923 per 50 iters\n",
            "time = 0:00:47.827117, epoch 11, iter = 950, loss = 2.4875370264053345, perplexity = 12.031606069117379, 0:00:13.143170 per 50 iters\n",
            "time = 0:00:48.045339, epoch 11, iter = 1000, loss = 2.469235272407532, perplexity = 11.813409356379852, 0:00:13.093083 per 50 iters\n",
            "\n",
            "time = 0:00:48.291555, epoch 12, iter = 50, loss = 2.4031050324440004, perplexity = 11.057456894451041, 0:00:14.772859 per 50 iters\n",
            "time = 0:00:48.509958, epoch 12, iter = 100, loss = 2.2562962770462036, perplexity = 9.547661706695875, 0:00:13.103911 per 50 iters\n",
            "time = 0:00:48.728282, epoch 12, iter = 150, loss = 2.359498643875122, perplexity = 10.585642944892397, 0:00:13.099291 per 50 iters\n",
            "time = 0:00:48.946383, epoch 12, iter = 200, loss = 2.2146138882637025, perplexity = 9.157872466843752, 0:00:13.085880 per 50 iters\n",
            "time = 0:00:49.164844, epoch 12, iter = 250, loss = 2.4150351786613466, perplexity = 11.190164005618627, 0:00:13.107524 per 50 iters\n",
            "time = 0:00:49.382125, epoch 12, iter = 300, loss = 2.2723527336120606, perplexity = 9.70220067619659, 0:00:13.036680 per 50 iters\n",
            "time = 0:00:49.601629, epoch 12, iter = 350, loss = 2.22156907081604, perplexity = 9.221789160114955, 0:00:13.170034 per 50 iters\n",
            "time = 0:00:49.817747, epoch 12, iter = 400, loss = 2.3263747906684875, perplexity = 10.240749299038136, 0:00:12.966921 per 50 iters\n",
            "time = 0:00:50.034043, epoch 12, iter = 450, loss = 2.2543037366867065, perplexity = 9.528656545969236, 0:00:12.977592 per 50 iters\n",
            "time = 0:00:50.250866, epoch 12, iter = 500, loss = 2.3130863738059997, perplexity = 10.105566127771873, 0:00:13.009258 per 50 iters\n",
            "time = 0:00:50.465856, epoch 12, iter = 550, loss = 2.3148403120040895, perplexity = 10.123306219180856, 0:00:12.898549 per 50 iters\n",
            "time = 0:00:50.682826, epoch 12, iter = 600, loss = 2.265262494087219, perplexity = 9.633653046207773, 0:00:13.018000 per 50 iters\n",
            "time = 0:00:50.901231, epoch 12, iter = 650, loss = 2.285621657371521, perplexity = 9.83179633328924, 0:00:13.104154 per 50 iters\n",
            "time = 0:00:51.118491, epoch 12, iter = 700, loss = 2.3412297797203063, perplexity = 10.394011050221254, 0:00:13.035439 per 50 iters\n",
            "time = 0:00:51.331718, epoch 12, iter = 750, loss = 2.3031150317192077, perplexity = 10.005300791674959, 0:00:12.793432 per 50 iters\n",
            "time = 0:00:51.548534, epoch 12, iter = 800, loss = 2.3129128003120423, perplexity = 10.103812221570875, 0:00:13.008753 per 50 iters\n",
            "time = 0:00:51.764112, epoch 12, iter = 850, loss = 2.346888802051544, perplexity = 10.452997736935927, 0:00:12.934564 per 50 iters\n",
            "time = 0:00:51.982176, epoch 12, iter = 900, loss = 2.328903253078461, perplexity = 10.266675411478685, 0:00:13.083700 per 50 iters\n",
            "time = 0:00:52.199218, epoch 12, iter = 950, loss = 2.255679950714111, perplexity = 9.541779044382185, 0:00:13.022341 per 50 iters\n",
            "time = 0:00:52.415051, epoch 12, iter = 1000, loss = 2.2903118467330934, perplexity = 9.878017628439345, 0:00:12.949794 per 50 iters\n",
            "\n",
            "time = 0:00:52.658837, epoch 13, iter = 50, loss = 2.4065558981895445, perplexity = 11.095680608200988, 0:00:14.627008 per 50 iters\n",
            "time = 0:00:52.877007, epoch 13, iter = 100, loss = 2.1582160210609436, perplexity = 8.655682321599816, 0:00:13.090043 per 50 iters\n",
            "time = 0:00:53.096230, epoch 13, iter = 150, loss = 2.0479010772705077, perplexity = 7.7516139808026345, 0:00:13.153206 per 50 iters\n",
            "time = 0:00:53.313745, epoch 13, iter = 200, loss = 2.0723286962509153, perplexity = 7.943299127891501, 0:00:13.050755 per 50 iters\n",
            "time = 0:00:53.529640, epoch 13, iter = 250, loss = 2.0862474846839905, perplexity = 8.054633248532967, 0:00:12.953548 per 50 iters\n",
            "time = 0:00:53.748745, epoch 13, iter = 300, loss = 2.0555968737602233, perplexity = 7.811498960214449, 0:00:13.146160 per 50 iters\n",
            "time = 0:00:53.968031, epoch 13, iter = 350, loss = 2.074475622177124, perplexity = 7.960371122325051, 0:00:13.157037 per 50 iters\n",
            "time = 0:00:54.181200, epoch 13, iter = 400, loss = 2.1446936321258545, perplexity = 8.539424631121863, 0:00:12.789327 per 50 iters\n",
            "time = 0:00:54.399695, epoch 13, iter = 450, loss = 2.1300656533241273, perplexity = 8.415419293554335, 0:00:13.109551 per 50 iters\n",
            "time = 0:00:54.616331, epoch 13, iter = 500, loss = 2.2303550386428834, perplexity = 9.303168477520211, 0:00:12.996787 per 50 iters\n",
            "time = 0:00:54.832294, epoch 13, iter = 550, loss = 2.2354572772979737, perplexity = 9.35075676349902, 0:00:12.957643 per 50 iters\n",
            "time = 0:00:55.048531, epoch 13, iter = 600, loss = 2.129186532497406, perplexity = 8.408024374177861, 0:00:12.974068 per 50 iters\n",
            "time = 0:00:55.262783, epoch 13, iter = 650, loss = 2.1423809504508973, perplexity = 8.519698479209914, 0:00:12.854921 per 50 iters\n",
            "time = 0:00:55.482616, epoch 13, iter = 700, loss = 2.2554090642929077, perplexity = 9.539194656058593, 0:00:13.189852 per 50 iters\n",
            "time = 0:00:55.697501, epoch 13, iter = 750, loss = 2.0533563923835754, perplexity = 7.7940170335488625, 0:00:12.892971 per 50 iters\n",
            "time = 0:00:55.914222, epoch 13, iter = 800, loss = 2.2537156915664673, perplexity = 9.523054913152784, 0:00:13.003069 per 50 iters\n",
            "time = 0:00:56.132006, epoch 13, iter = 850, loss = 2.098143675327301, perplexity = 8.151024911246374, 0:00:13.066921 per 50 iters\n",
            "time = 0:00:56.352472, epoch 13, iter = 900, loss = 2.2021498703956603, perplexity = 9.04443698027903, 0:00:13.227828 per 50 iters\n",
            "time = 0:00:56.568101, epoch 13, iter = 950, loss = 2.1359428215026854, perplexity = 8.465023752125695, 0:00:12.937534 per 50 iters\n",
            "time = 0:00:56.783527, epoch 13, iter = 1000, loss = 2.1903854703903196, perplexity = 8.938658038701105, 0:00:12.925479 per 50 iters\n",
            "\n",
            "time = 0:00:57.030294, epoch 14, iter = 50, loss = 2.124888081550598, perplexity = 8.371960458859803, 0:00:14.805868 per 50 iters\n",
            "time = 0:00:57.248667, epoch 14, iter = 100, loss = 1.967002396583557, perplexity = 7.149213828349689, 0:00:13.102170 per 50 iters\n",
            "time = 0:00:57.465301, epoch 14, iter = 150, loss = 2.001624002456665, perplexity = 7.401065693353681, 0:00:12.997882 per 50 iters\n",
            "time = 0:00:57.681145, epoch 14, iter = 200, loss = 1.9615767192840576, perplexity = 7.110529540302573, 0:00:12.950465 per 50 iters\n",
            "time = 0:00:57.897558, epoch 14, iter = 250, loss = 1.987433247566223, perplexity = 7.296780675781808, 0:00:12.984686 per 50 iters\n",
            "time = 0:00:58.115173, epoch 14, iter = 300, loss = 1.9637303638458252, perplexity = 7.125859595397926, 0:00:13.056625 per 50 iters\n",
            "time = 0:00:58.331079, epoch 14, iter = 350, loss = 2.014943053722382, perplexity = 7.500300254860917, 0:00:12.954162 per 50 iters\n",
            "time = 0:00:58.547201, epoch 14, iter = 400, loss = 1.9438631081581115, perplexity = 6.9856853700347115, 0:00:12.967099 per 50 iters\n",
            "time = 0:00:58.764589, epoch 14, iter = 450, loss = 1.993961353302002, perplexity = 7.3445706508506134, 0:00:13.042505 per 50 iters\n",
            "time = 0:00:58.981446, epoch 14, iter = 500, loss = 1.9894445443153381, perplexity = 7.311471435820573, 0:00:13.010530 per 50 iters\n",
            "time = 0:00:59.196782, epoch 14, iter = 550, loss = 2.044019167423248, perplexity = 7.721581244060812, 0:00:12.920032 per 50 iters\n",
            "time = 0:00:59.414299, epoch 14, iter = 600, loss = 1.9977673530578612, perplexity = 7.3725773478877965, 0:00:13.050898 per 50 iters\n",
            "time = 0:00:59.633544, epoch 14, iter = 650, loss = 1.9685337257385254, perplexity = 7.160170014542823, 0:00:13.154487 per 50 iters\n",
            "time = 0:00:59.851053, epoch 14, iter = 700, loss = 2.029252369403839, perplexity = 7.608395962278658, 0:00:13.050377 per 50 iters\n",
            "time = 0:01:00.066708, epoch 14, iter = 750, loss = 2.0629675936698915, perplexity = 7.869288043068777, 0:00:12.939111 per 50 iters\n",
            "time = 0:01:00.285682, epoch 14, iter = 800, loss = 1.9502032923698425, perplexity = 7.03011660439433, 0:00:13.138272 per 50 iters\n",
            "time = 0:01:00.502669, epoch 14, iter = 850, loss = 2.0283384823799135, perplexity = 7.601445924194371, 0:00:13.019113 per 50 iters\n",
            "time = 0:01:00.723433, epoch 14, iter = 900, loss = 2.1848583912849424, perplexity = 8.889389649191704, 0:00:13.244905 per 50 iters\n",
            "time = 0:01:00.940728, epoch 14, iter = 950, loss = 2.0801253437995912, perplexity = 8.005472287725786, 0:00:13.037474 per 50 iters\n",
            "time = 0:01:01.156004, epoch 14, iter = 1000, loss = 2.1096545219421388, perplexity = 8.245392190424981, 0:00:12.915701 per 50 iters\n",
            "\n",
            "time = 0:01:01.399562, epoch 15, iter = 50, loss = 2.012731742858887, perplexity = 7.483733083761561, 0:00:14.613311 per 50 iters\n",
            "time = 0:01:01.620851, epoch 15, iter = 100, loss = 1.7606440424919128, perplexity = 5.8161820567975795, 0:00:13.277237 per 50 iters\n",
            "time = 0:01:01.838553, epoch 15, iter = 150, loss = 1.8547112607955933, perplexity = 6.3898529831665565, 0:00:13.061889 per 50 iters\n",
            "time = 0:01:02.056679, epoch 15, iter = 200, loss = 1.9099652814865111, perplexity = 6.752854345396699, 0:00:13.087290 per 50 iters\n",
            "time = 0:01:02.274690, epoch 15, iter = 250, loss = 1.8530357050895692, perplexity = 6.37915539324665, 0:00:13.080479 per 50 iters\n",
            "time = 0:01:02.490397, epoch 15, iter = 300, loss = 1.8161711132526397, perplexity = 6.1482722860484325, 0:00:12.942276 per 50 iters\n",
            "time = 0:01:02.709667, epoch 15, iter = 350, loss = 1.8671514511108398, perplexity = 6.4698404685760815, 0:00:13.155995 per 50 iters\n",
            "time = 0:01:02.926041, epoch 15, iter = 400, loss = 1.9062042927742004, perplexity = 6.727504636293721, 0:00:12.982288 per 50 iters\n",
            "time = 0:01:03.143692, epoch 15, iter = 450, loss = 1.8735583782196046, perplexity = 6.5114253382275695, 0:00:13.058075 per 50 iters\n",
            "time = 0:01:03.364102, epoch 15, iter = 500, loss = 1.9176913356781007, perplexity = 6.805229329469769, 0:00:13.223763 per 50 iters\n",
            "time = 0:01:03.581009, epoch 15, iter = 550, loss = 1.8743502306938171, perplexity = 6.516583468461864, 0:00:13.014158 per 50 iters\n",
            "time = 0:01:03.797724, epoch 15, iter = 600, loss = 1.9741691732406617, perplexity = 7.200634687946872, 0:00:13.002748 per 50 iters\n",
            "time = 0:01:04.014050, epoch 15, iter = 650, loss = 1.841203212738037, perplexity = 6.304118895711416, 0:00:12.979388 per 50 iters\n",
            "time = 0:01:04.228986, epoch 15, iter = 700, loss = 1.9325554752349854, perplexity = 6.907138729373322, 0:00:12.896008 per 50 iters\n",
            "time = 0:01:04.445997, epoch 15, iter = 750, loss = 1.9076508378982544, perplexity = 6.73724331734502, 0:00:13.020542 per 50 iters\n",
            "time = 0:01:04.662302, epoch 15, iter = 800, loss = 1.902108964920044, perplexity = 6.700009638111861, 0:00:12.978097 per 50 iters\n",
            "time = 0:01:04.880249, epoch 15, iter = 850, loss = 1.9368571972846984, perplexity = 6.9369153197360545, 0:00:13.076686 per 50 iters\n",
            "time = 0:01:05.092120, epoch 15, iter = 900, loss = 1.9309892225265504, perplexity = 6.896328872324693, 0:00:12.712103 per 50 iters\n",
            "time = 0:01:05.308971, epoch 15, iter = 950, loss = 1.8346803832054137, perplexity = 6.263132023315468, 0:00:13.010822 per 50 iters\n",
            "time = 0:01:05.523858, epoch 15, iter = 1000, loss = 1.9609529376029968, perplexity = 7.106095505311366, 0:00:12.892432 per 50 iters\n",
            "\n",
            "time = 0:01:05.772263, epoch 16, iter = 50, loss = 1.9344403409957887, perplexity = 6.920170035943175, 0:00:14.904156 per 50 iters\n",
            "time = 0:01:05.988890, epoch 16, iter = 100, loss = 1.7401195347309113, perplexity = 5.698024493789945, 0:00:12.997475 per 50 iters\n",
            "time = 0:01:06.208511, epoch 16, iter = 150, loss = 1.6802031922340392, perplexity = 5.366646321198192, 0:00:13.177040 per 50 iters\n",
            "time = 0:01:06.424141, epoch 16, iter = 200, loss = 1.711660816669464, perplexity = 5.538151698534451, 0:00:12.937640 per 50 iters\n",
            "time = 0:01:06.638000, epoch 16, iter = 250, loss = 1.7193860173225404, perplexity = 5.581100712934862, 0:00:12.831352 per 50 iters\n",
            "time = 0:01:06.856902, epoch 16, iter = 300, loss = 1.7751944756507874, perplexity = 5.9014287089166775, 0:00:13.133967 per 50 iters\n",
            "time = 0:01:07.075880, epoch 16, iter = 350, loss = 1.7586352491378785, perplexity = 5.8045102759588, 0:00:13.138493 per 50 iters\n",
            "time = 0:01:07.294212, epoch 16, iter = 400, loss = 1.6942897057533264, perplexity = 5.442778617560029, 0:00:13.099741 per 50 iters\n",
            "time = 0:01:07.513299, epoch 16, iter = 450, loss = 1.7493685841560365, perplexity = 5.750970275598652, 0:00:13.145060 per 50 iters\n",
            "time = 0:01:07.729813, epoch 16, iter = 500, loss = 1.7217493414878846, perplexity = 5.594306261468532, 0:00:12.990648 per 50 iters\n",
            "time = 0:01:07.947629, epoch 16, iter = 550, loss = 1.7878585982322692, perplexity = 5.9766403651079525, 0:00:13.068734 per 50 iters\n",
            "time = 0:01:08.162287, epoch 16, iter = 600, loss = 1.8044926714897156, perplexity = 6.076887687968755, 0:00:12.879392 per 50 iters\n",
            "time = 0:01:08.381319, epoch 16, iter = 650, loss = 1.7833722043037414, perplexity = 5.949886860315601, 0:00:13.141725 per 50 iters\n",
            "time = 0:01:08.595178, epoch 16, iter = 700, loss = 1.7498737931251527, perplexity = 5.753876451414236, 0:00:12.831426 per 50 iters\n",
            "time = 0:01:08.811275, epoch 16, iter = 750, loss = 1.820079309940338, perplexity = 6.172347959020202, 0:00:12.965602 per 50 iters\n",
            "time = 0:01:09.025402, epoch 16, iter = 800, loss = 1.8608405923843383, perplexity = 6.429138785766161, 0:00:12.847447 per 50 iters\n",
            "time = 0:01:09.240650, epoch 16, iter = 850, loss = 1.8360775637626647, perplexity = 6.271888865626321, 0:00:12.914750 per 50 iters\n",
            "time = 0:01:09.458055, epoch 16, iter = 900, loss = 1.8541601538658141, perplexity = 6.386332461088424, 0:00:13.044069 per 50 iters\n",
            "time = 0:01:09.676033, epoch 16, iter = 950, loss = 1.8309205436706544, perplexity = 6.239627865542265, 0:00:13.078545 per 50 iters\n",
            "time = 0:01:09.892833, epoch 16, iter = 1000, loss = 1.8104276251792908, perplexity = 6.113060972177282, 0:00:13.007854 per 50 iters\n",
            "\n",
            "time = 0:01:10.138360, epoch 17, iter = 50, loss = 1.744966218471527, perplexity = 5.725708048984719, 0:00:14.731497 per 50 iters\n",
            "time = 0:01:10.356855, epoch 17, iter = 100, loss = 1.5398563933372498, perplexity = 4.663920452842538, 0:00:13.109511 per 50 iters\n",
            "time = 0:01:10.576468, epoch 17, iter = 150, loss = 1.6416363859176635, perplexity = 5.163612264944519, 0:00:13.176581 per 50 iters\n",
            "time = 0:01:10.793543, epoch 17, iter = 200, loss = 1.6063977885246277, perplexity = 4.9848224629389675, 0:00:13.023633 per 50 iters\n",
            "time = 0:01:11.013259, epoch 17, iter = 250, loss = 1.6581991219520569, perplexity = 5.2498479902804585, 0:00:13.182768 per 50 iters\n",
            "time = 0:01:11.231006, epoch 17, iter = 300, loss = 1.6729907608032226, perplexity = 5.328079001852738, 0:00:13.064633 per 50 iters\n",
            "time = 0:01:11.447580, epoch 17, iter = 350, loss = 1.6932068061828613, perplexity = 5.4368878250769255, 0:00:12.994271 per 50 iters\n",
            "time = 0:01:11.664254, epoch 17, iter = 400, loss = 1.589161286354065, perplexity = 4.899637811450101, 0:00:13.000289 per 50 iters\n",
            "time = 0:01:11.882522, epoch 17, iter = 450, loss = 1.697625870704651, perplexity = 5.4609669475866625, 0:00:13.095954 per 50 iters\n",
            "time = 0:01:12.098727, epoch 17, iter = 500, loss = 1.6422795534133912, perplexity = 5.166934400744233, 0:00:12.972130 per 50 iters\n",
            "time = 0:01:12.318684, epoch 17, iter = 550, loss = 1.6771571373939513, perplexity = 5.3503240940164325, 0:00:13.197283 per 50 iters\n",
            "time = 0:01:12.531107, epoch 17, iter = 600, loss = 1.6479280614852905, perplexity = 5.196202454013416, 0:00:12.745166 per 50 iters\n",
            "time = 0:01:12.747058, epoch 17, iter = 650, loss = 1.6986292576789856, perplexity = 5.466449160619766, 0:00:12.956805 per 50 iters\n",
            "time = 0:01:12.963185, epoch 17, iter = 700, loss = 1.701454026699066, perplexity = 5.48191244668203, 0:00:12.966854 per 50 iters\n",
            "time = 0:01:13.180907, epoch 17, iter = 750, loss = 1.6624816870689392, perplexity = 5.272379017011539, 0:00:13.063108 per 50 iters\n",
            "time = 0:01:13.398724, epoch 17, iter = 800, loss = 1.7974007034301758, perplexity = 6.033943055560113, 0:00:13.068865 per 50 iters\n",
            "time = 0:01:13.615598, epoch 17, iter = 850, loss = 1.7492574429512024, perplexity = 5.7503311413509905, 0:00:13.012230 per 50 iters\n",
            "time = 0:01:13.829709, epoch 17, iter = 900, loss = 1.7188557887077331, perplexity = 5.57814223803808, 0:00:12.846494 per 50 iters\n",
            "time = 0:01:14.044210, epoch 17, iter = 950, loss = 1.698284888267517, perplexity = 5.464567006836196, 0:00:12.869891 per 50 iters\n",
            "time = 0:01:14.262153, epoch 17, iter = 1000, loss = 1.6839191102981568, perplexity = 5.386625436595392, 0:00:13.076431 per 50 iters\n",
            "\n",
            "time = 0:01:14.507374, epoch 18, iter = 50, loss = 1.6223470091819763, perplexity = 5.064963894181625, 0:00:14.712351 per 50 iters\n",
            "time = 0:01:14.726894, epoch 18, iter = 100, loss = 1.567389075756073, perplexity = 4.794114768505921, 0:00:13.170316 per 50 iters\n",
            "time = 0:01:14.941565, epoch 18, iter = 150, loss = 1.550014570951462, perplexity = 4.711538833694241, 0:00:12.880084 per 50 iters\n",
            "time = 0:01:15.160576, epoch 18, iter = 200, loss = 1.5447929120063781, perplexity = 4.687000904899534, 0:00:13.140471 per 50 iters\n",
            "time = 0:01:15.379523, epoch 18, iter = 250, loss = 1.5051552534103394, perplexity = 4.504852969786295, 0:00:13.136612 per 50 iters\n",
            "time = 0:01:15.596599, epoch 18, iter = 300, loss = 1.535348641872406, perplexity = 4.642943972489195, 0:00:13.024373 per 50 iters\n",
            "time = 0:01:15.812939, epoch 18, iter = 350, loss = 1.5565190649032592, perplexity = 4.742284894924903, 0:00:12.979558 per 50 iters\n",
            "time = 0:01:16.028733, epoch 18, iter = 400, loss = 1.5804442024230958, perplexity = 4.857112873423464, 0:00:12.947525 per 50 iters\n",
            "time = 0:01:16.247335, epoch 18, iter = 450, loss = 1.550596158504486, perplexity = 4.714279803015068, 0:00:13.115969 per 50 iters\n",
            "time = 0:01:16.468091, epoch 18, iter = 500, loss = 1.626047384738922, perplexity = 5.083740882300644, 0:00:13.245184 per 50 iters\n",
            "time = 0:01:16.685542, epoch 18, iter = 550, loss = 1.5966969966888427, perplexity = 4.936699530547388, 0:00:13.046909 per 50 iters\n",
            "time = 0:01:16.900705, epoch 18, iter = 600, loss = 1.5380517864227294, perplexity = 4.655511499454333, 0:00:12.909641 per 50 iters\n",
            "time = 0:01:17.116692, epoch 18, iter = 650, loss = 1.6545256567001343, perplexity = 5.230598234411835, 0:00:12.959070 per 50 iters\n",
            "time = 0:01:17.329487, epoch 18, iter = 700, loss = 1.6434272146224975, perplexity = 5.172867694980542, 0:00:12.767536 per 50 iters\n",
            "time = 0:01:17.546128, epoch 18, iter = 750, loss = 1.5752785611152649, perplexity = 4.832087462324206, 0:00:12.998309 per 50 iters\n",
            "time = 0:01:17.763140, epoch 18, iter = 800, loss = 1.6325515341758727, perplexity = 5.116914057395614, 0:00:13.020581 per 50 iters\n",
            "time = 0:01:17.979622, epoch 18, iter = 850, loss = 1.584180977344513, perplexity = 4.875296764394037, 0:00:12.988684 per 50 iters\n",
            "time = 0:01:18.200435, epoch 18, iter = 900, loss = 1.5727894020080566, perplexity = 4.8200745849946, 0:00:13.248658 per 50 iters\n",
            "time = 0:01:18.416974, epoch 18, iter = 950, loss = 1.5951973414421081, perplexity = 4.929301731655261, 0:00:12.992220 per 50 iters\n",
            "time = 0:01:18.633116, epoch 18, iter = 1000, loss = 1.61935156583786, perplexity = 5.049814782277165, 0:00:12.968340 per 50 iters\n",
            "\n",
            "time = 0:01:18.877310, epoch 19, iter = 50, loss = 1.5258226490020752, perplexity = 4.59892531488971, 0:00:14.651473 per 50 iters\n",
            "time = 0:01:19.092536, epoch 19, iter = 100, loss = 1.3803355050086976, perplexity = 3.976235450639514, 0:00:12.913368 per 50 iters\n",
            "time = 0:01:19.308389, epoch 19, iter = 150, loss = 1.3575540328025817, perplexity = 3.886674986273472, 0:00:12.950967 per 50 iters\n",
            "time = 0:01:19.524668, epoch 19, iter = 200, loss = 1.438127658367157, perplexity = 4.212800626052665, 0:00:12.976568 per 50 iters\n",
            "time = 0:01:19.739955, epoch 19, iter = 250, loss = 1.4735814428329468, perplexity = 4.364839604655128, 0:00:12.916220 per 50 iters\n",
            "time = 0:01:19.957019, epoch 19, iter = 300, loss = 1.5460588765144347, perplexity = 4.692938239128606, 0:00:13.023638 per 50 iters\n",
            "time = 0:01:20.174794, epoch 19, iter = 350, loss = 1.3942422819137574, perplexity = 4.031918357441977, 0:00:13.066292 per 50 iters\n",
            "time = 0:01:20.392368, epoch 19, iter = 400, loss = 1.4592091488838195, perplexity = 4.302555501662556, 0:00:13.054250 per 50 iters\n",
            "time = 0:01:20.608981, epoch 19, iter = 450, loss = 1.4489912724494933, perplexity = 4.258816362303466, 0:00:12.996682 per 50 iters\n",
            "time = 0:01:20.828098, epoch 19, iter = 500, loss = 1.486563036441803, perplexity = 4.421871560482293, 0:00:13.146810 per 50 iters\n",
            "time = 0:01:21.040664, epoch 19, iter = 550, loss = 1.471428165435791, perplexity = 4.355451005948507, 0:00:12.753790 per 50 iters\n",
            "time = 0:01:21.259241, epoch 19, iter = 600, loss = 1.5134588956832886, perplexity = 4.54241539397766, 0:00:13.114463 per 50 iters\n",
            "time = 0:01:21.479101, epoch 19, iter = 650, loss = 1.477808759212494, perplexity = 4.3833302179102125, 0:00:13.191429 per 50 iters\n",
            "time = 0:01:21.698267, epoch 19, iter = 700, loss = 1.5432955980300904, perplexity = 4.679988244325268, 0:00:13.149731 per 50 iters\n",
            "time = 0:01:21.913281, epoch 19, iter = 750, loss = 1.5181310296058654, perplexity = 4.563687822150928, 0:00:12.900701 per 50 iters\n",
            "time = 0:01:22.129703, epoch 19, iter = 800, loss = 1.5464204668998718, perplexity = 4.694635467307528, 0:00:12.985190 per 50 iters\n",
            "time = 0:01:22.347453, epoch 19, iter = 850, loss = 1.5841901588439942, perplexity = 4.8753415271342435, 0:00:13.064849 per 50 iters\n",
            "time = 0:01:22.568025, epoch 19, iter = 900, loss = 1.5398862838745118, perplexity = 4.664059862014117, 0:00:13.234118 per 50 iters\n",
            "time = 0:01:22.785206, epoch 19, iter = 950, loss = 1.5309061670303346, perplexity = 4.622363558531082, 0:00:13.030034 per 50 iters\n",
            "time = 0:01:23.003071, epoch 19, iter = 1000, loss = 1.5919644904136658, perplexity = 4.913391764615915, 0:00:13.071107 per 50 iters\n",
            "\n",
            "time = 0:01:23.248502, epoch 20, iter = 50, loss = 1.3784098887443543, perplexity = 3.9685861141918854, 0:00:14.725672 per 50 iters\n",
            "time = 0:01:23.466164, epoch 20, iter = 100, loss = 1.38538170337677, perplexity = 3.9963510344091495, 0:00:13.059453 per 50 iters\n",
            "time = 0:01:23.685375, epoch 20, iter = 150, loss = 1.3165227055549622, perplexity = 3.730427004623707, 0:00:13.152506 per 50 iters\n",
            "time = 0:01:23.904973, epoch 20, iter = 200, loss = 1.3718280601501465, perplexity = 3.942551332847576, 0:00:13.175698 per 50 iters\n",
            "time = 0:01:24.120251, epoch 20, iter = 250, loss = 1.3544730013608932, perplexity = 3.8747184471320266, 0:00:12.916481 per 50 iters\n",
            "time = 0:01:24.334313, epoch 20, iter = 300, loss = 1.3140250205993653, perplexity = 3.7211211995387865, 0:00:12.843537 per 50 iters\n",
            "time = 0:01:24.550309, epoch 20, iter = 350, loss = 1.3255649209022522, perplexity = 3.764311292581847, 0:00:12.959629 per 50 iters\n",
            "time = 0:01:24.768430, epoch 20, iter = 400, loss = 1.4198604369163512, perplexity = 4.136543091254565, 0:00:13.087132 per 50 iters\n",
            "time = 0:01:24.986962, epoch 20, iter = 450, loss = 1.478266122341156, perplexity = 4.385335450057304, 0:00:13.111703 per 50 iters\n",
            "time = 0:01:25.206654, epoch 20, iter = 500, loss = 1.4771784925460816, perplexity = 4.380568421411546, 0:00:13.181356 per 50 iters\n",
            "time = 0:01:25.423828, epoch 20, iter = 550, loss = 1.4013282442092896, perplexity = 4.060589841460605, 0:00:13.030153 per 50 iters\n",
            "time = 0:01:25.638138, epoch 20, iter = 600, loss = 1.419282727241516, perplexity = 4.134154060439927, 0:00:12.858474 per 50 iters\n",
            "time = 0:01:25.855450, epoch 20, iter = 650, loss = 1.4313802242279052, perplexity = 4.184470715871421, 0:00:13.038529 per 50 iters\n",
            "time = 0:01:26.070082, epoch 20, iter = 700, loss = 1.4400000500679015, perplexity = 4.220696028317941, 0:00:12.877705 per 50 iters\n",
            "time = 0:01:26.289066, epoch 20, iter = 750, loss = 1.4182852864265443, perplexity = 4.130032542271588, 0:00:13.138897 per 50 iters\n",
            "time = 0:01:26.502395, epoch 20, iter = 800, loss = 1.393257393836975, perplexity = 4.027949323972874, 0:00:12.799528 per 50 iters\n",
            "time = 0:01:26.717930, epoch 20, iter = 850, loss = 1.4735500192642212, perplexity = 4.364702447972823, 0:00:12.931893 per 50 iters\n",
            "time = 0:01:26.935157, epoch 20, iter = 900, loss = 1.4633849143981934, perplexity = 4.320559528686291, 0:00:13.033491 per 50 iters\n",
            "time = 0:01:27.155086, epoch 20, iter = 950, loss = 1.461062650680542, perplexity = 4.310537691231526, 0:00:13.195630 per 50 iters\n",
            "time = 0:01:27.371714, epoch 20, iter = 1000, loss = 1.4503784322738646, perplexity = 4.264728120589465, 0:00:12.997443 per 50 iters\n",
            "\n",
            "time = 0:01:27.616186, epoch 21, iter = 50, loss = 1.3823039400577546, perplexity = 3.984070120353314, 0:00:14.668201 per 50 iters\n",
            "time = 0:01:27.832887, epoch 21, iter = 100, loss = 1.333895308971405, perplexity = 3.795800442782839, 0:00:13.001853 per 50 iters\n",
            "time = 0:01:28.052185, epoch 21, iter = 150, loss = 1.2886930775642396, perplexity = 3.6280418866313724, 0:00:13.157745 per 50 iters\n",
            "time = 0:01:28.271049, epoch 21, iter = 200, loss = 1.2493406224250794, perplexity = 3.4880422621837033, 0:00:13.131684 per 50 iters\n",
            "time = 0:01:28.486459, epoch 21, iter = 250, loss = 1.3078692626953126, perplexity = 3.6982852367429184, 0:00:12.924383 per 50 iters\n",
            "time = 0:01:28.704652, epoch 21, iter = 300, loss = 1.3123087477684021, perplexity = 3.714740217642543, 0:00:13.091263 per 50 iters\n",
            "time = 0:01:28.918430, epoch 21, iter = 350, loss = 1.314403202533722, perplexity = 3.72252872648586, 0:00:12.826499 per 50 iters\n",
            "time = 0:01:29.136753, epoch 21, iter = 400, loss = 1.3201129806041718, perplexity = 3.7438443351623047, 0:00:13.099165 per 50 iters\n",
            "time = 0:01:29.352043, epoch 21, iter = 450, loss = 1.2907698607444764, perplexity = 3.6355843723415404, 0:00:12.917251 per 50 iters\n",
            "time = 0:01:29.568382, epoch 21, iter = 500, loss = 1.4080960357189178, perplexity = 4.088164270658406, 0:00:12.979404 per 50 iters\n",
            "time = 0:01:29.784999, epoch 21, iter = 550, loss = 1.3335286045074464, perplexity = 3.794408760999731, 0:00:12.995907 per 50 iters\n",
            "time = 0:01:30.006009, epoch 21, iter = 600, loss = 1.3622215723991393, perplexity = 3.904858599024892, 0:00:13.260431 per 50 iters\n",
            "time = 0:01:30.222379, epoch 21, iter = 650, loss = 1.3064157629013062, perplexity = 3.6929136846337673, 0:00:12.982029 per 50 iters\n",
            "time = 0:01:30.440531, epoch 21, iter = 700, loss = 1.3526584696769715, perplexity = 3.867694022691125, 0:00:13.089004 per 50 iters\n",
            "time = 0:01:30.653953, epoch 21, iter = 750, loss = 1.3159662866592408, perplexity = 3.728351901915941, 0:00:12.804330 per 50 iters\n",
            "time = 0:01:30.869555, epoch 21, iter = 800, loss = 1.323054347038269, perplexity = 3.7548725643047316, 0:00:12.935959 per 50 iters\n",
            "time = 0:01:31.086116, epoch 21, iter = 850, loss = 1.3509311509132385, perplexity = 3.861019048796818, 0:00:12.993451 per 50 iters\n",
            "time = 0:01:31.303707, epoch 21, iter = 900, loss = 1.363424916267395, perplexity = 3.9095603149996236, 0:00:13.055245 per 50 iters\n",
            "time = 0:01:31.522082, epoch 21, iter = 950, loss = 1.3686024403572083, perplexity = 3.9298546495787785, 0:00:13.102342 per 50 iters\n",
            "time = 0:01:31.741109, epoch 21, iter = 1000, loss = 1.4175932717323303, perplexity = 4.127175487740629, 0:00:13.141466 per 50 iters\n",
            "\n",
            "time = 0:01:31.986197, epoch 22, iter = 50, loss = 1.286893937587738, perplexity = 3.621520399729726, 0:00:14.705139 per 50 iters\n",
            "time = 0:01:32.204337, epoch 22, iter = 100, loss = 1.203137320280075, perplexity = 3.330549549579185, 0:00:13.088171 per 50 iters\n",
            "time = 0:01:32.419180, epoch 22, iter = 150, loss = 1.1926159369945526, perplexity = 3.295691261487165, 0:00:12.890449 per 50 iters\n",
            "time = 0:01:32.636319, epoch 22, iter = 200, loss = 1.3004522931575775, perplexity = 3.6709566407640795, 0:00:13.028159 per 50 iters\n",
            "time = 0:01:32.853115, epoch 22, iter = 250, loss = 1.1826936531066894, perplexity = 3.26315217517019, 0:00:13.007572 per 50 iters\n",
            "time = 0:01:33.069551, epoch 22, iter = 300, loss = 1.2715341234207154, perplexity = 3.5663195421077565, 0:00:12.985987 per 50 iters\n",
            "time = 0:01:33.284818, epoch 22, iter = 350, loss = 1.1735238897800446, perplexity = 3.2333666140067865, 0:00:12.915807 per 50 iters\n",
            "time = 0:01:33.501613, epoch 22, iter = 400, loss = 1.222608128786087, perplexity = 3.396033485869496, 0:00:13.006652 per 50 iters\n",
            "time = 0:01:33.712698, epoch 22, iter = 450, loss = 1.225388491153717, perplexity = 3.4054888281205598, 0:00:12.665007 per 50 iters\n",
            "time = 0:01:33.927838, epoch 22, iter = 500, loss = 1.2923601150512696, perplexity = 3.6413704755157354, 0:00:12.908239 per 50 iters\n",
            "time = 0:01:34.143611, epoch 22, iter = 550, loss = 1.2910427057743072, perplexity = 3.63657645880484, 0:00:12.946188 per 50 iters\n",
            "time = 0:01:34.362403, epoch 22, iter = 600, loss = 1.2252311849594115, perplexity = 3.4049531657658663, 0:00:13.127428 per 50 iters\n",
            "time = 0:01:34.580976, epoch 22, iter = 650, loss = 1.3931952834129333, perplexity = 4.027699154101502, 0:00:13.114136 per 50 iters\n",
            "time = 0:01:34.800067, epoch 22, iter = 700, loss = 1.3058562064170838, perplexity = 3.6908478688600637, 0:00:13.145298 per 50 iters\n",
            "time = 0:01:35.018571, epoch 22, iter = 750, loss = 1.2875843691825866, perplexity = 3.624021675215537, 0:00:13.110101 per 50 iters\n",
            "time = 0:01:35.232034, epoch 22, iter = 800, loss = 1.252028992176056, perplexity = 3.49743202541396, 0:00:12.807573 per 50 iters\n",
            "time = 0:01:35.451280, epoch 22, iter = 850, loss = 1.3446343278884887, perplexity = 3.8367832794056476, 0:00:13.154569 per 50 iters\n",
            "time = 0:01:35.670235, epoch 22, iter = 900, loss = 1.2715123558044434, perplexity = 3.5662419126773677, 0:00:13.137166 per 50 iters\n",
            "time = 0:01:35.890278, epoch 22, iter = 950, loss = 1.263106346130371, perplexity = 3.536389693463168, 0:00:13.202347 per 50 iters\n",
            "time = 0:01:36.111485, epoch 22, iter = 1000, loss = 1.315832712650299, perplexity = 3.727853924264833, 0:00:13.272172 per 50 iters\n",
            "\n",
            "time = 0:01:36.358584, epoch 23, iter = 50, loss = 1.211513992547989, perplexity = 3.358565648647349, 0:00:14.825799 per 50 iters\n",
            "time = 0:01:36.577730, epoch 23, iter = 100, loss = 1.1644807684421539, perplexity = 3.204258698955713, 0:00:13.148596 per 50 iters\n",
            "time = 0:01:36.794479, epoch 23, iter = 150, loss = 1.1398057591915132, perplexity = 3.1261610781528226, 0:00:13.004764 per 50 iters\n",
            "time = 0:01:37.014924, epoch 23, iter = 200, loss = 1.1727259492874145, perplexity = 3.230787608941078, 0:00:13.226515 per 50 iters\n",
            "time = 0:01:37.231001, epoch 23, iter = 250, loss = 1.1333203518390655, perplexity = 3.105952252178655, 0:00:12.964414 per 50 iters\n",
            "time = 0:01:37.446825, epoch 23, iter = 300, loss = 1.1355015909671784, perplexity = 3.1127344708925357, 0:00:12.949302 per 50 iters\n",
            "time = 0:01:37.665639, epoch 23, iter = 350, loss = 1.1550242137908935, perplexity = 3.174100273597408, 0:00:13.128724 per 50 iters\n",
            "time = 0:01:37.882297, epoch 23, iter = 400, loss = 1.1910927855968476, perplexity = 3.290675245781252, 0:00:12.999292 per 50 iters\n",
            "time = 0:01:38.097532, epoch 23, iter = 450, loss = 1.229761654138565, perplexity = 3.420414197558846, 0:00:12.914008 per 50 iters\n",
            "time = 0:01:38.310505, epoch 23, iter = 500, loss = 1.214216080904007, perplexity = 3.3676530617468967, 0:00:12.778158 per 50 iters\n",
            "time = 0:01:38.526443, epoch 23, iter = 550, loss = 1.22975923538208, perplexity = 3.4204059244198297, 0:00:12.956092 per 50 iters\n",
            "time = 0:01:38.744113, epoch 23, iter = 600, loss = 1.2195496594905852, perplexity = 3.385662689192309, 0:00:13.060043 per 50 iters\n",
            "time = 0:01:38.960285, epoch 23, iter = 650, loss = 1.2078870850801469, perplexity = 3.3464065051880483, 0:00:12.970096 per 50 iters\n",
            "time = 0:01:39.176448, epoch 23, iter = 700, loss = 1.1908402276039123, perplexity = 3.2898442643856893, 0:00:12.969640 per 50 iters\n",
            "time = 0:01:39.394979, epoch 23, iter = 750, loss = 1.2123031294345856, perplexity = 3.3612170627134796, 0:00:13.111712 per 50 iters\n",
            "time = 0:01:39.610682, epoch 23, iter = 800, loss = 1.2355077600479125, perplexity = 3.4401248352644016, 0:00:12.941906 per 50 iters\n",
            "time = 0:01:39.822914, epoch 23, iter = 850, loss = 1.221624537706375, perplexity = 3.392694819836622, 0:00:12.733773 per 50 iters\n",
            "time = 0:01:40.041863, epoch 23, iter = 900, loss = 1.2480266737937926, perplexity = 3.483462163493586, 0:00:13.136743 per 50 iters\n",
            "time = 0:01:40.260787, epoch 23, iter = 950, loss = 1.2307361245155335, perplexity = 3.423748914398832, 0:00:13.135310 per 50 iters\n",
            "time = 0:01:40.480463, epoch 23, iter = 1000, loss = 1.2185100722312927, perplexity = 3.3821448262759213, 0:00:13.180333 per 50 iters\n",
            "\n",
            "time = 0:01:40.723930, epoch 24, iter = 50, loss = 1.137935665845871, perplexity = 3.1203203281991874, 0:00:14.607889 per 50 iters\n",
            "time = 0:01:40.942318, epoch 24, iter = 100, loss = 1.1080603981018067, perplexity = 3.028478651157967, 0:00:13.103019 per 50 iters\n",
            "time = 0:01:41.158011, epoch 24, iter = 150, loss = 1.0709610867500305, perplexity = 2.918182779467343, 0:00:12.940683 per 50 iters\n",
            "time = 0:01:41.375618, epoch 24, iter = 200, loss = 1.0384168255329131, perplexity = 2.82474141397553, 0:00:13.056247 per 50 iters\n",
            "time = 0:01:41.592905, epoch 24, iter = 250, loss = 1.0752841436862945, perplexity = 2.9308255578088276, 0:00:13.037077 per 50 iters\n",
            "time = 0:01:41.809729, epoch 24, iter = 300, loss = 1.0986340475082397, perplexity = 3.000065277230566, 0:00:13.009288 per 50 iters\n",
            "time = 0:01:42.028325, epoch 24, iter = 350, loss = 1.1551567566394807, perplexity = 3.1745210057712763, 0:00:13.115655 per 50 iters\n",
            "time = 0:01:42.243442, epoch 24, iter = 400, loss = 1.1233900892734527, perplexity = 3.0752619643039885, 0:00:12.906871 per 50 iters\n",
            "time = 0:01:42.461409, epoch 24, iter = 450, loss = 1.1442830634117127, perplexity = 3.1401892330653345, 0:00:13.077851 per 50 iters\n",
            "time = 0:01:42.678956, epoch 24, iter = 500, loss = 1.1387450683116913, perplexity = 3.1228469455542007, 0:00:13.052697 per 50 iters\n",
            "time = 0:01:42.896591, epoch 24, iter = 550, loss = 1.1379738891124724, perplexity = 3.1204395993144254, 0:00:13.057865 per 50 iters\n",
            "time = 0:01:43.111078, epoch 24, iter = 600, loss = 1.191088103055954, perplexity = 3.2906598370959217, 0:00:12.868135 per 50 iters\n",
            "time = 0:01:43.328269, epoch 24, iter = 650, loss = 1.1701166486740113, perplexity = 3.222368501618998, 0:00:13.031351 per 50 iters\n",
            "time = 0:01:43.544692, epoch 24, iter = 700, loss = 1.1383005154132844, perplexity = 3.1214589834274244, 0:00:12.984337 per 50 iters\n",
            "time = 0:01:43.761940, epoch 24, iter = 750, loss = 1.151192330121994, perplexity = 3.161960764043798, 0:00:13.034783 per 50 iters\n",
            "time = 0:01:43.980299, epoch 24, iter = 800, loss = 1.1541913831233979, perplexity = 3.1714578860312814, 0:00:13.101386 per 50 iters\n",
            "time = 0:01:44.198476, epoch 24, iter = 850, loss = 1.1569786548614502, perplexity = 3.18030993176301, 0:00:13.090417 per 50 iters\n",
            "time = 0:01:44.414554, epoch 24, iter = 900, loss = 1.1695482683181764, perplexity = 3.220537491067924, 0:00:12.964487 per 50 iters\n",
            "time = 0:01:44.631926, epoch 24, iter = 950, loss = 1.2328598487377167, perplexity = 3.4310277392716113, 0:00:13.042157 per 50 iters\n",
            "time = 0:01:44.850420, epoch 24, iter = 1000, loss = 1.2371239423751832, perplexity = 3.445689199529157, 0:00:13.109474 per 50 iters\n",
            "\n",
            "time = 0:01:45.096570, epoch 25, iter = 50, loss = 1.1255590784549714, perplexity = 3.0819394132743425, 0:00:14.768924 per 50 iters\n",
            "time = 0:01:45.314694, epoch 25, iter = 100, loss = 1.0379060876369477, perplexity = 2.8232990798478115, 0:00:13.087193 per 50 iters\n",
            "time = 0:01:45.532017, epoch 25, iter = 150, loss = 1.0326518094539643, perplexity = 2.8085035849503477, 0:00:13.039159 per 50 iters\n",
            "time = 0:01:45.750092, epoch 25, iter = 200, loss = 0.9859783971309661, perplexity = 2.680433129986503, 0:00:13.084321 per 50 iters\n",
            "time = 0:01:45.966698, epoch 25, iter = 250, loss = 1.035212494134903, perplexity = 2.815704492749077, 0:00:12.996204 per 50 iters\n",
            "time = 0:01:46.188096, epoch 25, iter = 300, loss = 1.065034375190735, perplexity = 2.900938702666916, 0:00:13.283714 per 50 iters\n",
            "time = 0:01:46.406687, epoch 25, iter = 350, loss = 1.039314377307892, perplexity = 2.8272779037906846, 0:00:13.115372 per 50 iters\n",
            "time = 0:01:46.623689, epoch 25, iter = 400, loss = 1.0708677172660828, perplexity = 2.917910322966918, 0:00:13.019912 per 50 iters\n",
            "time = 0:01:46.841515, epoch 25, iter = 450, loss = 1.0457001721858978, perplexity = 2.8453900893495447, 0:00:13.069401 per 50 iters\n",
            "time = 0:01:47.056368, epoch 25, iter = 500, loss = 1.0731663113832475, perplexity = 2.9246251288198275, 0:00:12.891029 per 50 iters\n",
            "time = 0:01:47.274456, epoch 25, iter = 550, loss = 1.0899735283851624, perplexity = 2.9741953397674914, 0:00:13.085054 per 50 iters\n",
            "time = 0:01:47.491655, epoch 25, iter = 600, loss = 1.0887234997749329, perplexity = 2.9704798332289206, 0:00:13.031745 per 50 iters\n",
            "time = 0:01:47.706937, epoch 25, iter = 650, loss = 1.0621860969066619, perplexity = 2.8926877779995572, 0:00:12.916076 per 50 iters\n",
            "time = 0:01:47.921586, epoch 25, iter = 700, loss = 1.086060519218445, perplexity = 2.9625800263740527, 0:00:12.878736 per 50 iters\n",
            "time = 0:01:48.140101, epoch 25, iter = 750, loss = 1.1599862217903136, perplexity = 3.1898893248494065, 0:00:13.110752 per 50 iters\n",
            "time = 0:01:48.359122, epoch 25, iter = 800, loss = 1.1614474499225615, perplexity = 3.194553888035133, 0:00:13.141088 per 50 iters\n",
            "time = 0:01:48.574328, epoch 25, iter = 850, loss = 1.0814188146591186, perplexity = 2.9488604708527624, 0:00:12.912240 per 50 iters\n",
            "time = 0:01:48.793360, epoch 25, iter = 900, loss = 1.1592896449565888, perplexity = 3.1876680955618175, 0:00:13.141766 per 50 iters\n",
            "time = 0:01:49.007662, epoch 25, iter = 950, loss = 1.1421193480491638, perplexity = 3.1334021027374415, 0:00:12.857948 per 50 iters\n",
            "time = 0:01:49.223631, epoch 25, iter = 1000, loss = 1.1508243191242218, perplexity = 3.160797341797327, 0:00:12.957968 per 50 iters\n",
            "\n",
            "time = 0:01:49.468727, epoch 26, iter = 50, loss = 0.9931680238246918, perplexity = 2.6997738866674386, 0:00:14.705601 per 50 iters\n",
            "time = 0:01:49.686657, epoch 26, iter = 100, loss = 0.9609796774387359, perplexity = 2.614256347255536, 0:00:13.075620 per 50 iters\n",
            "time = 0:01:49.902966, epoch 26, iter = 150, loss = 0.9862459468841552, perplexity = 2.6811503751539765, 0:00:12.978383 per 50 iters\n",
            "time = 0:01:50.123613, epoch 26, iter = 200, loss = 0.9638773846626282, perplexity = 2.6218426829395893, 0:00:13.238631 per 50 iters\n",
            "time = 0:01:50.338643, epoch 26, iter = 250, loss = 1.0135660362243653, perplexity = 2.755409405838482, 0:00:12.901607 per 50 iters\n",
            "time = 0:01:50.554228, epoch 26, iter = 300, loss = 0.9689016103744507, perplexity = 2.6350485592316972, 0:00:12.934859 per 50 iters\n",
            "time = 0:01:50.771145, epoch 26, iter = 350, loss = 0.9652246356010437, perplexity = 2.6253773434572647, 0:00:13.014921 per 50 iters\n",
            "time = 0:01:50.989511, epoch 26, iter = 400, loss = 1.004254539012909, perplexity = 2.7298715014220405, 0:00:13.101759 per 50 iters\n",
            "time = 0:01:51.204462, epoch 26, iter = 450, loss = 1.028458194732666, perplexity = 2.7967504642263155, 0:00:12.896895 per 50 iters\n",
            "time = 0:01:51.419190, epoch 26, iter = 500, loss = 1.0336425530910491, perplexity = 2.811287470837766, 0:00:12.883551 per 50 iters\n",
            "time = 0:01:51.632468, epoch 26, iter = 550, loss = 1.0488043370842934, perplexity = 2.8542363724444324, 0:00:12.796517 per 50 iters\n",
            "time = 0:01:51.852860, epoch 26, iter = 600, loss = 1.0653833591938018, perplexity = 2.901951260540997, 0:00:13.223330 per 50 iters\n",
            "time = 0:01:52.070606, epoch 26, iter = 650, loss = 1.0579015350341796, perplexity = 2.880320391572607, 0:00:13.064617 per 50 iters\n",
            "time = 0:01:52.285044, epoch 26, iter = 700, loss = 1.051870288848877, perplexity = 2.8630007522043885, 0:00:12.866092 per 50 iters\n",
            "time = 0:01:52.504227, epoch 26, iter = 750, loss = 1.14066348195076, perplexity = 3.1288436079275868, 0:00:13.150823 per 50 iters\n",
            "time = 0:01:52.721412, epoch 26, iter = 800, loss = 1.0789741969108582, perplexity = 2.9416604384577716, 0:00:13.030905 per 50 iters\n",
            "time = 0:01:52.939098, epoch 26, iter = 850, loss = 1.0809687316417693, perplexity = 2.9475335374717893, 0:00:13.060133 per 50 iters\n",
            "time = 0:01:53.158194, epoch 26, iter = 900, loss = 1.0472650909423828, perplexity = 2.8498463796265603, 0:00:13.145671 per 50 iters\n",
            "time = 0:01:53.376676, epoch 26, iter = 950, loss = 1.0679516518115997, perplexity = 2.9094138995589613, 0:00:13.108662 per 50 iters\n",
            "time = 0:01:53.595894, epoch 26, iter = 1000, loss = 1.0663887977600097, perplexity = 2.9048704615483185, 0:00:13.152948 per 50 iters\n",
            "\n",
            "time = 0:01:53.837880, epoch 27, iter = 50, loss = 0.9808015191555023, perplexity = 2.6665927107422824, 0:00:14.518895 per 50 iters\n",
            "time = 0:01:54.057288, epoch 27, iter = 100, loss = 0.9217624402046204, perplexity = 2.513716763668337, 0:00:13.164276 per 50 iters\n",
            "time = 0:01:54.274363, epoch 27, iter = 150, loss = 0.9544378423690796, perplexity = 2.5972101309616527, 0:00:13.024307 per 50 iters\n",
            "time = 0:01:54.494078, epoch 27, iter = 200, loss = 0.9238381147384643, perplexity = 2.518939840368358, 0:00:13.182704 per 50 iters\n",
            "time = 0:01:54.712495, epoch 27, iter = 250, loss = 0.9793523669242858, perplexity = 2.66273121059232, 0:00:13.104791 per 50 iters\n",
            "time = 0:01:54.930198, epoch 27, iter = 300, loss = 0.981026703119278, perplexity = 2.667193252272286, 0:00:13.061925 per 50 iters\n",
            "time = 0:01:55.149984, epoch 27, iter = 350, loss = 0.9441116631031037, perplexity = 2.57052886839288, 0:00:13.186313 per 50 iters\n",
            "time = 0:01:55.364069, epoch 27, iter = 400, loss = 0.9492636215686798, perplexity = 2.583806299375682, 0:00:12.844925 per 50 iters\n",
            "time = 0:01:55.583323, epoch 27, iter = 450, loss = 1.017529046535492, perplexity = 2.766350787810041, 0:00:13.155119 per 50 iters\n",
            "time = 0:01:55.800702, epoch 27, iter = 500, loss = 1.0093274545669555, perplexity = 2.743755094395625, 0:00:13.042556 per 50 iters\n",
            "time = 0:01:56.017792, epoch 27, iter = 550, loss = 0.9608132767677308, perplexity = 2.613821369436477, 0:00:13.025247 per 50 iters\n",
            "time = 0:01:56.232909, epoch 27, iter = 600, loss = 0.9748468852043152, perplexity = 2.650761309132353, 0:00:12.906882 per 50 iters\n",
            "time = 0:01:56.449886, epoch 27, iter = 650, loss = 0.992327082157135, perplexity = 2.6975044886625694, 0:00:13.018493 per 50 iters\n",
            "time = 0:01:56.668070, epoch 27, iter = 700, loss = 0.9934241402149201, perplexity = 2.7004654315639356, 0:00:13.090853 per 50 iters\n",
            "time = 0:01:56.885015, epoch 27, iter = 750, loss = 1.0202313899993896, perplexity = 2.773836527745036, 0:00:13.016542 per 50 iters\n",
            "time = 0:01:57.101919, epoch 27, iter = 800, loss = 1.0169264161586762, perplexity = 2.7646842030101277, 0:00:13.014050 per 50 iters\n",
            "time = 0:01:57.317766, epoch 27, iter = 850, loss = 1.0168822586536408, perplexity = 2.7645621241488807, 0:00:12.950638 per 50 iters\n",
            "time = 0:01:57.533950, epoch 27, iter = 900, loss = 1.0558280205726625, perplexity = 2.874354193223777, 0:00:12.970123 per 50 iters\n",
            "time = 0:01:57.749969, epoch 27, iter = 950, loss = 1.0054375290870667, perplexity = 2.733102823245927, 0:00:12.961001 per 50 iters\n",
            "time = 0:01:57.964558, epoch 27, iter = 1000, loss = 1.0330991542339325, perplexity = 2.809760235425656, 0:00:12.875217 per 50 iters\n",
            "\n",
            "time = 0:01:58.209897, epoch 28, iter = 50, loss = 0.9622992539405822, perplexity = 2.6177083355816095, 0:00:14.720155 per 50 iters\n",
            "time = 0:01:58.425378, epoch 28, iter = 100, loss = 0.8658070170879364, perplexity = 2.376923530073458, 0:00:12.928701 per 50 iters\n",
            "time = 0:01:58.641383, epoch 28, iter = 150, loss = 0.8838311290740967, perplexity = 2.4201538900441117, 0:00:12.960149 per 50 iters\n",
            "time = 0:01:58.858986, epoch 28, iter = 200, loss = 0.8664536058902741, perplexity = 2.3784609191877477, 0:00:13.055993 per 50 iters\n",
            "time = 0:01:59.075003, epoch 28, iter = 250, loss = 0.8840946173667907, perplexity = 2.4207916562789347, 0:00:12.960800 per 50 iters\n",
            "time = 0:01:59.293498, epoch 28, iter = 300, loss = 0.9148069608211518, perplexity = 2.4962933229775706, 0:00:13.108783 per 50 iters\n",
            "time = 0:01:59.510366, epoch 28, iter = 350, loss = 0.9011944186687469, perplexity = 2.462542662208478, 0:00:13.011961 per 50 iters\n",
            "time = 0:01:59.726894, epoch 28, iter = 400, loss = 0.9040303921699524, perplexity = 2.469536280114295, 0:00:12.991457 per 50 iters\n",
            "time = 0:01:59.944019, epoch 28, iter = 450, loss = 0.9351395225524902, perplexity = 2.5475688762562414, 0:00:13.027335 per 50 iters\n",
            "time = 0:02:00.162831, epoch 28, iter = 500, loss = 0.9519407188892365, perplexity = 2.5907326674405855, 0:00:13.128509 per 50 iters\n",
            "time = 0:02:00.381068, epoch 28, iter = 550, loss = 0.9750798833370209, perplexity = 2.6513790035256553, 0:00:13.094084 per 50 iters\n",
            "time = 0:02:00.597910, epoch 28, iter = 600, loss = 1.0049038016796112, perplexity = 2.7316444805751128, 0:00:13.010340 per 50 iters\n",
            "time = 0:02:00.814937, epoch 28, iter = 650, loss = 0.9517652654647827, perplexity = 2.59027815439634, 0:00:13.021419 per 50 iters\n",
            "time = 0:02:01.032795, epoch 28, iter = 700, loss = 0.9898317098617554, perplexity = 2.6907816022357176, 0:00:13.071196 per 50 iters\n",
            "time = 0:02:01.247948, epoch 28, iter = 750, loss = 0.9466048169136048, perplexity = 2.5769455878466334, 0:00:12.909057 per 50 iters\n",
            "time = 0:02:01.468858, epoch 28, iter = 800, loss = 0.9626634287834167, perplexity = 2.6186618127089605, 0:00:13.254398 per 50 iters\n",
            "time = 0:02:01.686871, epoch 28, iter = 850, loss = 0.9734132552146911, perplexity = 2.646963820971116, 0:00:13.080625 per 50 iters\n",
            "time = 0:02:01.904263, epoch 28, iter = 900, loss = 0.9835081577301026, perplexity = 2.6738199898399344, 0:00:13.043376 per 50 iters\n",
            "time = 0:02:02.120621, epoch 28, iter = 950, loss = 0.9922305345535278, perplexity = 2.697244063640378, 0:00:12.981315 per 50 iters\n",
            "time = 0:02:02.335469, epoch 28, iter = 1000, loss = 1.0045972728729249, perplexity = 2.7308072811716126, 0:00:12.890605 per 50 iters\n",
            "\n",
            "time = 0:02:02.581006, epoch 29, iter = 50, loss = 0.9207084906101227, perplexity = 2.511068828544774, 0:00:14.731343 per 50 iters\n",
            "time = 0:02:02.801838, epoch 29, iter = 100, loss = 0.8569484281539917, perplexity = 2.355960330865087, 0:00:13.249752 per 50 iters\n",
            "time = 0:02:03.019255, epoch 29, iter = 150, loss = 0.8721408343315125, perplexity = 2.3920263079422304, 0:00:13.044824 per 50 iters\n",
            "time = 0:02:03.238153, epoch 29, iter = 200, loss = 0.8811556452512741, perplexity = 2.413687461732067, 0:00:13.133720 per 50 iters\n",
            "time = 0:02:03.452192, epoch 29, iter = 250, loss = 0.8432981014251709, perplexity = 2.3240192019794437, 0:00:12.842145 per 50 iters\n",
            "time = 0:02:03.668495, epoch 29, iter = 300, loss = 0.8579551565647126, perplexity = 2.3583333373508033, 0:00:12.977914 per 50 iters\n",
            "time = 0:02:03.886889, epoch 29, iter = 350, loss = 0.8542975199222564, perplexity = 2.34972316695747, 0:00:13.103489 per 50 iters\n",
            "time = 0:02:04.104278, epoch 29, iter = 400, loss = 0.8795617806911469, perplexity = 2.409843435070303, 0:00:13.043138 per 50 iters\n",
            "time = 0:02:04.323213, epoch 29, iter = 450, loss = 0.9055875670909882, perplexity = 2.4733847756890226, 0:00:13.135865 per 50 iters\n",
            "time = 0:02:04.541033, epoch 29, iter = 500, loss = 0.8918605399131775, perplexity = 2.4396645245480473, 0:00:13.069028 per 50 iters\n",
            "time = 0:02:04.756015, epoch 29, iter = 550, loss = 0.8971085333824158, perplexity = 2.4525015228191203, 0:00:12.897739 per 50 iters\n",
            "time = 0:02:04.972707, epoch 29, iter = 600, loss = 0.8568437826633454, perplexity = 2.355713803139553, 0:00:13.001337 per 50 iters\n",
            "time = 0:02:05.188933, epoch 29, iter = 650, loss = 0.943725872039795, perplexity = 2.569537372594884, 0:00:12.973348 per 50 iters\n",
            "time = 0:02:05.402731, epoch 29, iter = 700, loss = 0.9197648286819458, perplexity = 2.5087003461913175, 0:00:12.827721 per 50 iters\n",
            "time = 0:02:05.620196, epoch 29, iter = 750, loss = 0.9051528298854827, perplexity = 2.472309737000089, 0:00:13.047722 per 50 iters\n",
            "time = 0:02:05.835980, epoch 29, iter = 800, loss = 0.9167088139057159, perplexity = 2.5010454236000856, 0:00:12.946847 per 50 iters\n",
            "time = 0:02:06.055551, epoch 29, iter = 850, loss = 0.946060791015625, perplexity = 2.5755440439818074, 0:00:13.174084 per 50 iters\n",
            "time = 0:02:06.271474, epoch 29, iter = 900, loss = 0.9288644409179687, perplexity = 2.531632726202081, 0:00:12.955228 per 50 iters\n",
            "time = 0:02:06.494032, epoch 29, iter = 950, loss = 0.9884669673442841, perplexity = 2.6871118828585256, 0:00:13.353232 per 50 iters\n",
            "time = 0:02:06.705630, epoch 29, iter = 1000, loss = 1.004046268761158, perplexity = 2.7293030095992137, 0:00:12.695742 per 50 iters\n",
            "\n",
            "time = 0:02:06.952725, epoch 30, iter = 50, loss = 0.8871903491020202, perplexity = 2.4282973897079425, 0:00:14.824783 per 50 iters\n",
            "time = 0:02:07.171787, epoch 30, iter = 100, loss = 0.8082606077194214, perplexity = 2.2440013914127634, 0:00:13.143565 per 50 iters\n",
            "time = 0:02:07.385594, epoch 30, iter = 150, loss = 0.8580060505867004, perplexity = 2.3584533654738604, 0:00:12.828289 per 50 iters\n",
            "time = 0:02:07.599795, epoch 30, iter = 200, loss = 0.7892259931564332, perplexity = 2.201691642185302, 0:00:12.851875 per 50 iters\n",
            "time = 0:02:07.816666, epoch 30, iter = 250, loss = 0.8111225271224975, perplexity = 2.2504327411479674, 0:00:13.012142 per 50 iters\n",
            "time = 0:02:08.038058, epoch 30, iter = 300, loss = 0.8552920353412629, perplexity = 2.352061165272391, 0:00:13.283384 per 50 iters\n",
            "time = 0:02:08.254055, epoch 30, iter = 350, loss = 0.8337053471803665, perplexity = 2.301832045026649, 0:00:12.959626 per 50 iters\n",
            "time = 0:02:08.469865, epoch 30, iter = 400, loss = 0.8066781163215637, perplexity = 2.240453086835303, 0:00:12.948371 per 50 iters\n",
            "time = 0:02:08.688520, epoch 30, iter = 450, loss = 0.8465947043895722, perplexity = 2.331693212703432, 0:00:13.119160 per 50 iters\n",
            "time = 0:02:08.905202, epoch 30, iter = 500, loss = 0.8782915294170379, perplexity = 2.4067842717409, 0:00:13.000805 per 50 iters\n",
            "time = 0:02:09.122306, epoch 30, iter = 550, loss = 0.922158396244049, perplexity = 2.514712282080082, 0:00:13.026100 per 50 iters\n",
            "time = 0:02:09.341596, epoch 30, iter = 600, loss = 0.8560350036621094, perplexity = 2.353809321538829, 0:00:13.157168 per 50 iters\n",
            "time = 0:02:09.560700, epoch 30, iter = 650, loss = 0.9017032146453857, perplexity = 2.4637959128047053, 0:00:13.145683 per 50 iters\n",
            "time = 0:02:09.777088, epoch 30, iter = 700, loss = 0.8967365908622742, perplexity = 2.4515895028420904, 0:00:12.983105 per 50 iters\n",
            "time = 0:02:09.992999, epoch 30, iter = 750, loss = 0.8561952769756317, perplexity = 2.3541866045915865, 0:00:12.954446 per 50 iters\n",
            "time = 0:02:10.207808, epoch 30, iter = 800, loss = 0.8574969911575318, perplexity = 2.3572530780846384, 0:00:12.888355 per 50 iters\n",
            "time = 0:02:10.427034, epoch 30, iter = 850, loss = 0.9306221115589142, perplexity = 2.5360864156315555, 0:00:13.153392 per 50 iters\n",
            "time = 0:02:10.641888, epoch 30, iter = 900, loss = 0.9133725643157959, perplexity = 2.4927152153847563, 0:00:12.891102 per 50 iters\n",
            "time = 0:02:10.860914, epoch 30, iter = 950, loss = 0.8907669472694397, perplexity = 2.436997983691299, 0:00:13.140758 per 50 iters\n",
            "time = 0:02:11.074332, epoch 30, iter = 1000, loss = 0.9362631487846375, perplexity = 2.5504330002749063, 0:00:12.804885 per 50 iters\n",
            "\n",
            "time = 0:02:11.320531, epoch 31, iter = 50, loss = 0.8153015339374542, perplexity = 2.2598569932011032, 0:00:14.771715 per 50 iters\n",
            "time = 0:02:11.537881, epoch 31, iter = 100, loss = 0.7539919877052307, perplexity = 2.125467945339266, 0:00:13.040902 per 50 iters\n",
            "time = 0:02:11.754508, epoch 31, iter = 150, loss = 0.7689222383499146, perplexity = 2.157439794452957, 0:00:12.997480 per 50 iters\n",
            "time = 0:02:11.970721, epoch 31, iter = 200, loss = 0.7764759516716003, perplexity = 2.1737981816706466, 0:00:12.972516 per 50 iters\n",
            "time = 0:02:12.185412, epoch 31, iter = 250, loss = 0.757444306910038, perplexity = 2.1328184199379177, 0:00:12.881325 per 50 iters\n",
            "time = 0:02:12.405244, epoch 31, iter = 300, loss = 0.8163732266426087, perplexity = 2.262280163670544, 0:00:13.189771 per 50 iters\n",
            "time = 0:02:12.626666, epoch 31, iter = 350, loss = 0.8562944936752319, perplexity = 2.354420190804372, 0:00:13.285152 per 50 iters\n",
            "time = 0:02:12.847945, epoch 31, iter = 400, loss = 0.7891124832630158, perplexity = 2.2014417425849664, 0:00:13.275719 per 50 iters\n",
            "time = 0:02:13.063123, epoch 31, iter = 450, loss = 0.80505096077919, perplexity = 2.2368104855207793, 0:00:12.910485 per 50 iters\n",
            "time = 0:02:13.279154, epoch 31, iter = 500, loss = 0.8276624393463134, perplexity = 2.287964229295831, 0:00:12.961639 per 50 iters\n",
            "time = 0:02:13.491894, epoch 31, iter = 550, loss = 0.8100647163391114, perplexity = 2.2480534677594792, 0:00:12.764189 per 50 iters\n",
            "time = 0:02:13.708344, epoch 31, iter = 600, loss = 0.8413220942020416, perplexity = 2.3194314574505817, 0:00:12.986902 per 50 iters\n",
            "time = 0:02:13.926811, epoch 31, iter = 650, loss = 0.8801035559177399, perplexity = 2.41114938227637, 0:00:13.107858 per 50 iters\n",
            "time = 0:02:14.144247, epoch 31, iter = 700, loss = 0.8514244258403778, perplexity = 2.3429818800454543, 0:00:13.046006 per 50 iters\n",
            "time = 0:02:14.363606, epoch 31, iter = 750, loss = 0.899371987581253, perplexity = 2.458058934789674, 0:00:13.161371 per 50 iters\n",
            "time = 0:02:14.581362, epoch 31, iter = 800, loss = 0.901020610332489, perplexity = 2.462114688959132, 0:00:13.065189 per 50 iters\n",
            "time = 0:02:14.797792, epoch 31, iter = 850, loss = 0.8671990597248077, perplexity = 2.380234613021542, 0:00:12.985681 per 50 iters\n",
            "time = 0:02:15.014550, epoch 31, iter = 900, loss = 0.875033768415451, perplexity = 2.398956301552381, 0:00:13.005288 per 50 iters\n",
            "time = 0:02:15.230379, epoch 31, iter = 950, loss = 0.9078930413722992, perplexity = 2.4790936790133853, 0:00:12.949614 per 50 iters\n",
            "time = 0:02:15.446447, epoch 31, iter = 1000, loss = 0.9090788352489472, perplexity = 2.482035116742355, 0:00:12.963959 per 50 iters\n",
            "\n",
            "time = 0:02:15.692460, epoch 32, iter = 50, loss = 0.8014668953418732, perplexity = 2.228807959724241, 0:00:14.759898 per 50 iters\n",
            "time = 0:02:15.911914, epoch 32, iter = 100, loss = 0.7290745657682419, perplexity = 2.073161145351184, 0:00:13.167017 per 50 iters\n",
            "time = 0:02:16.127588, epoch 32, iter = 150, loss = 0.7153594386577606, perplexity = 2.044921574042186, 0:00:12.940313 per 50 iters\n",
            "time = 0:02:16.343826, epoch 32, iter = 200, loss = 0.7322012877464295, perplexity = 2.079653488455309, 0:00:12.974098 per 50 iters\n",
            "time = 0:02:16.561425, epoch 32, iter = 250, loss = 0.7762330782413482, perplexity = 2.1732702879578616, 0:00:13.055756 per 50 iters\n",
            "time = 0:02:16.780551, epoch 32, iter = 300, loss = 0.7758452260494232, perplexity = 2.1724275437536895, 0:00:13.146806 per 50 iters\n",
            "time = 0:02:16.997626, epoch 32, iter = 350, loss = 0.7890245312452316, perplexity = 2.2012481298561117, 0:00:13.024318 per 50 iters\n",
            "time = 0:02:17.210825, epoch 32, iter = 400, loss = 0.7880380550026893, perplexity = 2.1990777215761788, 0:00:12.791768 per 50 iters\n",
            "time = 0:02:17.427220, epoch 32, iter = 450, loss = 0.8187902295589446, perplexity = 2.2677547147615313, 0:00:12.983547 per 50 iters\n",
            "time = 0:02:17.642857, epoch 32, iter = 500, loss = 0.7793866169452667, perplexity = 2.1801345976695035, 0:00:12.937212 per 50 iters\n",
            "time = 0:02:17.859314, epoch 32, iter = 550, loss = 0.796790418624878, perplexity = 2.2184093246324004, 0:00:12.987228 per 50 iters\n",
            "time = 0:02:18.077135, epoch 32, iter = 600, loss = 0.8613215720653534, perplexity = 2.3662858454663174, 0:00:13.069065 per 50 iters\n",
            "time = 0:02:18.295881, epoch 32, iter = 650, loss = 0.8366327929496765, perplexity = 2.3085804064201105, 0:00:13.124501 per 50 iters\n",
            "time = 0:02:18.512465, epoch 32, iter = 700, loss = 0.8390631365776062, perplexity = 2.31419787352311, 0:00:12.994883 per 50 iters\n",
            "time = 0:02:18.725599, epoch 32, iter = 750, loss = 0.8475911879539489, perplexity = 2.3340178647134597, 0:00:12.787814 per 50 iters\n",
            "time = 0:02:18.942269, epoch 32, iter = 800, loss = 0.8384707367420197, perplexity = 2.3128273490726303, 0:00:13.000022 per 50 iters\n",
            "time = 0:02:19.161772, epoch 32, iter = 850, loss = 0.8248089694976807, perplexity = 2.2814448981337603, 0:00:13.170037 per 50 iters\n",
            "time = 0:02:19.379981, epoch 32, iter = 900, loss = 0.8596824407577515, perplexity = 2.362410369329116, 0:00:13.092373 per 50 iters\n",
            "time = 0:02:19.597960, epoch 32, iter = 950, loss = 0.876711323261261, perplexity = 2.4029840597690204, 0:00:13.078621 per 50 iters\n",
            "time = 0:02:19.815514, epoch 32, iter = 1000, loss = 0.8466182339191437, perplexity = 2.3317480769932954, 0:00:13.052223 per 50 iters\n",
            "\n",
            "time = 0:02:20.062447, epoch 33, iter = 50, loss = 0.7826897692680359, perplexity = 2.1873478209588657, 0:00:14.815790 per 50 iters\n",
            "time = 0:02:20.278480, epoch 33, iter = 100, loss = 0.6831229567527771, perplexity = 1.9800517025267663, 0:00:12.961850 per 50 iters\n",
            "time = 0:02:20.498418, epoch 33, iter = 150, loss = 0.7249757897853851, perplexity = 2.0646811129885343, 0:00:13.196065 per 50 iters\n",
            "time = 0:02:20.713373, epoch 33, iter = 200, loss = 0.7180019104480744, perplexity = 2.0503323674009275, 0:00:12.897182 per 50 iters\n",
            "time = 0:02:20.931499, epoch 33, iter = 250, loss = 0.7469326031208038, perplexity = 2.110516286538898, 0:00:13.087385 per 50 iters\n",
            "time = 0:02:21.150347, epoch 33, iter = 300, loss = 0.7361894881725312, perplexity = 2.0879641246098695, 0:00:13.130694 per 50 iters\n",
            "time = 0:02:21.365094, epoch 33, iter = 350, loss = 0.7711309367418289, perplexity = 2.1622101945057737, 0:00:12.884708 per 50 iters\n",
            "time = 0:02:21.584874, epoch 33, iter = 400, loss = 0.7741862392425537, perplexity = 2.168826502985195, 0:00:13.186640 per 50 iters\n",
            "time = 0:02:21.800265, epoch 33, iter = 450, loss = 0.7739099407196045, perplexity = 2.1682273422033185, 0:00:12.923266 per 50 iters\n",
            "time = 0:02:22.018272, epoch 33, iter = 500, loss = 0.7859661889076233, perplexity = 2.19452624365897, 0:00:13.080253 per 50 iters\n",
            "time = 0:02:22.232965, epoch 33, iter = 550, loss = 0.76575523853302, perplexity = 2.1506179910458596, 0:00:12.881418 per 50 iters\n",
            "time = 0:02:22.447466, epoch 33, iter = 600, loss = 0.8056057420372963, perplexity = 2.238051770345023, 0:00:12.869874 per 50 iters\n",
            "time = 0:02:22.665384, epoch 33, iter = 650, loss = 0.7976879298686981, perplexity = 2.2204012657056946, 0:00:13.074254 per 50 iters\n",
            "time = 0:02:22.884134, epoch 33, iter = 700, loss = 0.8261422622203827, perplexity = 2.284488760742705, 0:00:13.124830 per 50 iters\n",
            "time = 0:02:23.098327, epoch 33, iter = 750, loss = 0.8229762721061706, perplexity = 2.2772675291159663, 0:00:12.851272 per 50 iters\n",
            "time = 0:02:23.314069, epoch 33, iter = 800, loss = 0.8121079671382904, perplexity = 2.252651500671603, 0:00:12.944323 per 50 iters\n",
            "time = 0:02:23.532661, epoch 33, iter = 850, loss = 0.8213108539581299, perplexity = 2.2734780828272156, 0:00:13.115354 per 50 iters\n",
            "time = 0:02:23.749110, epoch 33, iter = 900, loss = 0.81365696310997, perplexity = 2.2561435526607414, 0:00:12.986793 per 50 iters\n",
            "time = 0:02:23.966572, epoch 33, iter = 950, loss = 0.8298663592338562, perplexity = 2.293012279868979, 0:00:13.047519 per 50 iters\n",
            "time = 0:02:24.185922, epoch 33, iter = 1000, loss = 0.8426715469360352, perplexity = 2.322563533391071, 0:00:13.160804 per 50 iters\n",
            "\n",
            "time = 0:02:24.433334, epoch 34, iter = 50, loss = 0.7596444880962372, perplexity = 2.137516172957878, 0:00:14.843855 per 50 iters\n",
            "time = 0:02:24.650201, epoch 34, iter = 100, loss = 0.7081517660617829, perplexity = 2.030235438858429, 0:00:13.011883 per 50 iters\n",
            "time = 0:02:24.866231, epoch 34, iter = 150, loss = 0.673308162689209, perplexity = 1.960712960956024, 0:00:12.961653 per 50 iters\n",
            "time = 0:02:25.084072, epoch 34, iter = 200, loss = 0.7080679166316987, perplexity = 2.0300652119107596, 0:00:13.070350 per 50 iters\n",
            "time = 0:02:25.302825, epoch 34, iter = 250, loss = 0.7166199314594269, perplexity = 2.0475008081777695, 0:00:13.125008 per 50 iters\n",
            "time = 0:02:25.520951, epoch 34, iter = 300, loss = 0.7154387354850769, perplexity = 2.045083736264508, 0:00:13.087403 per 50 iters\n",
            "time = 0:02:25.738151, epoch 34, iter = 350, loss = 0.7155480819940567, perplexity = 2.04530737125827, 0:00:13.031856 per 50 iters\n",
            "time = 0:02:25.955879, epoch 34, iter = 400, loss = 0.7346284902095794, perplexity = 2.084707359427862, 0:00:13.063558 per 50 iters\n",
            "time = 0:02:26.174911, epoch 34, iter = 450, loss = 0.7609853267669677, perplexity = 2.1403841596259237, 0:00:13.140665 per 50 iters\n",
            "time = 0:02:26.392642, epoch 34, iter = 500, loss = 0.7603951162099838, perplexity = 2.1391212550253864, 0:00:13.063694 per 50 iters\n",
            "time = 0:02:26.607800, epoch 34, iter = 550, loss = 0.7768870961666107, perplexity = 2.1746921105806867, 0:00:12.909200 per 50 iters\n",
            "time = 0:02:26.819148, epoch 34, iter = 600, loss = 0.755489786863327, perplexity = 2.1286538547689804, 0:00:12.680715 per 50 iters\n",
            "time = 0:02:27.034747, epoch 34, iter = 650, loss = 0.7425563359260559, perplexity = 2.1013002839036528, 0:00:12.935761 per 50 iters\n",
            "time = 0:02:27.255027, epoch 34, iter = 700, loss = 0.8200608360767364, perplexity = 2.270637970036429, 0:00:13.215963 per 50 iters\n",
            "time = 0:02:27.470916, epoch 34, iter = 750, loss = 0.789031652212143, perplexity = 2.201263804927019, 0:00:12.953080 per 50 iters\n",
            "time = 0:02:27.684468, epoch 34, iter = 800, loss = 0.7579364693164825, perplexity = 2.1338683713360935, 0:00:12.812935 per 50 iters\n",
            "time = 0:02:27.901827, epoch 34, iter = 850, loss = 0.813292201757431, perplexity = 2.255320748759605, 0:00:13.041267 per 50 iters\n",
            "time = 0:02:28.117320, epoch 34, iter = 900, loss = 0.7839669680595398, perplexity = 2.190143283753239, 0:00:12.929467 per 50 iters\n",
            "time = 0:02:28.338222, epoch 34, iter = 950, loss = 0.7950190734863282, perplexity = 2.2144832343169583, 0:00:13.253990 per 50 iters\n",
            "time = 0:02:28.554895, epoch 34, iter = 1000, loss = 0.8047902345657348, perplexity = 2.2362273664131944, 0:00:13.000234 per 50 iters\n",
            "\n",
            "time = 0:02:28.801719, epoch 35, iter = 50, loss = 0.7277075964212417, perplexity = 2.0703291336916543, 0:00:14.809246 per 50 iters\n",
            "time = 0:02:29.012440, epoch 35, iter = 100, loss = 0.6425524640083313, perplexity = 1.9013277616066975, 0:00:12.643096 per 50 iters\n",
            "time = 0:02:29.231868, epoch 35, iter = 150, loss = 0.6859718251228333, perplexity = 1.9857006519292126, 0:00:13.165468 per 50 iters\n",
            "time = 0:02:29.448936, epoch 35, iter = 200, loss = 0.6826401752233505, perplexity = 1.9790960008535972, 0:00:13.023910 per 50 iters\n",
            "time = 0:02:29.667020, epoch 35, iter = 250, loss = 0.6891104972362518, perplexity = 1.991942906261312, 0:00:13.084854 per 50 iters\n",
            "time = 0:02:29.885504, epoch 35, iter = 300, loss = 0.7056292772293091, perplexity = 2.025120646352202, 0:00:13.108903 per 50 iters\n",
            "time = 0:02:30.102656, epoch 35, iter = 350, loss = 0.6920774793624878, perplexity = 1.9978617414578401, 0:00:13.028906 per 50 iters\n",
            "time = 0:02:30.316145, epoch 35, iter = 400, loss = 0.6872627612948418, perplexity = 1.9882657200409461, 0:00:12.808363 per 50 iters\n",
            "time = 0:02:30.536285, epoch 35, iter = 450, loss = 0.739485696554184, perplexity = 2.0948578447854285, 0:00:13.208204 per 50 iters\n",
            "time = 0:02:30.752238, epoch 35, iter = 500, loss = 0.7458545887470245, perplexity = 2.108242345536672, 0:00:12.957009 per 50 iters\n",
            "time = 0:02:30.969795, epoch 35, iter = 550, loss = 0.7370310080051422, perplexity = 2.0897219273397054, 0:00:13.053231 per 50 iters\n",
            "time = 0:02:31.186048, epoch 35, iter = 600, loss = 0.7614651381969452, perplexity = 2.1414113868282243, 0:00:12.975018 per 50 iters\n",
            "time = 0:02:31.406104, epoch 35, iter = 650, loss = 0.75611394405365, perplexity = 2.1299828840966026, 0:00:13.203235 per 50 iters\n",
            "time = 0:02:31.619314, epoch 35, iter = 700, loss = 0.7217071080207824, perplexity = 2.057943345293005, 0:00:12.792374 per 50 iters\n",
            "time = 0:02:31.837392, epoch 35, iter = 750, loss = 0.7489325857162475, perplexity = 2.1147415061538406, 0:00:13.083787 per 50 iters\n",
            "time = 0:02:32.053581, epoch 35, iter = 800, loss = 0.7727755570411682, perplexity = 2.165769135033836, 0:00:12.971196 per 50 iters\n",
            "time = 0:02:32.272511, epoch 35, iter = 850, loss = 0.7592918992042541, perplexity = 2.1367626413501024, 0:00:13.135586 per 50 iters\n",
            "time = 0:02:32.491750, epoch 35, iter = 900, loss = 0.7597504752874374, perplexity = 2.137742734299283, 0:00:13.153368 per 50 iters\n",
            "time = 0:02:32.709729, epoch 35, iter = 950, loss = 0.7949937784671783, perplexity = 2.2144272196295884, 0:00:13.078538 per 50 iters\n",
            "time = 0:02:32.925212, epoch 35, iter = 1000, loss = 0.7707742774486541, perplexity = 2.161439159652652, 0:00:12.928752 per 50 iters\n",
            "\n",
            "time = 0:02:33.172680, epoch 36, iter = 50, loss = 0.7089330691099167, perplexity = 2.031822287819481, 0:00:14.847903 per 50 iters\n",
            "time = 0:02:33.391486, epoch 36, iter = 100, loss = 0.6549877953529358, perplexity = 1.9251190218347676, 0:00:13.128191 per 50 iters\n",
            "time = 0:02:33.608643, epoch 36, iter = 150, loss = 0.6613759088516236, perplexity = 1.9374562645432567, 0:00:13.029114 per 50 iters\n",
            "time = 0:02:33.826401, epoch 36, iter = 200, loss = 0.6539451265335083, perplexity = 1.9231128063479364, 0:00:13.064519 per 50 iters\n",
            "time = 0:02:34.045278, epoch 36, iter = 250, loss = 0.691839719414711, perplexity = 1.997386786419406, 0:00:13.132497 per 50 iters\n",
            "time = 0:02:34.261225, epoch 36, iter = 300, loss = 0.6730181562900543, perplexity = 1.9601444240940902, 0:00:12.956604 per 50 iters\n",
            "time = 0:02:34.479586, epoch 36, iter = 350, loss = 0.7120509600639343, perplexity = 2.038167174342978, 0:00:13.101487 per 50 iters\n",
            "time = 0:02:34.697590, epoch 36, iter = 400, loss = 0.6835940891504287, perplexity = 1.9809847888191836, 0:00:13.080006 per 50 iters\n",
            "time = 0:02:34.914887, epoch 36, iter = 450, loss = 0.7279480093717575, perplexity = 2.0708269274628606, 0:00:13.036903 per 50 iters\n",
            "time = 0:02:35.127161, epoch 36, iter = 500, loss = 0.7143728077411652, perplexity = 2.0429049861727777, 0:00:12.736179 per 50 iters\n",
            "time = 0:02:35.343907, epoch 36, iter = 550, loss = 0.6987169575691223, perplexity = 2.011170634110554, 0:00:13.004639 per 50 iters\n",
            "time = 0:02:35.562062, epoch 36, iter = 600, loss = 0.724710984826088, perplexity = 2.064134447573499, 0:00:13.088455 per 50 iters\n",
            "time = 0:02:35.781744, epoch 36, iter = 650, loss = 0.733853759765625, perplexity = 2.083092898636491, 0:00:13.180788 per 50 iters\n",
            "time = 0:02:35.997263, epoch 36, iter = 700, loss = 0.6972062495350838, perplexity = 2.008134636306324, 0:00:12.930948 per 50 iters\n",
            "time = 0:02:36.213429, epoch 36, iter = 750, loss = 0.7191110718250274, perplexity = 2.0526077785385657, 0:00:12.969751 per 50 iters\n",
            "time = 0:02:36.430420, epoch 36, iter = 800, loss = 0.7386302149295807, perplexity = 2.093066498734123, 0:00:13.019268 per 50 iters\n",
            "time = 0:02:36.645566, epoch 36, iter = 850, loss = 0.7286801213026046, perplexity = 2.0723435596677002, 0:00:12.908632 per 50 iters\n",
            "time = 0:02:36.860417, epoch 36, iter = 900, loss = 0.7258719110488892, perplexity = 2.066532146887787, 0:00:12.890853 per 50 iters\n",
            "time = 0:02:37.079908, epoch 36, iter = 950, loss = 0.7464263880252838, perplexity = 2.109448181703516, 0:00:13.169298 per 50 iters\n",
            "time = 0:02:37.295232, epoch 36, iter = 1000, loss = 0.7552004194259644, perplexity = 2.1280379807692316, 0:00:12.919309 per 50 iters\n",
            "\n",
            "time = 0:02:37.540971, epoch 37, iter = 50, loss = 0.6763140559196472, perplexity = 1.966615521561348, 0:00:14.744173 per 50 iters\n",
            "time = 0:02:37.758450, epoch 37, iter = 100, loss = 0.6446570491790772, perplexity = 1.9053334815293386, 0:00:13.048564 per 50 iters\n",
            "time = 0:02:37.976725, epoch 37, iter = 150, loss = 0.6275553041696549, perplexity = 1.8730259987459685, 0:00:13.096288 per 50 iters\n",
            "time = 0:02:38.190484, epoch 37, iter = 200, loss = 0.6395121800899506, perplexity = 1.8955559637874424, 0:00:12.825456 per 50 iters\n",
            "time = 0:02:38.407984, epoch 37, iter = 250, loss = 0.6522850424051285, perplexity = 1.9199229257686719, 0:00:13.049730 per 50 iters\n",
            "time = 0:02:38.627942, epoch 37, iter = 300, loss = 0.6456730961799622, perplexity = 1.907270373719053, 0:00:13.196473 per 50 iters\n",
            "time = 0:02:38.845372, epoch 37, iter = 350, loss = 0.6831805562973022, perplexity = 1.9801657558876473, 0:00:13.045667 per 50 iters\n",
            "time = 0:02:39.061885, epoch 37, iter = 400, loss = 0.6651458030939102, perplexity = 1.9447740547404424, 0:00:12.989957 per 50 iters\n",
            "time = 0:02:39.278379, epoch 37, iter = 450, loss = 0.671882011294365, perplexity = 1.9579186804390054, 0:00:12.989525 per 50 iters\n",
            "time = 0:02:39.491953, epoch 37, iter = 500, loss = 0.6849330198764801, perplexity = 1.9836389667044156, 0:00:12.814254 per 50 iters\n",
            "time = 0:02:39.709829, epoch 37, iter = 550, loss = 0.6901318919658661, perplexity = 1.993978505645732, 0:00:13.072403 per 50 iters\n",
            "time = 0:02:39.927297, epoch 37, iter = 600, loss = 0.6815567523241043, perplexity = 1.9769529640436683, 0:00:13.047912 per 50 iters\n",
            "time = 0:02:40.144627, epoch 37, iter = 650, loss = 0.7035003477334976, perplexity = 2.0208138932890587, 0:00:13.039585 per 50 iters\n",
            "time = 0:02:40.362684, epoch 37, iter = 700, loss = 0.7228979706764221, perplexity = 2.060395532989915, 0:00:13.083292 per 50 iters\n",
            "time = 0:02:40.579506, epoch 37, iter = 750, loss = 0.7132783842086792, perplexity = 2.0406704058929406, 0:00:13.009175 per 50 iters\n",
            "time = 0:02:40.796900, epoch 37, iter = 800, loss = 0.7016957342624665, perplexity = 2.017170393857654, 0:00:13.043510 per 50 iters\n",
            "time = 0:02:41.012479, epoch 37, iter = 850, loss = 0.7034658443927765, perplexity = 2.0207441696616204, 0:00:12.934590 per 50 iters\n",
            "time = 0:02:41.230131, epoch 37, iter = 900, loss = 0.7469553649425507, perplexity = 2.11056432628114, 0:00:13.058964 per 50 iters\n",
            "time = 0:02:41.448281, epoch 37, iter = 950, loss = 0.7489751005172729, perplexity = 2.1148314158794284, 0:00:13.088119 per 50 iters\n",
            "time = 0:02:41.662350, epoch 37, iter = 1000, loss = 0.7814803528785705, perplexity = 2.184704005713737, 0:00:12.844011 per 50 iters\n",
            "\n",
            "time = 0:02:41.904865, epoch 38, iter = 50, loss = 0.6903481525182724, perplexity = 1.9944097711700286, 0:00:14.550767 per 50 iters\n",
            "time = 0:02:42.121057, epoch 38, iter = 100, loss = 0.6524885225296021, perplexity = 1.920313631673682, 0:00:12.971328 per 50 iters\n",
            "time = 0:02:42.337824, epoch 38, iter = 150, loss = 0.5975537014007568, perplexity = 1.817666801401108, 0:00:13.005109 per 50 iters\n",
            "time = 0:02:42.555755, epoch 38, iter = 200, loss = 0.626696240901947, perplexity = 1.8714176418500619, 0:00:13.074841 per 50 iters\n",
            "time = 0:02:42.775254, epoch 38, iter = 250, loss = 0.6402745115756988, perplexity = 1.8970015567221314, 0:00:13.169752 per 50 iters\n",
            "time = 0:02:42.991080, epoch 38, iter = 300, loss = 0.6410557860136032, perplexity = 1.8984842146530174, 0:00:12.949445 per 50 iters\n",
            "time = 0:02:43.204622, epoch 38, iter = 350, loss = 0.6224750390648842, perplexity = 1.863534659796804, 0:00:12.812346 per 50 iters\n",
            "time = 0:02:43.421705, epoch 38, iter = 400, loss = 0.6361750084161758, perplexity = 1.8892407115204544, 0:00:13.024860 per 50 iters\n",
            "time = 0:02:43.643205, epoch 38, iter = 450, loss = 0.6716301655769348, perplexity = 1.957425649090783, 0:00:13.289801 per 50 iters\n",
            "time = 0:02:43.858625, epoch 38, iter = 500, loss = 0.6403220558166504, perplexity = 1.8970917503653069, 0:00:12.924027 per 50 iters\n",
            "time = 0:02:44.074139, epoch 38, iter = 550, loss = 0.6571119964122772, perplexity = 1.9292127080673187, 0:00:12.930641 per 50 iters\n",
            "time = 0:02:44.290567, epoch 38, iter = 600, loss = 0.6906196165084839, perplexity = 1.9949512550979958, 0:00:12.985566 per 50 iters\n",
            "time = 0:02:44.509180, epoch 38, iter = 650, loss = 0.6793493437767029, perplexity = 1.9725938341333829, 0:00:13.116614 per 50 iters\n",
            "time = 0:02:44.726720, epoch 38, iter = 700, loss = 0.6874221456050873, perplexity = 1.988582643656975, 0:00:13.052225 per 50 iters\n",
            "time = 0:02:44.943273, epoch 38, iter = 750, loss = 0.6793682813644409, perplexity = 1.9726311906559084, 0:00:12.992986 per 50 iters\n",
            "time = 0:02:45.159227, epoch 38, iter = 800, loss = 0.7087139821052552, perplexity = 2.031377190719714, 0:00:12.957106 per 50 iters\n",
            "time = 0:02:45.375124, epoch 38, iter = 850, loss = 0.6874219733476639, perplexity = 1.988582301108882, 0:00:12.953638 per 50 iters\n",
            "time = 0:02:45.594421, epoch 38, iter = 900, loss = 0.7010750997066498, perplexity = 2.0159188566200577, 0:00:13.157577 per 50 iters\n",
            "time = 0:02:45.814578, epoch 38, iter = 950, loss = 0.7339999991655349, perplexity = 2.083397551167503, 0:00:13.209283 per 50 iters\n",
            "time = 0:02:46.029770, epoch 38, iter = 1000, loss = 0.7087700474262237, perplexity = 2.031491083726614, 0:00:12.911371 per 50 iters\n",
            "\n",
            "time = 0:02:46.274844, epoch 39, iter = 50, loss = 0.6533114349842072, perplexity = 1.9218945320600294, 0:00:14.704249 per 50 iters\n",
            "time = 0:02:46.490170, epoch 39, iter = 100, loss = 0.5789535051584244, perplexity = 1.7841703283956643, 0:00:12.919303 per 50 iters\n",
            "time = 0:02:46.709441, epoch 39, iter = 150, loss = 0.5935839897394181, perplexity = 1.8104654913223401, 0:00:13.156119 per 50 iters\n",
            "time = 0:02:46.921267, epoch 39, iter = 200, loss = 0.5964385893940926, perplexity = 1.8156410290182203, 0:00:12.709317 per 50 iters\n",
            "time = 0:02:47.140055, epoch 39, iter = 250, loss = 0.6103474879264832, perplexity = 1.8410710375991817, 0:00:13.126532 per 50 iters\n",
            "time = 0:02:47.360091, epoch 39, iter = 300, loss = 0.6430742651224136, perplexity = 1.9023201354393084, 0:00:13.202011 per 50 iters\n",
            "time = 0:02:47.576641, epoch 39, iter = 350, loss = 0.6251612389087677, perplexity = 1.8685472156583296, 0:00:12.992845 per 50 iters\n",
            "time = 0:02:47.792500, epoch 39, iter = 400, loss = 0.66019681930542, perplexity = 1.935173176362716, 0:00:12.951341 per 50 iters\n",
            "time = 0:02:48.009775, epoch 39, iter = 450, loss = 0.6434429228305817, perplexity = 1.903021569707272, 0:00:13.036371 per 50 iters\n",
            "time = 0:02:48.228131, epoch 39, iter = 500, loss = 0.6231372439861298, perplexity = 1.8647691103039232, 0:00:13.101203 per 50 iters\n",
            "time = 0:02:48.443680, epoch 39, iter = 550, loss = 0.6555981695652008, perplexity = 1.9262944235221837, 0:00:12.932776 per 50 iters\n",
            "time = 0:02:48.660153, epoch 39, iter = 600, loss = 0.6549690437316894, perplexity = 1.925082923070472, 0:00:12.988230 per 50 iters\n",
            "time = 0:02:48.879240, epoch 39, iter = 650, loss = 0.6567309075593948, perplexity = 1.9284776466801814, 0:00:13.145074 per 50 iters\n",
            "time = 0:02:49.094061, epoch 39, iter = 700, loss = 0.6863106691837311, perplexity = 1.986373608809122, 0:00:12.889101 per 50 iters\n",
            "time = 0:02:49.308564, epoch 39, iter = 750, loss = 0.67508740067482, perplexity = 1.9642046412790384, 0:00:12.870025 per 50 iters\n",
            "time = 0:02:49.522224, epoch 39, iter = 800, loss = 0.6662444138526916, perplexity = 1.946911778488524, 0:00:12.819387 per 50 iters\n",
            "time = 0:02:49.744371, epoch 39, iter = 850, loss = 0.6801007819175721, perplexity = 1.9740766734380244, 0:00:13.328608 per 50 iters\n",
            "time = 0:02:49.961482, epoch 39, iter = 900, loss = 0.6748206633329391, perplexity = 1.963680784423312, 0:00:13.026436 per 50 iters\n",
            "time = 0:02:50.178005, epoch 39, iter = 950, loss = 0.6724069756269455, perplexity = 1.9589467877485518, 0:00:12.991218 per 50 iters\n",
            "time = 0:02:50.393793, epoch 39, iter = 1000, loss = 0.6982779860496521, perplexity = 2.0102879812252974, 0:00:12.947143 per 50 iters\n",
            "\n",
            "time = 0:02:50.634307, epoch 40, iter = 50, loss = 0.6125590336322785, perplexity = 1.8451471559461259, 0:00:14.429854 per 50 iters\n",
            "time = 0:02:50.851242, epoch 40, iter = 100, loss = 0.5622864145040513, perplexity = 1.754679842769837, 0:00:13.015946 per 50 iters\n",
            "time = 0:02:51.071594, epoch 40, iter = 150, loss = 0.5785304433107377, perplexity = 1.7834156736440179, 0:00:13.220980 per 50 iters\n",
            "time = 0:02:51.285476, epoch 40, iter = 200, loss = 0.5824254494905472, perplexity = 1.7903756344600548, 0:00:12.832680 per 50 iters\n",
            "time = 0:02:51.500003, epoch 40, iter = 250, loss = 0.5979496157169342, perplexity = 1.8183865841865754, 0:00:12.871472 per 50 iters\n",
            "time = 0:02:51.717341, epoch 40, iter = 300, loss = 0.5918501365184784, perplexity = 1.807329129679902, 0:00:13.040086 per 50 iters\n",
            "time = 0:02:51.933493, epoch 40, iter = 350, loss = 0.6665806102752686, perplexity = 1.947566433303662, 0:00:12.968875 per 50 iters\n",
            "time = 0:02:52.152463, epoch 40, iter = 400, loss = 0.6189818829298019, perplexity = 1.8570363985952112, 0:00:13.138070 per 50 iters\n",
            "time = 0:02:52.368309, epoch 40, iter = 450, loss = 0.6475692945718765, perplexity = 1.9108903677634266, 0:00:12.950522 per 50 iters\n",
            "time = 0:02:52.583762, epoch 40, iter = 500, loss = 0.6566641873121262, perplexity = 1.9283489824670448, 0:00:12.927032 per 50 iters\n",
            "time = 0:02:52.801541, epoch 40, iter = 550, loss = 0.640937038064003, perplexity = 1.898258786929984, 0:00:13.066622 per 50 iters\n",
            "time = 0:02:53.016634, epoch 40, iter = 600, loss = 0.6380090528726577, perplexity = 1.892708842355293, 0:00:12.905389 per 50 iters\n",
            "time = 0:02:53.234755, epoch 40, iter = 650, loss = 0.6425454974174499, perplexity = 1.9013145158801898, 0:00:13.087114 per 50 iters\n",
            "time = 0:02:53.450199, epoch 40, iter = 700, loss = 0.6185439616441727, perplexity = 1.8562233408687143, 0:00:12.926461 per 50 iters\n",
            "time = 0:02:53.670645, epoch 40, iter = 750, loss = 0.6423376500606537, perplexity = 1.900919373749672, 0:00:13.226589 per 50 iters\n",
            "time = 0:02:53.891187, epoch 40, iter = 800, loss = 0.6359853065013885, perplexity = 1.8888823529317147, 0:00:13.232323 per 50 iters\n",
            "time = 0:02:54.106261, epoch 40, iter = 850, loss = 0.6439131653308868, perplexity = 1.9039166617670158, 0:00:12.904268 per 50 iters\n",
            "time = 0:02:54.322594, epoch 40, iter = 900, loss = 0.6722415220737458, perplexity = 1.9586226998534757, 0:00:12.979133 per 50 iters\n",
            "time = 0:02:54.539293, epoch 40, iter = 950, loss = 0.6654650783538818, perplexity = 1.945395072114822, 0:00:13.001807 per 50 iters\n",
            "time = 0:02:54.758638, epoch 40, iter = 1000, loss = 0.6854950547218323, perplexity = 1.9847541542820848, 0:00:13.160537 per 50 iters\n",
            "\n",
            "time = 0:02:55.005194, epoch 41, iter = 50, loss = 0.6045234805345535, perplexity = 1.8303797894410294, 0:00:14.793148 per 50 iters\n",
            "time = 0:02:55.222236, epoch 41, iter = 100, loss = 0.5415301239490509, perplexity = 1.7186345752320713, 0:00:13.022371 per 50 iters\n",
            "time = 0:02:55.440851, epoch 41, iter = 150, loss = 0.5787212777137757, perplexity = 1.7837560431855426, 0:00:13.116652 per 50 iters\n",
            "time = 0:02:55.659090, epoch 41, iter = 200, loss = 0.5638044846057891, perplexity = 1.7573455926629302, 0:00:13.094256 per 50 iters\n",
            "time = 0:02:55.876463, epoch 41, iter = 250, loss = 0.5695612686872482, perplexity = 1.7674914274666658, 0:00:13.042233 per 50 iters\n",
            "time = 0:02:56.095538, epoch 41, iter = 300, loss = 0.5989587843418122, perplexity = 1.820222569128618, 0:00:13.143540 per 50 iters\n",
            "time = 0:02:56.309304, epoch 41, iter = 350, loss = 0.6135843980312348, perplexity = 1.8470400744504438, 0:00:12.825807 per 50 iters\n",
            "time = 0:02:56.527780, epoch 41, iter = 400, loss = 0.5815893286466598, perplexity = 1.788879289723381, 0:00:13.108382 per 50 iters\n",
            "time = 0:02:56.740096, epoch 41, iter = 450, loss = 0.5964963442087173, perplexity = 1.8157458940574778, 0:00:12.738811 per 50 iters\n",
            "time = 0:02:56.958154, epoch 41, iter = 500, loss = 0.6046986937522888, perplexity = 1.8307005242712853, 0:00:13.083329 per 50 iters\n",
            "time = 0:02:57.176268, epoch 41, iter = 550, loss = 0.6105143308639527, perplexity = 1.8413782329251573, 0:00:13.086674 per 50 iters\n",
            "time = 0:02:57.392341, epoch 41, iter = 600, loss = 0.644384593963623, perplexity = 1.9048144341969038, 0:00:12.964229 per 50 iters\n",
            "time = 0:02:57.608348, epoch 41, iter = 650, loss = 0.6163747775554657, perplexity = 1.8522012146758144, 0:00:12.959549 per 50 iters\n",
            "time = 0:02:57.828576, epoch 41, iter = 700, loss = 0.6388323068618774, perplexity = 1.8942676640252318, 0:00:13.213525 per 50 iters\n",
            "time = 0:02:58.044927, epoch 41, iter = 750, loss = 0.6089199906587601, perplexity = 1.8384447886508932, 0:00:12.980887 per 50 iters\n",
            "time = 0:02:58.254701, epoch 41, iter = 800, loss = 0.6314322412014007, perplexity = 1.8803016972011173, 0:00:12.586337 per 50 iters\n",
            "time = 0:02:58.474807, epoch 41, iter = 850, loss = 0.6419234132766723, perplexity = 1.9001321060905512, 0:00:13.206204 per 50 iters\n",
            "time = 0:02:58.689445, epoch 41, iter = 900, loss = 0.6770544004440308, perplexity = 1.968072033688165, 0:00:12.878116 per 50 iters\n",
            "time = 0:02:58.905350, epoch 41, iter = 950, loss = 0.6780450695753097, perplexity = 1.9700227079769381, 0:00:12.954126 per 50 iters\n",
            "time = 0:02:59.124335, epoch 41, iter = 1000, loss = 0.6887326401472091, perplexity = 1.991190378696104, 0:00:13.138965 per 50 iters\n",
            "\n",
            "time = 0:02:59.369278, epoch 42, iter = 50, loss = 0.6240430295467376, perplexity = 1.8664589564414837, 0:00:14.695727 per 50 iters\n",
            "time = 0:02:59.587800, epoch 42, iter = 100, loss = 0.524931390285492, perplexity = 1.690342870458768, 0:00:13.111221 per 50 iters\n",
            "time = 0:02:59.805006, epoch 42, iter = 150, loss = 0.5604993087053299, perplexity = 1.751546844581372, 0:00:13.032218 per 50 iters\n",
            "time = 0:03:00.022678, epoch 42, iter = 200, loss = 0.5623776572942734, perplexity = 1.754839951958931, 0:00:13.060167 per 50 iters\n",
            "time = 0:03:00.240285, epoch 42, iter = 250, loss = 0.567127857208252, perplexity = 1.763195622388533, 0:00:13.056259 per 50 iters\n",
            "time = 0:03:00.457220, epoch 42, iter = 300, loss = 0.6002516674995423, perplexity = 1.8225774261810546, 0:00:13.015940 per 50 iters\n",
            "time = 0:03:00.674075, epoch 42, iter = 350, loss = 0.5754818898439408, perplexity = 1.7779871144401538, 0:00:13.011093 per 50 iters\n",
            "time = 0:03:00.888787, epoch 42, iter = 400, loss = 0.5483920997381211, perplexity = 1.7304683592126955, 0:00:12.882536 per 50 iters\n",
            "time = 0:03:01.104014, epoch 42, iter = 450, loss = 0.5750342905521393, perplexity = 1.7771914667458542, 0:00:12.913491 per 50 iters\n",
            "time = 0:03:01.322833, epoch 42, iter = 500, loss = 0.6132281392812728, perplexity = 1.8463821674619099, 0:00:13.128931 per 50 iters\n",
            "time = 0:03:01.541946, epoch 42, iter = 550, loss = 0.6099663251638412, perplexity = 1.84036942359933, 0:00:13.146602 per 50 iters\n",
            "time = 0:03:01.761490, epoch 42, iter = 600, loss = 0.6057101607322692, perplexity = 1.8325531541808617, 0:00:13.172461 per 50 iters\n",
            "time = 0:03:01.978964, epoch 42, iter = 650, loss = 0.5958506149053574, perplexity = 1.8145737921972154, 0:00:13.048278 per 50 iters\n",
            "time = 0:03:02.195680, epoch 42, iter = 700, loss = 0.6053494238853454, perplexity = 1.8318922039559198, 0:00:13.002836 per 50 iters\n",
            "time = 0:03:02.413343, epoch 42, iter = 750, loss = 0.6117160385847091, perplexity = 1.8435923614657252, 0:00:13.059603 per 50 iters\n",
            "time = 0:03:02.628619, epoch 42, iter = 800, loss = 0.609382725507021, perplexity = 1.8392956979787216, 0:00:12.916431 per 50 iters\n",
            "time = 0:03:02.843597, epoch 42, iter = 850, loss = 0.6362680596113205, perplexity = 1.8894165158058498, 0:00:12.898549 per 50 iters\n",
            "time = 0:03:03.060185, epoch 42, iter = 900, loss = 0.6376558190584183, perplexity = 1.8920403916583082, 0:00:12.995115 per 50 iters\n",
            "time = 0:03:03.275118, epoch 42, iter = 950, loss = 0.6294436585903168, perplexity = 1.8765662772689968, 0:00:12.895855 per 50 iters\n",
            "time = 0:03:03.489277, epoch 42, iter = 1000, loss = 0.626911655664444, perplexity = 1.8718208162602146, 0:00:12.849412 per 50 iters\n",
            "\n",
            "time = 0:03:03.736406, epoch 43, iter = 50, loss = 0.5675378304719925, perplexity = 1.7639186336499728, 0:00:14.827615 per 50 iters\n",
            "time = 0:03:03.952880, epoch 43, iter = 100, loss = 0.523925187587738, perplexity = 1.6886428983040944, 0:00:12.988227 per 50 iters\n",
            "time = 0:03:04.169841, epoch 43, iter = 150, loss = 0.5486829179525375, perplexity = 1.7309716841155032, 0:00:13.017508 per 50 iters\n",
            "time = 0:03:04.388614, epoch 43, iter = 200, loss = 0.537802346944809, perplexity = 1.712239815308623, 0:00:13.126183 per 50 iters\n",
            "time = 0:03:04.603636, epoch 43, iter = 250, loss = 0.5438809245824814, perplexity = 1.722679495017385, 0:00:12.901133 per 50 iters\n",
            "time = 0:03:04.820736, epoch 43, iter = 300, loss = 0.5515894883871079, perplexity = 1.7360101940805068, 0:00:13.025854 per 50 iters\n",
            "time = 0:03:05.041324, epoch 43, iter = 350, loss = 0.5751051080226898, perplexity = 1.777317327406727, 0:00:13.234421 per 50 iters\n",
            "time = 0:03:05.257366, epoch 43, iter = 400, loss = 0.5720362007617951, perplexity = 1.7718712663582188, 0:00:12.962346 per 50 iters\n",
            "time = 0:03:05.476323, epoch 43, iter = 450, loss = 0.5774846941232681, perplexity = 1.7815516429765361, 0:00:13.137210 per 50 iters\n",
            "time = 0:03:05.693851, epoch 43, iter = 500, loss = 0.5838959282636642, perplexity = 1.7930102804471906, 0:00:13.051609 per 50 iters\n",
            "time = 0:03:05.908739, epoch 43, iter = 550, loss = 0.5901937538385391, perplexity = 1.8043379789415661, 0:00:12.893151 per 50 iters\n",
            "time = 0:03:06.124324, epoch 43, iter = 600, loss = 0.5951782160997391, perplexity = 1.8133540850574024, 0:00:12.934916 per 50 iters\n",
            "time = 0:03:06.341450, epoch 43, iter = 650, loss = 0.6084756702184677, perplexity = 1.837628111499558, 0:00:13.027428 per 50 iters\n",
            "time = 0:03:06.555326, epoch 43, iter = 700, loss = 0.608930544257164, perplexity = 1.8384641909612622, 0:00:12.832427 per 50 iters\n",
            "time = 0:03:06.773311, epoch 43, iter = 750, loss = 0.6081696259975433, perplexity = 1.8370658020859876, 0:00:13.078969 per 50 iters\n",
            "time = 0:03:06.990771, epoch 43, iter = 800, loss = 0.5956841397285462, perplexity = 1.814271735847462, 0:00:13.047406 per 50 iters\n",
            "time = 0:03:07.206304, epoch 43, iter = 850, loss = 0.606929412484169, perplexity = 1.8347888604920024, 0:00:12.931076 per 50 iters\n",
            "time = 0:03:07.424138, epoch 43, iter = 900, loss = 0.6258379346132279, perplexity = 1.8698120814491033, 0:00:13.069857 per 50 iters\n",
            "time = 0:03:07.640332, epoch 43, iter = 950, loss = 0.6147100050747395, perplexity = 1.849120286298801, 0:00:12.971482 per 50 iters\n",
            "time = 0:03:07.855475, epoch 43, iter = 1000, loss = 0.6153616601228714, perplexity = 1.8503256675717106, 0:00:12.908444 per 50 iters\n",
            "\n",
            "time = 0:03:08.099922, epoch 44, iter = 50, loss = 0.5372511857748031, perplexity = 1.7112963552318503, 0:00:14.666702 per 50 iters\n",
            "time = 0:03:08.318391, epoch 44, iter = 100, loss = 0.5177676451206207, perplexity = 1.6782769550661658, 0:00:13.107981 per 50 iters\n",
            "time = 0:03:08.532497, epoch 44, iter = 150, loss = 0.5175653660297393, perplexity = 1.6779375090620199, 0:00:12.846071 per 50 iters\n",
            "time = 0:03:08.750273, epoch 44, iter = 200, loss = 0.5637637639045715, perplexity = 1.7572740337750894, 0:00:13.066438 per 50 iters\n",
            "time = 0:03:08.968730, epoch 44, iter = 250, loss = 0.5438189733028412, perplexity = 1.722572776123979, 0:00:13.107273 per 50 iters\n",
            "time = 0:03:09.187731, epoch 44, iter = 300, loss = 0.5324560195207596, perplexity = 1.7031100477373602, 0:00:13.139910 per 50 iters\n",
            "time = 0:03:09.402544, epoch 44, iter = 350, loss = 0.5445727360248566, perplexity = 1.7238716767385127, 0:00:12.888570 per 50 iters\n",
            "time = 0:03:09.619400, epoch 44, iter = 400, loss = 0.5686398035287857, perplexity = 1.7658634958546942, 0:00:13.011278 per 50 iters\n",
            "time = 0:03:09.836443, epoch 44, iter = 450, loss = 0.5537172585725785, perplexity = 1.7397079574133243, 0:00:13.022396 per 50 iters\n",
            "time = 0:03:10.050659, epoch 44, iter = 500, loss = 0.5748637455701828, perplexity = 1.7768884015030875, 0:00:12.852191 per 50 iters\n",
            "time = 0:03:10.270073, epoch 44, iter = 550, loss = 0.602014908194542, perplexity = 1.825793903747414, 0:00:13.164578 per 50 iters\n",
            "time = 0:03:10.489108, epoch 44, iter = 600, loss = 0.5925414806604385, perplexity = 1.8085790480984043, 0:00:13.142009 per 50 iters\n",
            "time = 0:03:10.709909, epoch 44, iter = 650, loss = 0.579424866437912, perplexity = 1.785011515440407, 0:00:13.247870 per 50 iters\n",
            "time = 0:03:10.922787, epoch 44, iter = 700, loss = 0.5762498618662357, perplexity = 1.7793530832458226, 0:00:12.772571 per 50 iters\n",
            "time = 0:03:11.136215, epoch 44, iter = 750, loss = 0.5994903534650803, perplexity = 1.821190400455678, 0:00:12.805458 per 50 iters\n",
            "time = 0:03:11.353612, epoch 44, iter = 800, loss = 0.5798013585805893, perplexity = 1.7856836847758557, 0:00:13.043696 per 50 iters\n",
            "time = 0:03:11.568543, epoch 44, iter = 850, loss = 0.594566131234169, perplexity = 1.8122444980813586, 0:00:12.895729 per 50 iters\n",
            "time = 0:03:11.784341, epoch 44, iter = 900, loss = 0.5937973946332932, perplexity = 1.8108518947471048, 0:00:12.947743 per 50 iters\n",
            "time = 0:03:12.000913, epoch 44, iter = 950, loss = 0.5920013129711151, perplexity = 1.8076023759401536, 0:00:12.994110 per 50 iters\n",
            "time = 0:03:12.218454, epoch 44, iter = 1000, loss = 0.6043216544389725, perplexity = 1.8300104083113256, 0:00:13.051936 per 50 iters\n",
            "\n",
            "time = 0:03:12.463733, epoch 45, iter = 50, loss = 0.5326328891515731, perplexity = 1.7034113028233908, 0:00:14.716528 per 50 iters\n",
            "time = 0:03:12.682186, epoch 45, iter = 100, loss = 0.4691207653284073, perplexity = 1.5985880411077666, 0:00:13.107003 per 50 iters\n",
            "time = 0:03:12.901276, epoch 45, iter = 150, loss = 0.5186660236120224, perplexity = 1.6797853604432351, 0:00:13.145185 per 50 iters\n",
            "time = 0:03:13.113279, epoch 45, iter = 200, loss = 0.5416395092010498, perplexity = 1.718822578790398, 0:00:12.720065 per 50 iters\n",
            "time = 0:03:13.329533, epoch 45, iter = 250, loss = 0.550685858130455, perplexity = 1.7344421912973522, 0:00:12.975029 per 50 iters\n",
            "time = 0:03:13.547550, epoch 45, iter = 300, loss = 0.5515060186386108, perplexity = 1.7358652957936145, 0:00:13.080841 per 50 iters\n",
            "time = 0:03:13.761908, epoch 45, iter = 350, loss = 0.511837769150734, perplexity = 1.6683544296279007, 0:00:12.861290 per 50 iters\n",
            "time = 0:03:13.976425, epoch 45, iter = 400, loss = 0.5556920623779297, perplexity = 1.7431469338420686, 0:00:12.870827 per 50 iters\n",
            "time = 0:03:14.193317, epoch 45, iter = 450, loss = 0.5464598327875138, perplexity = 1.7271278607998137, 0:00:13.012817 per 50 iters\n",
            "time = 0:03:14.409371, epoch 45, iter = 500, loss = 0.5458547097444534, perplexity = 1.726083052083729, 0:00:12.963088 per 50 iters\n",
            "time = 0:03:14.624020, epoch 45, iter = 550, loss = 0.5577841658890247, perplexity = 1.7467975951117969, 0:00:12.878828 per 50 iters\n",
            "time = 0:03:14.840081, epoch 45, iter = 600, loss = 0.5574881756305694, perplexity = 1.746280636551274, 0:00:12.963509 per 50 iters\n",
            "time = 0:03:15.058767, epoch 45, iter = 650, loss = 0.5789325767755509, perplexity = 1.7841329889866482, 0:00:13.120985 per 50 iters\n",
            "time = 0:03:15.277602, epoch 45, iter = 700, loss = 0.574253904223442, perplexity = 1.7758051118382943, 0:00:13.129963 per 50 iters\n",
            "time = 0:03:15.494743, epoch 45, iter = 750, loss = 0.5901528894901276, perplexity = 1.8042642473522492, 0:00:13.028232 per 50 iters\n",
            "time = 0:03:15.712938, epoch 45, iter = 800, loss = 0.5786596250534057, perplexity = 1.783646073270033, 0:00:13.091587 per 50 iters\n",
            "time = 0:03:15.931495, epoch 45, iter = 850, loss = 0.6064923417568207, perplexity = 1.833987103215298, 0:00:13.113283 per 50 iters\n",
            "time = 0:03:16.146547, epoch 45, iter = 900, loss = 0.5600975096225739, perplexity = 1.7508432160339338, 0:00:12.902981 per 50 iters\n",
            "time = 0:03:16.362706, epoch 45, iter = 950, loss = 0.5821819823980331, perplexity = 1.7899397899688732, 0:00:12.969390 per 50 iters\n",
            "time = 0:03:16.581860, epoch 45, iter = 1000, loss = 0.5945663076639175, perplexity = 1.8122448178152277, 0:00:13.149077 per 50 iters\n",
            "\n",
            "time = 0:03:16.825182, epoch 46, iter = 50, loss = 0.5146431440114975, perplexity = 1.6730413604286483, 0:00:14.599208 per 50 iters\n",
            "time = 0:03:17.042159, epoch 46, iter = 100, loss = 0.5057678109407425, perplexity = 1.6582582606214957, 0:00:13.018452 per 50 iters\n",
            "time = 0:03:17.260207, epoch 46, iter = 150, loss = 0.5205184322595596, perplexity = 1.6828998931740031, 0:00:13.082612 per 50 iters\n",
            "time = 0:03:17.474372, epoch 46, iter = 200, loss = 0.47261452555656436, perplexity = 1.6041828922701702, 0:00:12.849779 per 50 iters\n",
            "time = 0:03:17.693866, epoch 46, iter = 250, loss = 0.4997463268041611, perplexity = 1.6483030873495381, 0:00:13.169481 per 50 iters\n",
            "time = 0:03:17.910986, epoch 46, iter = 300, loss = 0.5255246484279632, perplexity = 1.69134597765157, 0:00:13.027021 per 50 iters\n",
            "time = 0:03:18.128647, epoch 46, iter = 350, loss = 0.5258101105690003, perplexity = 1.6918288618148793, 0:00:13.059497 per 50 iters\n",
            "time = 0:03:18.346532, epoch 46, iter = 400, loss = 0.5465618824958801, perplexity = 1.727304122687904, 0:00:13.072968 per 50 iters\n",
            "time = 0:03:18.566379, epoch 46, iter = 450, loss = 0.5521669626235962, perplexity = 1.7370129847568923, 0:00:13.190655 per 50 iters\n",
            "time = 0:03:18.779419, epoch 46, iter = 500, loss = 0.5631233698129654, perplexity = 1.7561490461226967, 0:00:12.782222 per 50 iters\n",
            "time = 0:03:18.995120, epoch 46, iter = 550, loss = 0.5422552168369293, perplexity = 1.7198811968430476, 0:00:12.941890 per 50 iters\n",
            "time = 0:03:19.211628, epoch 46, iter = 600, loss = 0.5439426499605179, perplexity = 1.722785831342242, 0:00:12.990366 per 50 iters\n",
            "time = 0:03:19.429722, epoch 46, iter = 650, loss = 0.5363800501823426, perplexity = 1.7098062332109596, 0:00:13.085511 per 50 iters\n",
            "time = 0:03:19.646563, epoch 46, iter = 700, loss = 0.5523248076438904, perplexity = 1.737287185246744, 0:00:13.009507 per 50 iters\n",
            "time = 0:03:19.862621, epoch 46, iter = 750, loss = 0.5730537885427475, perplexity = 1.7736752185924973, 0:00:12.963326 per 50 iters\n",
            "time = 0:03:20.078058, epoch 46, iter = 800, loss = 0.5984931200742721, perplexity = 1.8193751538400278, 0:00:12.926056 per 50 iters\n",
            "time = 0:03:20.297154, epoch 46, iter = 850, loss = 0.564795052409172, perplexity = 1.7590872250865301, 0:00:13.145618 per 50 iters\n",
            "time = 0:03:20.511535, epoch 46, iter = 900, loss = 0.5700461298227311, perplexity = 1.7683486231607892, 0:00:12.862729 per 50 iters\n",
            "time = 0:03:20.726950, epoch 46, iter = 950, loss = 0.5583206403255463, perplexity = 1.7477349587806934, 0:00:12.924718 per 50 iters\n",
            "time = 0:03:20.944606, epoch 46, iter = 1000, loss = 0.5960270142555237, perplexity = 1.81489391006845, 0:00:13.059240 per 50 iters\n",
            "\n",
            "time = 0:03:21.189841, epoch 47, iter = 50, loss = 0.519590231180191, perplexity = 1.6813385484097363, 0:00:14.713940 per 50 iters\n",
            "time = 0:03:21.406214, epoch 47, iter = 100, loss = 0.4831091225147247, perplexity = 1.621106794610645, 0:00:12.982202 per 50 iters\n",
            "time = 0:03:21.624365, epoch 47, iter = 150, loss = 0.5130391991138459, perplexity = 1.670360045190814, 0:00:13.088814 per 50 iters\n",
            "time = 0:03:21.839703, epoch 47, iter = 200, loss = 0.49875327944755554, perplexity = 1.6466670567881196, 0:00:12.920109 per 50 iters\n",
            "time = 0:03:22.059999, epoch 47, iter = 250, loss = 0.4979034399986267, perplexity = 1.645268248629375, 0:00:13.217618 per 50 iters\n",
            "time = 0:03:22.274853, epoch 47, iter = 300, loss = 0.5187502181529999, perplexity = 1.6799267951545303, 0:00:12.891091 per 50 iters\n",
            "time = 0:03:22.489887, epoch 47, iter = 350, loss = 0.5005959255993366, perplexity = 1.649704078722654, 0:00:12.901824 per 50 iters\n",
            "time = 0:03:22.709748, epoch 47, iter = 400, loss = 0.5435357886552811, perplexity = 1.7220850390225646, 0:00:13.191527 per 50 iters\n",
            "time = 0:03:22.926100, epoch 47, iter = 450, loss = 0.5401973354816437, perplexity = 1.7163455246394719, 0:00:12.980978 per 50 iters\n",
            "time = 0:03:23.143253, epoch 47, iter = 500, loss = 0.5398338860273362, perplexity = 1.7157218331421713, 0:00:13.029039 per 50 iters\n",
            "time = 0:03:23.359873, epoch 47, iter = 550, loss = 0.5429882788658142, perplexity = 1.7211424386704122, 0:00:12.997072 per 50 iters\n",
            "time = 0:03:23.578112, epoch 47, iter = 600, loss = 0.5525362199544906, perplexity = 1.737654507971658, 0:00:13.094224 per 50 iters\n",
            "time = 0:03:23.794206, epoch 47, iter = 650, loss = 0.5222092485427856, perplexity = 1.6857477746601413, 0:00:12.965404 per 50 iters\n",
            "time = 0:03:24.010027, epoch 47, iter = 700, loss = 0.5407833820581436, perplexity = 1.7173516778558047, 0:00:12.948490 per 50 iters\n",
            "time = 0:03:24.220870, epoch 47, iter = 750, loss = 0.5547579336166382, perplexity = 1.7415193704512473, 0:00:12.650352 per 50 iters\n",
            "time = 0:03:24.439156, epoch 47, iter = 800, loss = 0.549995858669281, perplexity = 1.7332458399082917, 0:00:13.097003 per 50 iters\n",
            "time = 0:03:24.656986, epoch 47, iter = 850, loss = 0.5472488266229629, perplexity = 1.7284910917547083, 0:00:13.069649 per 50 iters\n",
            "time = 0:03:24.876079, epoch 47, iter = 900, loss = 0.5531261241436005, perplexity = 1.7386798600451439, 0:00:13.144679 per 50 iters\n",
            "time = 0:03:25.091254, epoch 47, iter = 950, loss = 0.5516447967290878, perplexity = 1.7361062125812892, 0:00:12.909712 per 50 iters\n",
            "time = 0:03:25.308461, epoch 47, iter = 1000, loss = 0.5701266026496887, perplexity = 1.7684909328994982, 0:00:13.032228 per 50 iters\n",
            "\n",
            "time = 0:03:25.553559, epoch 48, iter = 50, loss = 0.49708689212799073, perplexity = 1.6439253566867245, 0:00:14.705779 per 50 iters\n",
            "time = 0:03:25.769065, epoch 48, iter = 100, loss = 0.5028460091352462, perplexity = 1.6534202299668088, 0:00:12.929612 per 50 iters\n",
            "time = 0:03:25.984769, epoch 48, iter = 150, loss = 0.4746890711784363, perplexity = 1.6075142972470242, 0:00:12.942128 per 50 iters\n",
            "time = 0:03:26.201210, epoch 48, iter = 200, loss = 0.49543472766876223, perplexity = 1.641211564071944, 0:00:12.985616 per 50 iters\n",
            "time = 0:03:26.417782, epoch 48, iter = 250, loss = 0.5049049019813537, perplexity = 1.6568279519132765, 0:00:12.994153 per 50 iters\n",
            "time = 0:03:26.634422, epoch 48, iter = 300, loss = 0.494649276137352, perplexity = 1.6399229780627504, 0:00:12.998277 per 50 iters\n",
            "time = 0:03:26.850253, epoch 48, iter = 350, loss = 0.49902747094631195, perplexity = 1.6471186208010509, 0:00:12.949727 per 50 iters\n",
            "time = 0:03:27.067562, epoch 48, iter = 400, loss = 0.5027553004026413, perplexity = 1.6532702571153115, 0:00:13.038400 per 50 iters\n",
            "time = 0:03:27.283831, epoch 48, iter = 450, loss = 0.5198026306927204, perplexity = 1.6816957018260785, 0:00:12.975981 per 50 iters\n",
            "time = 0:03:27.500255, epoch 48, iter = 500, loss = 0.5109120178222656, perplexity = 1.6668106629805814, 0:00:12.985273 per 50 iters\n",
            "time = 0:03:27.716020, epoch 48, iter = 550, loss = 0.4971333682537079, perplexity = 1.6440017617437632, 0:00:12.945644 per 50 iters\n",
            "time = 0:03:27.936331, epoch 48, iter = 600, loss = 0.5249711483716964, perplexity = 1.6904100765923116, 0:00:13.218500 per 50 iters\n",
            "time = 0:03:28.151732, epoch 48, iter = 650, loss = 0.5366375434398651, perplexity = 1.710246553474998, 0:00:12.923946 per 50 iters\n",
            "time = 0:03:28.370270, epoch 48, iter = 700, loss = 0.5437263613939285, perplexity = 1.7224132527579368, 0:00:13.111434 per 50 iters\n",
            "time = 0:03:28.585905, epoch 48, iter = 750, loss = 0.5527574622631073, perplexity = 1.7380389931972111, 0:00:12.937958 per 50 iters\n",
            "time = 0:03:28.803656, epoch 48, iter = 800, loss = 0.552448313832283, perplexity = 1.7375017642157797, 0:00:13.064915 per 50 iters\n",
            "time = 0:03:29.021066, epoch 48, iter = 850, loss = 0.5554938644170762, perplexity = 1.7428014799095763, 0:00:13.044447 per 50 iters\n",
            "time = 0:03:29.238036, epoch 48, iter = 900, loss = 0.545942941904068, perplexity = 1.72623535483799, 0:00:13.018031 per 50 iters\n",
            "time = 0:03:29.454620, epoch 48, iter = 950, loss = 0.5510025739669799, perplexity = 1.73499160360607, 0:00:12.994856 per 50 iters\n",
            "time = 0:03:29.669851, epoch 48, iter = 1000, loss = 0.5506815373897552, perplexity = 1.734434697238575, 0:00:12.913756 per 50 iters\n",
            "\n",
            "time = 0:03:29.917806, epoch 49, iter = 50, loss = 0.49397037386894227, perplexity = 1.6388100084744635, 0:00:14.877115 per 50 iters\n",
            "time = 0:03:30.132237, epoch 49, iter = 100, loss = 0.47491869926452634, perplexity = 1.6078834700630649, 0:00:12.865740 per 50 iters\n",
            "time = 0:03:30.353334, epoch 49, iter = 150, loss = 0.46667312443256376, perplexity = 1.5946800562655485, 0:00:13.265689 per 50 iters\n",
            "time = 0:03:30.570099, epoch 49, iter = 200, loss = 0.4853680604696274, perplexity = 1.6247729134865236, 0:00:13.005722 per 50 iters\n",
            "time = 0:03:30.789066, epoch 49, iter = 250, loss = 0.4795163494348526, perplexity = 1.6152929758788241, 0:00:13.137903 per 50 iters\n",
            "time = 0:03:31.001346, epoch 49, iter = 300, loss = 0.4759626698493957, perplexity = 1.6095629296103582, 0:00:12.736649 per 50 iters\n",
            "time = 0:03:31.218956, epoch 49, iter = 350, loss = 0.48570668160915376, perplexity = 1.6253231891041802, 0:00:13.056439 per 50 iters\n",
            "time = 0:03:31.433932, epoch 49, iter = 400, loss = 0.5087179118394851, perplexity = 1.6631575128975526, 0:00:12.898422 per 50 iters\n",
            "time = 0:03:31.650806, epoch 49, iter = 450, loss = 0.5386579102277755, perplexity = 1.7137053716749449, 0:00:13.012265 per 50 iters\n",
            "time = 0:03:31.867215, epoch 49, iter = 500, loss = 0.4912459516525269, perplexity = 1.6343512745736437, 0:00:12.984450 per 50 iters\n",
            "time = 0:03:32.086213, epoch 49, iter = 550, loss = 0.5197385799884796, perplexity = 1.6815879914815564, 0:00:13.139678 per 50 iters\n",
            "time = 0:03:32.301573, epoch 49, iter = 600, loss = 0.5213286691904068, perplexity = 1.684263993365922, 0:00:12.921484 per 50 iters\n",
            "time = 0:03:32.517687, epoch 49, iter = 650, loss = 0.5242242187261581, perplexity = 1.68914793061879, 0:00:12.966711 per 50 iters\n",
            "time = 0:03:32.734075, epoch 49, iter = 700, loss = 0.5160972368717194, perplexity = 1.675475887510967, 0:00:12.983083 per 50 iters\n",
            "time = 0:03:32.953290, epoch 49, iter = 750, loss = 0.5197929549217224, perplexity = 1.6816794302022997, 0:00:13.152756 per 50 iters\n",
            "time = 0:03:33.169076, epoch 49, iter = 800, loss = 0.5125361543893814, perplexity = 1.6695199906923315, 0:00:12.946301 per 50 iters\n",
            "time = 0:03:33.386122, epoch 49, iter = 850, loss = 0.546508122086525, perplexity = 1.727211264607254, 0:00:13.022607 per 50 iters\n",
            "time = 0:03:33.600916, epoch 49, iter = 900, loss = 0.5636648905277252, perplexity = 1.7571002947465493, 0:00:12.887532 per 50 iters\n",
            "time = 0:03:33.817442, epoch 49, iter = 950, loss = 0.5404851377010346, perplexity = 1.7168395637800753, 0:00:12.991374 per 50 iters\n",
            "time = 0:03:34.033284, epoch 49, iter = 1000, loss = 0.5537826770544052, perplexity = 1.7398217701894092, 0:00:12.950361 per 50 iters\n",
            "\n",
            "time = 0:03:34.280096, epoch 50, iter = 50, loss = 0.4936879378557205, perplexity = 1.6383472148671092, 0:00:14.808566 per 50 iters\n",
            "time = 0:03:34.495531, epoch 50, iter = 100, loss = 0.4484811818599701, perplexity = 1.5659320124761418, 0:00:12.925923 per 50 iters\n",
            "time = 0:03:34.709258, epoch 50, iter = 150, loss = 0.45379880726337435, perplexity = 1.5742812316613806, 0:00:12.823464 per 50 iters\n",
            "time = 0:03:34.923502, epoch 50, iter = 200, loss = 0.4739110416173935, perplexity = 1.6062640900161245, 0:00:12.854497 per 50 iters\n",
            "time = 0:03:35.138761, epoch 50, iter = 250, loss = 0.4598738804459572, perplexity = 1.5838742148876466, 0:00:12.915316 per 50 iters\n",
            "time = 0:03:35.357703, epoch 50, iter = 300, loss = 0.4880524790287018, perplexity = 1.6291403434320901, 0:00:13.136371 per 50 iters\n",
            "time = 0:03:35.575427, epoch 50, iter = 350, loss = 0.4734855788946152, perplexity = 1.6055808298840502, 0:00:13.063256 per 50 iters\n",
            "time = 0:03:35.789197, epoch 50, iter = 400, loss = 0.4830229598283768, perplexity = 1.620967121711747, 0:00:12.826047 per 50 iters\n",
            "time = 0:03:36.010899, epoch 50, iter = 450, loss = 0.5225318104028702, perplexity = 1.6862916203051852, 0:00:13.302004 per 50 iters\n",
            "time = 0:03:36.226931, epoch 50, iter = 500, loss = 0.5084161299467087, perplexity = 1.6626556778015065, 0:00:12.960842 per 50 iters\n",
            "time = 0:03:36.444730, epoch 50, iter = 550, loss = 0.5288808161020279, perplexity = 1.6970319545561947, 0:00:13.067811 per 50 iters\n",
            "time = 0:03:36.666305, epoch 50, iter = 600, loss = 0.525976316332817, perplexity = 1.6921100768922406, 0:00:13.294378 per 50 iters\n",
            "time = 0:03:36.877587, epoch 50, iter = 650, loss = 0.5159310048818588, perplexity = 1.675197392968215, 0:00:12.676684 per 50 iters\n",
            "time = 0:03:37.093982, epoch 50, iter = 700, loss = 0.5253059953451157, perplexity = 1.6909762000673725, 0:00:12.983588 per 50 iters\n",
            "time = 0:03:37.311110, epoch 50, iter = 750, loss = 0.5050723230838776, perplexity = 1.6571053630972734, 0:00:13.027576 per 50 iters\n",
            "time = 0:03:37.530288, epoch 50, iter = 800, loss = 0.5298787307739258, perplexity = 1.6987262929042677, 0:00:13.150520 per 50 iters\n",
            "time = 0:03:37.748910, epoch 50, iter = 850, loss = 0.5116802453994751, perplexity = 1.6680916448776795, 0:00:13.117154 per 50 iters\n",
            "time = 0:03:37.966292, epoch 50, iter = 900, loss = 0.5391306936740875, perplexity = 1.714515774764016, 0:00:13.042742 per 50 iters\n",
            "time = 0:03:38.180723, epoch 50, iter = 950, loss = 0.5353560370206832, perplexity = 1.7080562652722837, 0:00:12.865710 per 50 iters\n",
            "time = 0:03:38.397845, epoch 50, iter = 1000, loss = 0.5307654398679733, perplexity = 1.7002332369682498, 0:00:13.027166 per 50 iters\n",
            "\n",
            "time = 0:03:38.646581, epoch 51, iter = 50, loss = 0.4727938026189804, perplexity = 1.6044705112476467, 0:00:14.923996 per 50 iters\n",
            "time = 0:03:38.862325, epoch 51, iter = 100, loss = 0.4324799120426178, perplexity = 1.5410745179425183, 0:00:12.944499 per 50 iters\n",
            "time = 0:03:39.077988, epoch 51, iter = 150, loss = 0.4493431186676025, perplexity = 1.5672823287760054, 0:00:12.939693 per 50 iters\n",
            "time = 0:03:39.294523, epoch 51, iter = 200, loss = 0.4365016168355942, perplexity = 1.5472847441956008, 0:00:12.991932 per 50 iters\n",
            "time = 0:03:39.512737, epoch 51, iter = 250, loss = 0.4633458375930786, perplexity = 1.5893829157411048, 0:00:13.092709 per 50 iters\n",
            "time = 0:03:39.729323, epoch 51, iter = 300, loss = 0.46367427945137024, perplexity = 1.5899050213554633, 0:00:12.994953 per 50 iters\n",
            "time = 0:03:39.945571, epoch 51, iter = 350, loss = 0.47965578496456146, perplexity = 1.6155182208137593, 0:00:12.973998 per 50 iters\n",
            "time = 0:03:40.164989, epoch 51, iter = 400, loss = 0.5003564125299453, perplexity = 1.6493090003502773, 0:00:13.164286 per 50 iters\n",
            "time = 0:03:40.377827, epoch 51, iter = 450, loss = 0.502480480670929, perplexity = 1.652815968253434, 0:00:12.770022 per 50 iters\n",
            "time = 0:03:40.596097, epoch 51, iter = 500, loss = 0.4905238914489746, perplexity = 1.6331716005087509, 0:00:13.095341 per 50 iters\n",
            "time = 0:03:40.812538, epoch 51, iter = 550, loss = 0.48135274171829223, perplexity = 1.6182620127590477, 0:00:12.986357 per 50 iters\n",
            "time = 0:03:41.025766, epoch 51, iter = 600, loss = 0.49478867173194885, perplexity = 1.6401515920348906, 0:00:12.793509 per 50 iters\n",
            "time = 0:03:41.244282, epoch 51, iter = 650, loss = 0.5086377447843552, perplexity = 1.663024187801738, 0:00:13.110824 per 50 iters\n",
            "time = 0:03:41.464447, epoch 51, iter = 700, loss = 0.4920574355125427, perplexity = 1.6356780625152485, 0:00:13.209717 per 50 iters\n",
            "time = 0:03:41.679231, epoch 51, iter = 750, loss = 0.5447559371590615, perplexity = 1.7241875209155373, 0:00:12.886816 per 50 iters\n",
            "time = 0:03:41.895208, epoch 51, iter = 800, loss = 0.5059651786088943, perplexity = 1.658585579487606, 0:00:12.958527 per 50 iters\n",
            "time = 0:03:42.111276, epoch 51, iter = 850, loss = 0.5374629950523376, perplexity = 1.7116588620662994, 0:00:12.963933 per 50 iters\n",
            "time = 0:03:42.327086, epoch 51, iter = 900, loss = 0.5462634253501892, perplexity = 1.726788673353301, 0:00:12.948392 per 50 iters\n",
            "time = 0:03:42.545217, epoch 51, iter = 950, loss = 0.5293508613109589, perplexity = 1.6978298237984537, 0:00:13.087694 per 50 iters\n",
            "time = 0:03:42.761338, epoch 51, iter = 1000, loss = 0.544845488667488, perplexity = 1.7243419314225892, 0:00:12.967138 per 50 iters\n",
            "\n",
            "time = 0:03:43.003430, epoch 52, iter = 50, loss = 0.49719732865691185, perplexity = 1.6441069161221347, 0:00:14.525307 per 50 iters\n",
            "time = 0:03:43.221183, epoch 52, iter = 100, loss = 0.4548413115739822, perplexity = 1.5759232824052687, 0:00:13.065061 per 50 iters\n",
            "time = 0:03:43.437882, epoch 52, iter = 150, loss = 0.4482408279180527, perplexity = 1.5655556797725045, 0:00:13.001141 per 50 iters\n",
            "time = 0:03:43.654125, epoch 52, iter = 200, loss = 0.4546298432350159, perplexity = 1.5755900597606616, 0:00:12.974409 per 50 iters\n",
            "time = 0:03:43.869112, epoch 52, iter = 250, loss = 0.4477859824895859, perplexity = 1.5648437558484947, 0:00:12.899130 per 50 iters\n",
            "time = 0:03:44.089157, epoch 52, iter = 300, loss = 0.4497195452451706, perplexity = 1.5678724065526208, 0:00:13.202506 per 50 iters\n",
            "time = 0:03:44.303397, epoch 52, iter = 350, loss = 0.4665954768657684, perplexity = 1.5945562380465164, 0:00:12.853522 per 50 iters\n",
            "time = 0:03:44.521457, epoch 52, iter = 400, loss = 0.47262036442756655, perplexity = 1.6041922589144875, 0:00:13.083464 per 50 iters\n",
            "time = 0:03:44.739065, epoch 52, iter = 450, loss = 0.48516995191574097, perplexity = 1.624451063955864, 0:00:13.056378 per 50 iters\n",
            "time = 0:03:44.955817, epoch 52, iter = 500, loss = 0.4860181999206543, perplexity = 1.6258295859115366, 0:00:13.004994 per 50 iters\n",
            "time = 0:03:45.171297, epoch 52, iter = 550, loss = 0.5010758227109909, perplexity = 1.6504959569399544, 0:00:12.928655 per 50 iters\n",
            "time = 0:03:45.386751, epoch 52, iter = 600, loss = 0.48459913790225984, perplexity = 1.6235240691203352, 0:00:12.927036 per 50 iters\n",
            "time = 0:03:45.606624, epoch 52, iter = 650, loss = 0.4809826797246933, perplexity = 1.6176632662859305, 0:00:13.192310 per 50 iters\n",
            "time = 0:03:45.825597, epoch 52, iter = 700, loss = 0.4974455416202545, perplexity = 1.6445150554224748, 0:00:13.138209 per 50 iters\n",
            "time = 0:03:46.044585, epoch 52, iter = 750, loss = 0.5131653732061386, perplexity = 1.6705708146498612, 0:00:13.139119 per 50 iters\n",
            "time = 0:03:46.261186, epoch 52, iter = 800, loss = 0.5047226792573929, perplexity = 1.65652606771666, 0:00:12.995942 per 50 iters\n",
            "time = 0:03:46.476512, epoch 52, iter = 850, loss = 0.493269767165184, perplexity = 1.6376622493071717, 0:00:12.919363 per 50 iters\n",
            "time = 0:03:46.690221, epoch 52, iter = 900, loss = 0.5229332309961319, perplexity = 1.6869686683692464, 0:00:12.822297 per 50 iters\n",
            "time = 0:03:46.907253, epoch 52, iter = 950, loss = 0.5130766785144806, perplexity = 1.6704226504573487, 0:00:13.021748 per 50 iters\n",
            "time = 0:03:47.126520, epoch 52, iter = 1000, loss = 0.519427125453949, perplexity = 1.68106433482825, 0:00:13.155737 per 50 iters\n",
            "\n",
            "time = 0:03:47.371712, epoch 53, iter = 50, loss = 0.4732836866378784, perplexity = 1.6052567082668547, 0:00:14.711374 per 50 iters\n",
            "time = 0:03:47.590788, epoch 53, iter = 100, loss = 0.4356110262870789, perplexity = 1.545907360460066, 0:00:13.143666 per 50 iters\n",
            "time = 0:03:47.806150, epoch 53, iter = 150, loss = 0.44534617617726324, perplexity = 1.561030493877077, 0:00:12.921548 per 50 iters\n",
            "time = 0:03:48.022776, epoch 53, iter = 200, loss = 0.45263723433017733, perplexity = 1.572453650833143, 0:00:12.997435 per 50 iters\n",
            "time = 0:03:48.239728, epoch 53, iter = 250, loss = 0.4582622277736664, perplexity = 1.5813236156687562, 0:00:13.016922 per 50 iters\n",
            "time = 0:03:48.457402, epoch 53, iter = 300, loss = 0.45788711190223697, perplexity = 1.5807305473242816, 0:00:13.060333 per 50 iters\n",
            "time = 0:03:48.673418, epoch 53, iter = 350, loss = 0.4773297280073166, perplexity = 1.6117648004437983, 0:00:12.960770 per 50 iters\n",
            "time = 0:03:48.889193, epoch 53, iter = 400, loss = 0.4748180466890335, perplexity = 1.6077216405951238, 0:00:12.946424 per 50 iters\n",
            "time = 0:03:49.100886, epoch 53, iter = 450, loss = 0.4674731570482254, perplexity = 1.5959563627974573, 0:00:12.701312 per 50 iters\n",
            "time = 0:03:49.316372, epoch 53, iter = 500, loss = 0.4732301568984985, perplexity = 1.6051707815934602, 0:00:12.929048 per 50 iters\n",
            "time = 0:03:49.537194, epoch 53, iter = 550, loss = 0.47074242413043976, perplexity = 1.6011825085773845, 0:00:13.249135 per 50 iters\n",
            "time = 0:03:49.756423, epoch 53, iter = 600, loss = 0.47665763199329375, perplexity = 1.6106819036919362, 0:00:13.153620 per 50 iters\n",
            "time = 0:03:49.969590, epoch 53, iter = 650, loss = 0.47468515515327453, perplexity = 1.6075080021929142, 0:00:12.789846 per 50 iters\n",
            "time = 0:03:50.184832, epoch 53, iter = 700, loss = 0.48328471958637237, perplexity = 1.621391481210942, 0:00:12.914355 per 50 iters\n",
            "time = 0:03:50.400889, epoch 53, iter = 750, loss = 0.5050419235229492, perplexity = 1.6570549885875083, 0:00:12.963314 per 50 iters\n",
            "time = 0:03:50.616923, epoch 53, iter = 800, loss = 0.4678161984682083, perplexity = 1.596503935849131, 0:00:12.961243 per 50 iters\n",
            "time = 0:03:50.838200, epoch 53, iter = 850, loss = 0.5282107573747635, perplexity = 1.6958952243651209, 0:00:13.276422 per 50 iters\n",
            "time = 0:03:51.054819, epoch 53, iter = 900, loss = 0.5022626805305481, perplexity = 1.6524560239029127, 0:00:12.997000 per 50 iters\n",
            "time = 0:03:51.273263, epoch 53, iter = 950, loss = 0.5011610734462738, perplexity = 1.65063666893168, 0:00:13.106503 per 50 iters\n",
            "time = 0:03:51.490479, epoch 53, iter = 1000, loss = 0.5165650570392608, perplexity = 1.6762598922936998, 0:00:13.031979 per 50 iters\n",
            "\n",
            "time = 0:03:51.734383, epoch 54, iter = 50, loss = 0.45593582272529604, perplexity = 1.577649092298276, 0:00:14.634055 per 50 iters\n",
            "time = 0:03:51.953500, epoch 54, iter = 100, loss = 0.4082380932569504, perplexity = 1.5041652501425333, 0:00:13.146878 per 50 iters\n",
            "time = 0:03:52.171554, epoch 54, iter = 150, loss = 0.41145154893398284, perplexity = 1.5090065930591439, 0:00:13.083020 per 50 iters\n",
            "time = 0:03:52.392516, epoch 54, iter = 200, loss = 0.44326516568660734, perplexity = 1.5577853508025952, 0:00:13.257491 per 50 iters\n",
            "time = 0:03:52.606038, epoch 54, iter = 250, loss = 0.4248169821500778, perplexity = 1.5293105029291711, 0:00:12.811136 per 50 iters\n",
            "time = 0:03:52.820530, epoch 54, iter = 300, loss = 0.4428852051496506, perplexity = 1.557193566278743, 0:00:12.869345 per 50 iters\n",
            "time = 0:03:53.037070, epoch 54, iter = 350, loss = 0.4838642758131027, perplexity = 1.6223314410933367, 0:00:12.992307 per 50 iters\n",
            "time = 0:03:53.255152, epoch 54, iter = 400, loss = 0.47205413997173307, perplexity = 1.603284183137249, 0:00:13.084710 per 50 iters\n",
            "time = 0:03:53.467550, epoch 54, iter = 450, loss = 0.47789264887571337, perplexity = 1.612672351900777, 0:00:12.743810 per 50 iters\n",
            "time = 0:03:53.687743, epoch 54, iter = 500, loss = 0.4562894809246063, perplexity = 1.578207139508571, 0:00:13.211361 per 50 iters\n",
            "time = 0:03:53.907273, epoch 54, iter = 550, loss = 0.46341745734214784, perplexity = 1.5894967510230835, 0:00:13.171668 per 50 iters\n",
            "time = 0:03:54.125680, epoch 54, iter = 600, loss = 0.49283911764621735, perplexity = 1.6369571426850889, 0:00:13.104295 per 50 iters\n",
            "time = 0:03:54.340880, epoch 54, iter = 650, loss = 0.4642327833175659, perplexity = 1.5907932374697529, 0:00:12.911827 per 50 iters\n",
            "time = 0:03:54.558866, epoch 54, iter = 700, loss = 0.4739102303981781, perplexity = 1.606262786984358, 0:00:13.078194 per 50 iters\n",
            "time = 0:03:54.773996, epoch 54, iter = 750, loss = 0.49494692385196687, perplexity = 1.640411170040324, 0:00:12.907692 per 50 iters\n",
            "time = 0:03:54.989679, epoch 54, iter = 800, loss = 0.5091409146785736, perplexity = 1.6638611820638949, 0:00:12.940808 per 50 iters\n",
            "time = 0:03:55.206083, epoch 54, iter = 850, loss = 0.4913860511779785, perplexity = 1.6345802624518047, 0:00:12.984116 per 50 iters\n",
            "time = 0:03:55.422323, epoch 54, iter = 900, loss = 0.48447700798511506, perplexity = 1.6233258003678106, 0:00:12.974227 per 50 iters\n",
            "time = 0:03:55.639359, epoch 54, iter = 950, loss = 0.5181205934286117, perplexity = 1.678869404623681, 0:00:13.021374 per 50 iters\n",
            "time = 0:03:55.853591, epoch 54, iter = 1000, loss = 0.5271247893571853, perplexity = 1.6940545360355226, 0:00:12.852875 per 50 iters\n",
            "\n",
            "time = 0:03:56.099001, epoch 55, iter = 50, loss = 0.4594641476869583, perplexity = 1.5832253826686584, 0:00:14.724492 per 50 iters\n",
            "time = 0:03:56.319129, epoch 55, iter = 100, loss = 0.43105884194374083, perplexity = 1.5388860983420396, 0:00:13.207466 per 50 iters\n",
            "time = 0:03:56.535586, epoch 55, iter = 150, loss = 0.4396338242292404, perplexity = 1.5521387588332658, 0:00:12.987279 per 50 iters\n",
            "time = 0:03:56.750657, epoch 55, iter = 200, loss = 0.4049490681290627, perplexity = 1.4992261397199418, 0:00:12.904093 per 50 iters\n",
            "time = 0:03:56.967766, epoch 55, iter = 250, loss = 0.4194212782382965, perplexity = 1.5210810181635905, 0:00:13.025662 per 50 iters\n",
            "time = 0:03:57.185257, epoch 55, iter = 300, loss = 0.446691774725914, perplexity = 1.563132428106709, 0:00:13.049426 per 50 iters\n",
            "time = 0:03:57.404507, epoch 55, iter = 350, loss = 0.4474577611684799, perplexity = 1.5643302250441153, 0:00:13.154754 per 50 iters\n",
            "time = 0:03:57.621896, epoch 55, iter = 400, loss = 0.4483796501159668, perplexity = 1.565773028739009, 0:00:13.043110 per 50 iters\n",
            "time = 0:03:57.836390, epoch 55, iter = 450, loss = 0.4864139771461487, perplexity = 1.6264731795856338, 0:00:12.869519 per 50 iters\n",
            "time = 0:03:58.051187, epoch 55, iter = 500, loss = 0.45093748390674593, perplexity = 1.569783142316263, 0:00:12.886651 per 50 iters\n",
            "time = 0:03:58.267828, epoch 55, iter = 550, loss = 0.4611082696914673, perplexity = 1.5858305393692882, 0:00:12.998289 per 50 iters\n",
            "time = 0:03:58.482869, epoch 55, iter = 600, loss = 0.5002114897966385, perplexity = 1.6490699953009298, 0:00:12.902349 per 50 iters\n",
            "time = 0:03:58.703042, epoch 55, iter = 650, loss = 0.4509494411945343, perplexity = 1.5698019127772826, 0:00:13.210192 per 50 iters\n",
            "time = 0:03:58.919868, epoch 55, iter = 700, loss = 0.4580374085903168, perplexity = 1.5809681437448213, 0:00:13.009381 per 50 iters\n",
            "time = 0:03:59.130054, epoch 55, iter = 750, loss = 0.5115608090162277, perplexity = 1.6678924259419214, 0:00:12.610999 per 50 iters\n",
            "time = 0:03:59.345695, epoch 55, iter = 800, loss = 0.4838497674465179, perplexity = 1.622307903884811, 0:00:12.938265 per 50 iters\n",
            "time = 0:03:59.562637, epoch 55, iter = 850, loss = 0.4703787785768509, perplexity = 1.6006003515334817, 0:00:13.016320 per 50 iters\n",
            "time = 0:03:59.784087, epoch 55, iter = 900, loss = 0.4981904637813568, perplexity = 1.6457405475229674, 0:00:13.286750 per 50 iters\n",
            "time = 0:04:00.000310, epoch 55, iter = 950, loss = 0.49716030597686767, perplexity = 1.644046048004578, 0:00:12.972410 per 50 iters\n",
            "time = 0:04:00.219361, epoch 55, iter = 1000, loss = 0.4877916938066483, perplexity = 1.6287155430991038, 0:00:13.142882 per 50 iters\n",
            "\n",
            "time = 0:04:00.461968, epoch 56, iter = 50, loss = 0.46226556062698365, perplexity = 1.587666869056663, 0:00:14.556299 per 50 iters\n",
            "time = 0:04:00.681145, epoch 56, iter = 100, loss = 0.417006738781929, perplexity = 1.5174127384141716, 0:00:13.150463 per 50 iters\n",
            "time = 0:04:00.907498, epoch 56, iter = 150, loss = 0.42124788999557494, perplexity = 1.5238619817322907, 0:00:13.581039 per 50 iters\n",
            "time = 0:04:01.123859, epoch 56, iter = 200, loss = 0.41665070831775664, perplexity = 1.5168725894130284, 0:00:12.981496 per 50 iters\n",
            "time = 0:04:01.340587, epoch 56, iter = 250, loss = 0.4330628061294556, perplexity = 1.541973063019268, 0:00:13.003543 per 50 iters\n",
            "time = 0:04:01.558658, epoch 56, iter = 300, loss = 0.4219966971874237, perplexity = 1.5250034878742629, 0:00:13.083999 per 50 iters\n",
            "time = 0:04:01.775140, epoch 56, iter = 350, loss = 0.44972249746322635, perplexity = 1.567877035260681, 0:00:12.988746 per 50 iters\n",
            "time = 0:04:01.992348, epoch 56, iter = 400, loss = 0.4556127601861954, perplexity = 1.577139495296991, 0:00:13.032364 per 50 iters\n",
            "time = 0:04:02.210420, epoch 56, iter = 450, loss = 0.4453471854329109, perplexity = 1.5610320693567141, 0:00:13.084115 per 50 iters\n",
            "time = 0:04:02.423551, epoch 56, iter = 500, loss = 0.44090435564517977, perplexity = 1.5541120531890473, 0:00:12.787657 per 50 iters\n",
            "time = 0:04:02.640690, epoch 56, iter = 550, loss = 0.44023767054080964, perplexity = 1.5530762951332615, 0:00:13.027353 per 50 iters\n",
            "time = 0:04:02.856436, epoch 56, iter = 600, loss = 0.46616062700748445, perplexity = 1.5938629962313526, 0:00:12.944608 per 50 iters\n",
            "time = 0:04:03.075610, epoch 56, iter = 650, loss = 0.48919516563415527, perplexity = 1.631003004297066, 0:00:13.150320 per 50 iters\n",
            "time = 0:04:03.286195, epoch 56, iter = 700, loss = 0.4931920957565308, perplexity = 1.6375350547131255, 0:00:12.634969 per 50 iters\n",
            "time = 0:04:03.500763, epoch 56, iter = 750, loss = 0.4760351552069187, perplexity = 1.6096796035832928, 0:00:12.873855 per 50 iters\n",
            "time = 0:04:03.719495, epoch 56, iter = 800, loss = 0.4757547527551651, perplexity = 1.609228308750956, 0:00:13.123817 per 50 iters\n",
            "time = 0:04:03.937496, epoch 56, iter = 850, loss = 0.4846075564622879, perplexity = 1.6235377369126995, 0:00:13.079906 per 50 iters\n",
            "time = 0:04:04.156034, epoch 56, iter = 900, loss = 0.47915940165519716, perplexity = 1.6147165035289748, 0:00:13.112134 per 50 iters\n",
            "time = 0:04:04.375726, epoch 56, iter = 950, loss = 0.5014236414432526, perplexity = 1.6510701301996193, 0:00:13.181405 per 50 iters\n",
            "time = 0:04:04.594897, epoch 56, iter = 1000, loss = 0.4748212569952011, perplexity = 1.607726801882107, 0:00:13.150063 per 50 iters\n",
            "\n",
            "time = 0:04:04.839535, epoch 57, iter = 50, loss = 0.44834126353263853, perplexity = 1.56571292521576, 0:00:14.677285 per 50 iters\n",
            "time = 0:04:05.059073, epoch 57, iter = 100, loss = 0.41100637793540956, perplexity = 1.5083349765904368, 0:00:13.172153 per 50 iters\n",
            "time = 0:04:05.279860, epoch 57, iter = 150, loss = 0.39622325003147124, perplexity = 1.4862010749543426, 0:00:13.247009 per 50 iters\n",
            "time = 0:04:05.496732, epoch 57, iter = 200, loss = 0.41224089950323106, perplexity = 1.5101981985077224, 0:00:13.011459 per 50 iters\n",
            "time = 0:04:05.712735, epoch 57, iter = 250, loss = 0.40653777837753297, perplexity = 1.501609868678825, 0:00:12.960073 per 50 iters\n",
            "time = 0:04:05.928536, epoch 57, iter = 300, loss = 0.42851419508457184, perplexity = 1.5349751547607788, 0:00:12.947942 per 50 iters\n",
            "time = 0:04:06.147291, epoch 57, iter = 350, loss = 0.426763282418251, perplexity = 1.5322898988301459, 0:00:13.125143 per 50 iters\n",
            "time = 0:04:06.364999, epoch 57, iter = 400, loss = 0.436434201002121, perplexity = 1.5471804362209944, 0:00:13.062338 per 50 iters\n",
            "time = 0:04:06.580399, epoch 57, iter = 450, loss = 0.4380930697917938, perplexity = 1.5497491355371413, 0:00:12.923850 per 50 iters\n",
            "time = 0:04:06.799654, epoch 57, iter = 500, loss = 0.4431086206436157, perplexity = 1.557541506314703, 0:00:13.154361 per 50 iters\n",
            "time = 0:04:07.017125, epoch 57, iter = 550, loss = 0.4455040591955185, perplexity = 1.5612769735400034, 0:00:13.047002 per 50 iters\n",
            "time = 0:04:07.231379, epoch 57, iter = 600, loss = 0.4611057883501053, perplexity = 1.5858266043872598, 0:00:12.855007 per 50 iters\n",
            "time = 0:04:07.448766, epoch 57, iter = 650, loss = 0.46354694247245787, perplexity = 1.5897025805426606, 0:00:13.043016 per 50 iters\n",
            "time = 0:04:07.663143, epoch 57, iter = 700, loss = 0.47343012273311613, perplexity = 1.605491793003093, 0:00:12.862505 per 50 iters\n",
            "time = 0:04:07.878887, epoch 57, iter = 750, loss = 0.47787638902664187, perplexity = 1.6126461303049135, 0:00:12.943812 per 50 iters\n",
            "time = 0:04:08.093845, epoch 57, iter = 800, loss = 0.5273093801736831, perplexity = 1.694367271808709, 0:00:12.897360 per 50 iters\n",
            "time = 0:04:08.310573, epoch 57, iter = 850, loss = 0.484547016620636, perplexity = 1.6234394511703225, 0:00:13.003509 per 50 iters\n",
            "time = 0:04:08.524322, epoch 57, iter = 900, loss = 0.487280079126358, perplexity = 1.627882481438696, 0:00:12.824765 per 50 iters\n",
            "time = 0:04:08.743198, epoch 57, iter = 950, loss = 0.4663358497619629, perplexity = 1.5941423017654415, 0:00:13.132425 per 50 iters\n",
            "time = 0:04:08.959796, epoch 57, iter = 1000, loss = 0.4822341525554657, perplexity = 1.6196889952209994, 0:00:12.995712 per 50 iters\n",
            "\n",
            "time = 0:04:09.198969, epoch 58, iter = 50, loss = 0.4615354961156845, perplexity = 1.5865081928254616, 0:00:14.350224 per 50 iters\n",
            "time = 0:04:09.418087, epoch 58, iter = 100, loss = 0.3977079892158508, perplexity = 1.4884093348655374, 0:00:13.146890 per 50 iters\n",
            "time = 0:04:09.638765, epoch 58, iter = 150, loss = 0.42631784081459045, perplexity = 1.5316075051548879, 0:00:13.240480 per 50 iters\n",
            "time = 0:04:09.858077, epoch 58, iter = 200, loss = 0.40600128889083864, perplexity = 1.500804486829927, 0:00:13.158586 per 50 iters\n",
            "time = 0:04:10.075622, epoch 58, iter = 250, loss = 0.410111118555069, perplexity = 1.5069852298308228, 0:00:13.052540 per 50 iters\n",
            "time = 0:04:10.293302, epoch 58, iter = 300, loss = 0.40740168452262876, perplexity = 1.502907679184432, 0:00:13.060658 per 50 iters\n",
            "time = 0:04:10.510599, epoch 58, iter = 350, loss = 0.4324378252029419, perplexity = 1.541009660351188, 0:00:13.037692 per 50 iters\n",
            "time = 0:04:10.727077, epoch 58, iter = 400, loss = 0.44516788721084594, perplexity = 1.5607522041725068, 0:00:12.988539 per 50 iters\n",
            "time = 0:04:10.942676, epoch 58, iter = 450, loss = 0.4296390914916992, perplexity = 1.536702814334242, 0:00:12.935823 per 50 iters\n",
            "time = 0:04:11.160283, epoch 58, iter = 500, loss = 0.44946598291397094, perplexity = 1.5674749035682132, 0:00:13.056207 per 50 iters\n",
            "time = 0:04:11.373863, epoch 58, iter = 550, loss = 0.43779445230960845, perplexity = 1.5492864224428164, 0:00:12.814645 per 50 iters\n",
            "time = 0:04:11.590235, epoch 58, iter = 600, loss = 0.468242489695549, perplexity = 1.5971846565537222, 0:00:12.982196 per 50 iters\n",
            "time = 0:04:11.808359, epoch 58, iter = 650, loss = 0.43793159604072573, perplexity = 1.5494989119338274, 0:00:13.086458 per 50 iters\n",
            "time = 0:04:12.025561, epoch 58, iter = 700, loss = 0.46817136228084566, perplexity = 1.5970710569783675, 0:00:13.031947 per 50 iters\n",
            "time = 0:04:12.246535, epoch 58, iter = 750, loss = 0.44622544705867767, perplexity = 1.5624036661420684, 0:00:13.258310 per 50 iters\n",
            "time = 0:04:12.463623, epoch 58, iter = 800, loss = 0.4731284910440445, perplexity = 1.6050075988296029, 0:00:13.025103 per 50 iters\n",
            "time = 0:04:12.679799, epoch 58, iter = 850, loss = 0.4638992381095886, perplexity = 1.590262724488462, 0:00:12.970406 per 50 iters\n",
            "time = 0:04:12.896204, epoch 58, iter = 900, loss = 0.4728237211704254, perplexity = 1.6045185153992834, 0:00:12.984196 per 50 iters\n",
            "time = 0:04:13.109818, epoch 58, iter = 950, loss = 0.48116817981004717, perplexity = 1.6179633707937457, 0:00:12.816679 per 50 iters\n",
            "time = 0:04:13.325354, epoch 58, iter = 1000, loss = 0.480219447016716, perplexity = 1.6164290838147342, 0:00:12.931983 per 50 iters\n",
            "\n",
            "time = 0:04:13.568037, epoch 59, iter = 50, loss = 0.4242850708961487, perplexity = 1.5284972617671484, 0:00:14.560819 per 50 iters\n",
            "time = 0:04:13.784706, epoch 59, iter = 100, loss = 0.40146260321140287, perplexity = 1.4940082416748939, 0:00:12.999943 per 50 iters\n",
            "time = 0:04:14.001399, epoch 59, iter = 150, loss = 0.3964264088869095, perplexity = 1.4865030405361337, 0:00:13.001463 per 50 iters\n",
            "time = 0:04:14.218981, epoch 59, iter = 200, loss = 0.41134815812110903, perplexity = 1.5088505837059616, 0:00:13.054807 per 50 iters\n",
            "time = 0:04:14.436081, epoch 59, iter = 250, loss = 0.4093536972999573, perplexity = 1.5058442393463796, 0:00:13.025834 per 50 iters\n",
            "time = 0:04:14.654940, epoch 59, iter = 300, loss = 0.42263628721237184, perplexity = 1.5259791768803355, 0:00:13.130716 per 50 iters\n",
            "time = 0:04:14.874344, epoch 59, iter = 350, loss = 0.40819052517414095, perplexity = 1.5040937015870828, 0:00:13.164095 per 50 iters\n",
            "time = 0:04:15.092612, epoch 59, iter = 400, loss = 0.42018312752246856, perplexity = 1.5222402941891795, 0:00:13.095878 per 50 iters\n",
            "time = 0:04:15.310111, epoch 59, iter = 450, loss = 0.44507508993148803, perplexity = 1.5606073773340798, 0:00:13.049841 per 50 iters\n",
            "time = 0:04:15.530194, epoch 59, iter = 500, loss = 0.4303416359424591, perplexity = 1.537782795691954, 0:00:13.204816 per 50 iters\n",
            "time = 0:04:15.745061, epoch 59, iter = 550, loss = 0.4385113763809204, perplexity = 1.5503975414188014, 0:00:12.891930 per 50 iters\n",
            "time = 0:04:15.959887, epoch 59, iter = 600, loss = 0.4260720324516296, perplexity = 1.53123106948876, 0:00:12.889417 per 50 iters\n",
            "time = 0:04:16.175800, epoch 59, iter = 650, loss = 0.4599521800875664, perplexity = 1.583998236526388, 0:00:12.954614 per 50 iters\n",
            "time = 0:04:16.393662, epoch 59, iter = 700, loss = 0.4503465282917023, perplexity = 1.5688557442064601, 0:00:13.071579 per 50 iters\n",
            "time = 0:04:16.613217, epoch 59, iter = 750, loss = 0.46818891286849973, perplexity = 1.5970990867599117, 0:00:13.173097 per 50 iters\n",
            "time = 0:04:16.828601, epoch 59, iter = 800, loss = 0.4737188458442688, perplexity = 1.6059554025126683, 0:00:12.922811 per 50 iters\n",
            "time = 0:04:17.045078, epoch 59, iter = 850, loss = 0.47643705844879153, perplexity = 1.610326669054495, 0:00:12.988520 per 50 iters\n",
            "time = 0:04:17.261254, epoch 59, iter = 900, loss = 0.49595858752727506, perplexity = 1.642071554167166, 0:00:12.970366 per 50 iters\n",
            "time = 0:04:17.475860, epoch 59, iter = 950, loss = 0.46494882345199584, perplexity = 1.5919327171812785, 0:00:12.876192 per 50 iters\n",
            "time = 0:04:17.688246, epoch 59, iter = 1000, loss = 0.4613006073236465, perplexity = 1.5861355835950697, 0:00:12.742309 per 50 iters\n",
            "\n",
            "time = 0:04:17.935221, epoch 60, iter = 50, loss = 0.4283062541484833, perplexity = 1.5346560037736527, 0:00:14.818319 per 50 iters\n",
            "time = 0:04:18.152553, epoch 60, iter = 100, loss = 0.3948492527008057, perplexity = 1.484160440878447, 0:00:13.039748 per 50 iters\n",
            "time = 0:04:18.372111, epoch 60, iter = 150, loss = 0.409992915391922, perplexity = 1.5068071099372158, 0:00:13.172737 per 50 iters\n",
            "time = 0:04:18.591271, epoch 60, iter = 200, loss = 0.39684701651334764, perplexity = 1.4871284065593466, 0:00:13.149436 per 50 iters\n",
            "time = 0:04:18.806413, epoch 60, iter = 250, loss = 0.4273816156387329, perplexity = 1.5332376575631592, 0:00:12.908290 per 50 iters\n",
            "time = 0:04:19.022471, epoch 60, iter = 300, loss = 0.4219694435596466, perplexity = 1.5249619265631964, 0:00:12.963345 per 50 iters\n",
            "time = 0:04:19.241641, epoch 60, iter = 350, loss = 0.4093723031878471, perplexity = 1.5058722571761238, 0:00:13.149156 per 50 iters\n",
            "time = 0:04:19.458925, epoch 60, iter = 400, loss = 0.4220614022016525, perplexity = 1.5251021664391093, 0:00:13.036820 per 50 iters\n",
            "time = 0:04:19.674489, epoch 60, iter = 450, loss = 0.4218712341785431, perplexity = 1.5248121683501334, 0:00:12.933654 per 50 iters\n",
            "time = 0:04:19.889835, epoch 60, iter = 500, loss = 0.42206462323665617, perplexity = 1.5251070788544832, 0:00:12.920585 per 50 iters\n",
            "time = 0:04:20.108126, epoch 60, iter = 550, loss = 0.44298570036888124, perplexity = 1.5573500646511083, 0:00:13.096181 per 50 iters\n",
            "time = 0:04:20.326847, epoch 60, iter = 600, loss = 0.4357446813583374, perplexity = 1.5461139926268983, 0:00:13.123074 per 50 iters\n",
            "time = 0:04:20.545132, epoch 60, iter = 650, loss = 0.44612310349941253, perplexity = 1.5622437723720548, 0:00:13.096186 per 50 iters\n",
            "time = 0:04:20.764566, epoch 60, iter = 700, loss = 0.4378855901956558, perplexity = 1.5494276275667103, 0:00:13.165903 per 50 iters\n",
            "time = 0:04:20.981690, epoch 60, iter = 750, loss = 0.47460980772972106, perplexity = 1.6073868851695925, 0:00:13.027216 per 50 iters\n",
            "time = 0:04:21.199170, epoch 60, iter = 800, loss = 0.44216040551662444, perplexity = 1.5560653218783094, 0:00:13.048619 per 50 iters\n",
            "time = 0:04:21.415390, epoch 60, iter = 850, loss = 0.4541056472063065, perplexity = 1.574764358142123, 0:00:12.972982 per 50 iters\n",
            "time = 0:04:21.629272, epoch 60, iter = 900, loss = 0.44899040400981904, perplexity = 1.5667296228052399, 0:00:12.832716 per 50 iters\n",
            "time = 0:04:21.846504, epoch 60, iter = 950, loss = 0.4532232826948166, perplexity = 1.573375454808158, 0:00:13.033734 per 50 iters\n",
            "time = 0:04:22.061011, epoch 60, iter = 1000, loss = 0.46389887034893035, perplexity = 1.5902621396525032, 0:00:12.870248 per 50 iters\n",
            "\n",
            "time = 0:04:22.307714, epoch 61, iter = 50, loss = 0.4132495492696762, perplexity = 1.5117222280447424, 0:00:14.801965 per 50 iters\n",
            "time = 0:04:22.523025, epoch 61, iter = 100, loss = 0.36745803236961366, perplexity = 1.4440591935153448, 0:00:12.918537 per 50 iters\n",
            "time = 0:04:22.739179, epoch 61, iter = 150, loss = 0.39275536835193636, perplexity = 1.481056031831074, 0:00:12.969060 per 50 iters\n",
            "time = 0:04:22.957636, epoch 61, iter = 200, loss = 0.4137013179063797, perplexity = 1.5124053310254135, 0:00:13.107226 per 50 iters\n",
            "time = 0:04:23.172375, epoch 61, iter = 250, loss = 0.38761894047260287, perplexity = 1.4734681982008315, 0:00:12.884125 per 50 iters\n",
            "time = 0:04:23.388240, epoch 61, iter = 300, loss = 0.41812318325042724, perplexity = 1.5191077915126643, 0:00:12.951801 per 50 iters\n",
            "time = 0:04:23.607476, epoch 61, iter = 350, loss = 0.4050626939535141, perplexity = 1.4993965002045986, 0:00:13.153238 per 50 iters\n",
            "time = 0:04:23.824000, epoch 61, iter = 400, loss = 0.4275710105895996, perplexity = 1.533528072534677, 0:00:12.990461 per 50 iters\n",
            "time = 0:04:24.039710, epoch 61, iter = 450, loss = 0.4186330679059029, perplexity = 1.5198825587697526, 0:00:12.941834 per 50 iters\n",
            "time = 0:04:24.258308, epoch 61, iter = 500, loss = 0.4258650416135788, perplexity = 1.53091415148713, 0:00:13.115722 per 50 iters\n",
            "time = 0:04:24.475029, epoch 61, iter = 550, loss = 0.43532219231128694, perplexity = 1.545460914368442, 0:00:13.003023 per 50 iters\n",
            "time = 0:04:24.690381, epoch 61, iter = 600, loss = 0.4297618520259857, perplexity = 1.5368914723724132, 0:00:12.920958 per 50 iters\n",
            "time = 0:04:24.908501, epoch 61, iter = 650, loss = 0.43433538138866423, perplexity = 1.54393658889187, 0:00:13.087034 per 50 iters\n",
            "time = 0:04:25.124134, epoch 61, iter = 700, loss = 0.4441083955764771, perplexity = 1.5590994759493284, 0:00:12.937875 per 50 iters\n",
            "time = 0:04:25.341289, epoch 61, iter = 750, loss = 0.45556589305400846, perplexity = 1.5770655810238763, 0:00:13.029097 per 50 iters\n",
            "time = 0:04:25.557586, epoch 61, iter = 800, loss = 0.45967825591564176, perplexity = 1.5835644005429115, 0:00:12.977683 per 50 iters\n",
            "time = 0:04:25.769509, epoch 61, iter = 850, loss = 0.47812740445137025, perplexity = 1.6130509801679032, 0:00:12.715169 per 50 iters\n",
            "time = 0:04:25.987976, epoch 61, iter = 900, loss = 0.45514584362506866, perplexity = 1.5764032746376144, 0:00:13.107813 per 50 iters\n",
            "time = 0:04:26.205394, epoch 61, iter = 950, loss = 0.47899313032627105, perplexity = 1.6144480447892082, 0:00:13.044968 per 50 iters\n",
            "time = 0:04:26.425806, epoch 61, iter = 1000, loss = 0.45508012652397156, perplexity = 1.5762996813882066, 0:00:13.224547 per 50 iters\n",
            "\n",
            "time = 0:04:26.674767, epoch 62, iter = 50, loss = 0.4196513348817825, perplexity = 1.5214309932125984, 0:00:14.937499 per 50 iters\n",
            "time = 0:04:26.893649, epoch 62, iter = 100, loss = 0.37841209411621096, perplexity = 1.4599644616906418, 0:00:13.132736 per 50 iters\n",
            "time = 0:04:27.109565, epoch 62, iter = 150, loss = 0.37799881517887113, perplexity = 1.4593612137927716, 0:00:12.954800 per 50 iters\n",
            "time = 0:04:27.325193, epoch 62, iter = 200, loss = 0.4016771012544632, perplexity = 1.494328737890726, 0:00:12.937556 per 50 iters\n",
            "time = 0:04:27.542791, epoch 62, iter = 250, loss = 0.41110120952129364, perplexity = 1.5084780211707762, 0:00:13.055758 per 50 iters\n",
            "time = 0:04:27.758651, epoch 62, iter = 300, loss = 0.40274092197418215, perplexity = 1.4959192816408606, 0:00:12.951432 per 50 iters\n",
            "time = 0:04:27.972371, epoch 62, iter = 350, loss = 0.42234654009342193, perplexity = 1.5255370928596355, 0:00:12.822897 per 50 iters\n",
            "time = 0:04:28.186277, epoch 62, iter = 400, loss = 0.4009603278338909, perplexity = 1.4932580265443667, 0:00:12.834242 per 50 iters\n",
            "time = 0:04:28.407250, epoch 62, iter = 450, loss = 0.4126006174087524, perplexity = 1.5107415415598653, 0:00:13.258127 per 50 iters\n",
            "time = 0:04:28.622904, epoch 62, iter = 500, loss = 0.4354011398553848, perplexity = 1.5455829295284658, 0:00:12.938329 per 50 iters\n",
            "time = 0:04:28.836463, epoch 62, iter = 550, loss = 0.4272173011302948, perplexity = 1.5329857450681437, 0:00:12.813276 per 50 iters\n",
            "time = 0:04:29.051353, epoch 62, iter = 600, loss = 0.41596299290657046, perplexity = 1.5158297713786, 0:00:12.893273 per 50 iters\n",
            "time = 0:04:29.269445, epoch 62, iter = 650, loss = 0.42024782598018645, perplexity = 1.522338783974524, 0:00:13.085391 per 50 iters\n",
            "time = 0:04:29.484546, epoch 62, iter = 700, loss = 0.42983067393302915, perplexity = 1.5369972478142526, 0:00:12.905901 per 50 iters\n",
            "time = 0:04:29.704639, epoch 62, iter = 750, loss = 0.43244085103273394, perplexity = 1.5410143231911826, 0:00:13.204730 per 50 iters\n",
            "time = 0:04:29.922380, epoch 62, iter = 800, loss = 0.4524161601066589, perplexity = 1.5721060602863373, 0:00:13.064232 per 50 iters\n",
            "time = 0:04:30.138153, epoch 62, iter = 850, loss = 0.451990881562233, perplexity = 1.5714376194561817, 0:00:12.946291 per 50 iters\n",
            "time = 0:04:30.353791, epoch 62, iter = 900, loss = 0.44258614897727966, perplexity = 1.5567279475577176, 0:00:12.938133 per 50 iters\n",
            "time = 0:04:30.571598, epoch 62, iter = 950, loss = 0.4466382962465286, perplexity = 1.5630488363965744, 0:00:13.068202 per 50 iters\n",
            "time = 0:04:30.789777, epoch 62, iter = 1000, loss = 0.46423578917980196, perplexity = 1.5907980191822575, 0:00:13.090621 per 50 iters\n",
            "\n",
            "time = 0:04:31.035671, epoch 63, iter = 50, loss = 0.4200181448459625, perplexity = 1.5219891716271647, 0:00:14.753484 per 50 iters\n",
            "time = 0:04:31.251311, epoch 63, iter = 100, loss = 0.3728500312566757, perplexity = 1.451866588897455, 0:00:12.937642 per 50 iters\n",
            "time = 0:04:31.468284, epoch 63, iter = 150, loss = 0.37882382214069366, perplexity = 1.4605656937378166, 0:00:13.018180 per 50 iters\n",
            "time = 0:04:31.685303, epoch 63, iter = 200, loss = 0.357836848795414, perplexity = 1.430232257328055, 0:00:13.021022 per 50 iters\n",
            "time = 0:04:31.900683, epoch 63, iter = 250, loss = 0.4136363074183464, perplexity = 1.5123070120126576, 0:00:12.922666 per 50 iters\n",
            "time = 0:04:32.111386, epoch 63, iter = 300, loss = 0.41986960992217065, perplexity = 1.5217631198702508, 0:00:12.641344 per 50 iters\n",
            "time = 0:04:32.327400, epoch 63, iter = 350, loss = 0.3854227191209793, perplexity = 1.4702356868375468, 0:00:12.960658 per 50 iters\n",
            "time = 0:04:32.545230, epoch 63, iter = 400, loss = 0.39243407011032105, perplexity = 1.480580247570729, 0:00:13.068987 per 50 iters\n",
            "time = 0:04:32.761416, epoch 63, iter = 450, loss = 0.4112438297271728, perplexity = 1.5086931759590652, 0:00:12.971050 per 50 iters\n",
            "time = 0:04:32.979890, epoch 63, iter = 500, loss = 0.4161466735601425, perplexity = 1.5161082255542504, 0:00:13.108202 per 50 iters\n",
            "time = 0:04:33.199953, epoch 63, iter = 550, loss = 0.4288190591335297, perplexity = 1.5354431848406567, 0:00:13.203146 per 50 iters\n",
            "time = 0:04:33.418698, epoch 63, iter = 600, loss = 0.4505008274316788, perplexity = 1.5690978359753338, 0:00:13.124531 per 50 iters\n",
            "time = 0:04:33.637394, epoch 63, iter = 650, loss = 0.42776595175266263, perplexity = 1.533827049421231, 0:00:13.121599 per 50 iters\n",
            "time = 0:04:33.851939, epoch 63, iter = 700, loss = 0.4292308884859085, perplexity = 1.5360756556391646, 0:00:12.872477 per 50 iters\n",
            "time = 0:04:34.070786, epoch 63, iter = 750, loss = 0.4426466453075409, perplexity = 1.5568221267344786, 0:00:13.130742 per 50 iters\n",
            "time = 0:04:34.286987, epoch 63, iter = 800, loss = 0.4131742024421692, perplexity = 1.5116083288618123, 0:00:12.971835 per 50 iters\n",
            "time = 0:04:34.505542, epoch 63, iter = 850, loss = 0.43841028422117234, perplexity = 1.5502408163048447, 0:00:13.113170 per 50 iters\n",
            "time = 0:04:34.719758, epoch 63, iter = 900, loss = 0.4679880064725876, perplexity = 1.5967782515684763, 0:00:12.852836 per 50 iters\n",
            "time = 0:04:34.936135, epoch 63, iter = 950, loss = 0.4443133234977722, perplexity = 1.5594190117038078, 0:00:12.982465 per 50 iters\n",
            "time = 0:04:35.153536, epoch 63, iter = 1000, loss = 0.4483499455451965, perplexity = 1.5657265188140488, 0:00:13.043913 per 50 iters\n",
            "\n",
            "time = 0:04:35.399998, epoch 64, iter = 50, loss = 0.3949541699886322, perplexity = 1.484316163135439, 0:00:14.787179 per 50 iters\n",
            "time = 0:04:35.618739, epoch 64, iter = 100, loss = 0.4071988153457642, perplexity = 1.5026028164653225, 0:00:13.124308 per 50 iters\n",
            "time = 0:04:35.835509, epoch 64, iter = 150, loss = 0.3702226239442825, perplexity = 1.4480569509320695, 0:00:13.006076 per 50 iters\n",
            "time = 0:04:36.054508, epoch 64, iter = 200, loss = 0.37597548186779023, perplexity = 1.4564114248454636, 0:00:13.139742 per 50 iters\n",
            "time = 0:04:36.268147, epoch 64, iter = 250, loss = 0.39325770318508146, perplexity = 1.4818002047620462, 0:00:12.817412 per 50 iters\n",
            "time = 0:04:36.482134, epoch 64, iter = 300, loss = 0.41154146790504453, perplexity = 1.5091422874799771, 0:00:12.839005 per 50 iters\n",
            "time = 0:04:36.699615, epoch 64, iter = 350, loss = 0.39801522314548493, perplexity = 1.4888666949690657, 0:00:13.048771 per 50 iters\n",
            "time = 0:04:36.917335, epoch 64, iter = 400, loss = 0.3928982400894165, perplexity = 1.4812676479962719, 0:00:13.063043 per 50 iters\n",
            "time = 0:04:37.135676, epoch 64, iter = 450, loss = 0.4022999060153961, perplexity = 1.495259702817685, 0:00:13.100345 per 50 iters\n",
            "time = 0:04:37.351259, epoch 64, iter = 500, loss = 0.41441285610198975, perplexity = 1.5134818481317833, 0:00:12.934787 per 50 iters\n",
            "time = 0:04:37.569113, epoch 64, iter = 550, loss = 0.4133052808046341, perplexity = 1.5118064809926925, 0:00:13.071098 per 50 iters\n",
            "time = 0:04:37.785218, epoch 64, iter = 600, loss = 0.3917695109546184, perplexity = 1.4795966412799364, 0:00:12.966171 per 50 iters\n",
            "time = 0:04:38.000980, epoch 64, iter = 650, loss = 0.422399994134903, perplexity = 1.5256186411622017, 0:00:12.945539 per 50 iters\n",
            "time = 0:04:38.216976, epoch 64, iter = 700, loss = 0.4626317322254181, perplexity = 1.588248334023368, 0:00:12.959596 per 50 iters\n",
            "time = 0:04:38.435001, epoch 64, iter = 750, loss = 0.42200526893138884, perplexity = 1.5250165598697318, 0:00:13.081313 per 50 iters\n",
            "time = 0:04:38.655911, epoch 64, iter = 800, loss = 0.4124435794353485, perplexity = 1.5105043163970084, 0:00:13.254518 per 50 iters\n",
            "time = 0:04:38.870932, epoch 64, iter = 850, loss = 0.4453808242082596, perplexity = 1.5610845814470236, 0:00:12.901081 per 50 iters\n",
            "time = 0:04:39.084995, epoch 64, iter = 900, loss = 0.4308552435040474, perplexity = 1.5385728154265899, 0:00:12.843617 per 50 iters\n",
            "time = 0:04:39.299482, epoch 64, iter = 950, loss = 0.43128864258527755, perplexity = 1.5392397759908094, 0:00:12.869074 per 50 iters\n",
            "time = 0:04:39.516995, epoch 64, iter = 1000, loss = 0.4351947754621506, perplexity = 1.5452640091530572, 0:00:13.050648 per 50 iters\n",
            "\n",
            "time = 0:04:39.757979, epoch 65, iter = 50, loss = 0.3959547594189644, perplexity = 1.4858020974806696, 0:00:14.458926 per 50 iters\n",
            "time = 0:04:39.971032, epoch 65, iter = 100, loss = 0.3668700337409973, perplexity = 1.443210338277232, 0:00:12.782980 per 50 iters\n",
            "time = 0:04:40.187820, epoch 65, iter = 150, loss = 0.3884157878160477, perplexity = 1.474642795345373, 0:00:13.006489 per 50 iters\n",
            "time = 0:04:40.405531, epoch 65, iter = 200, loss = 0.37847103357315065, perplexity = 1.4600505137390705, 0:00:13.062468 per 50 iters\n",
            "time = 0:04:40.623465, epoch 65, iter = 250, loss = 0.3674166324734688, perplexity = 1.443999410852213, 0:00:13.075899 per 50 iters\n",
            "time = 0:04:40.842546, epoch 65, iter = 300, loss = 0.3989241629838943, perplexity = 1.4902206004382998, 0:00:13.144723 per 50 iters\n",
            "time = 0:04:41.061947, epoch 65, iter = 350, loss = 0.3863081818819046, perplexity = 1.4715381023231349, 0:00:13.163897 per 50 iters\n",
            "time = 0:04:41.280089, epoch 65, iter = 400, loss = 0.38136430978775027, perplexity = 1.46428096013645, 0:00:13.088348 per 50 iters\n",
            "time = 0:04:41.498800, epoch 65, iter = 450, loss = 0.39537777841091154, perplexity = 1.4849450651581608, 0:00:13.122569 per 50 iters\n",
            "time = 0:04:41.712776, epoch 65, iter = 500, loss = 0.39229866564273835, perplexity = 1.4803797839627337, 0:00:12.838386 per 50 iters\n",
            "time = 0:04:41.926804, epoch 65, iter = 550, loss = 0.4095192837715149, perplexity = 1.5060936074261089, 0:00:12.841449 per 50 iters\n",
            "time = 0:04:42.147780, epoch 65, iter = 600, loss = 0.39626827895641326, perplexity = 1.4862679984977318, 0:00:13.258367 per 50 iters\n",
            "time = 0:04:42.364767, epoch 65, iter = 650, loss = 0.4531977427005768, perplexity = 1.5733352713212503, 0:00:13.019043 per 50 iters\n",
            "time = 0:04:42.581151, epoch 65, iter = 700, loss = 0.419043527841568, perplexity = 1.5205065377174625, 0:00:12.982946 per 50 iters\n",
            "time = 0:04:42.798730, epoch 65, iter = 750, loss = 0.4286666852235794, perplexity = 1.5352092411829836, 0:00:13.053825 per 50 iters\n",
            "time = 0:04:43.012630, epoch 65, iter = 800, loss = 0.4652526068687439, perplexity = 1.592416393404025, 0:00:12.833763 per 50 iters\n",
            "time = 0:04:43.230944, epoch 65, iter = 850, loss = 0.435758011341095, perplexity = 1.5461346024371252, 0:00:13.098677 per 50 iters\n",
            "time = 0:04:43.446629, epoch 65, iter = 900, loss = 0.43520777493715285, perplexity = 1.5452840969044808, 0:00:12.940844 per 50 iters\n",
            "time = 0:04:43.662357, epoch 65, iter = 950, loss = 0.4288217115402222, perplexity = 1.535447257465837, 0:00:12.943575 per 50 iters\n",
            "time = 0:04:43.882237, epoch 65, iter = 1000, loss = 0.4512881761789322, perplexity = 1.5703337496745113, 0:00:13.192587 per 50 iters\n",
            "\n",
            "time = 0:04:44.126001, epoch 66, iter = 50, loss = 0.3781513857841492, perplexity = 1.4595838864026947, 0:00:14.624883 per 50 iters\n",
            "time = 0:04:44.344183, epoch 66, iter = 100, loss = 0.37784605026245116, perplexity = 1.4591382916266966, 0:00:13.090762 per 50 iters\n",
            "time = 0:04:44.561582, epoch 66, iter = 150, loss = 0.3771018972992897, perplexity = 1.4580528734519844, 0:00:13.043042 per 50 iters\n",
            "time = 0:04:44.777026, epoch 66, iter = 200, loss = 0.3688581255078316, perplexity = 1.4460824269104577, 0:00:12.926480 per 50 iters\n",
            "time = 0:04:44.996250, epoch 66, iter = 250, loss = 0.35667762756347654, perplexity = 1.4285752623262074, 0:00:13.153274 per 50 iters\n",
            "time = 0:04:45.216750, epoch 66, iter = 300, loss = 0.3858484238386154, perplexity = 1.4708617063457454, 0:00:13.229832 per 50 iters\n",
            "time = 0:04:45.430398, epoch 66, iter = 350, loss = 0.38294292241334915, perplexity = 1.466594318015112, 0:00:12.818764 per 50 iters\n",
            "time = 0:04:45.650713, epoch 66, iter = 400, loss = 0.4040431973338127, perplexity = 1.4978686494927, 0:00:13.218718 per 50 iters\n",
            "time = 0:04:45.866230, epoch 66, iter = 450, loss = 0.4171412020921707, perplexity = 1.5176167884722973, 0:00:12.930858 per 50 iters\n",
            "time = 0:04:46.083995, epoch 66, iter = 500, loss = 0.3912091314792633, perplexity = 1.4787677379622532, 0:00:13.065691 per 50 iters\n",
            "time = 0:04:46.302033, epoch 66, iter = 550, loss = 0.42009745180606844, perplexity = 1.5221098807481541, 0:00:13.082134 per 50 iters\n",
            "time = 0:04:46.518041, epoch 66, iter = 600, loss = 0.40237406015396115, perplexity = 1.4953705866240743, 0:00:12.960364 per 50 iters\n",
            "time = 0:04:46.731499, epoch 66, iter = 650, loss = 0.4192748373746872, perplexity = 1.52085828605461, 0:00:12.807304 per 50 iters\n",
            "time = 0:04:46.949022, epoch 66, iter = 700, loss = 0.4162182551622391, perplexity = 1.516216754894293, 0:00:13.051313 per 50 iters\n",
            "time = 0:04:47.166344, epoch 66, iter = 750, loss = 0.4271811431646347, perplexity = 1.5329303164243155, 0:00:13.039159 per 50 iters\n",
            "time = 0:04:47.381476, epoch 66, iter = 800, loss = 0.43142002284526826, perplexity = 1.539442014997583, 0:00:12.906895 per 50 iters\n",
            "time = 0:04:47.600036, epoch 66, iter = 850, loss = 0.4218202906847, perplexity = 1.524734491069416, 0:00:13.113483 per 50 iters\n",
            "time = 0:04:47.816883, epoch 66, iter = 900, loss = 0.4383479118347168, perplexity = 1.5501441271009506, 0:00:13.010668 per 50 iters\n",
            "time = 0:04:48.030502, epoch 66, iter = 950, loss = 0.44190610349178316, perplexity = 1.5556696616269043, 0:00:12.816232 per 50 iters\n",
            "time = 0:04:48.247364, epoch 66, iter = 1000, loss = 0.4614898353815079, perplexity = 1.5864357533504323, 0:00:13.011642 per 50 iters\n",
            "\n",
            "time = 0:04:48.493722, epoch 67, iter = 50, loss = 0.3876901662349701, perplexity = 1.4735731508341934, 0:00:14.781299 per 50 iters\n",
            "time = 0:04:48.711896, epoch 67, iter = 100, loss = 0.3718618780374527, perplexity = 1.450432630855563, 0:00:13.090306 per 50 iters\n",
            "time = 0:04:48.930014, epoch 67, iter = 150, loss = 0.34773205339908597, perplexity = 1.4158528259575274, 0:00:13.086906 per 50 iters\n",
            "time = 0:04:49.145398, epoch 67, iter = 200, loss = 0.3641659617424011, perplexity = 1.4393130652415953, 0:00:12.922900 per 50 iters\n",
            "time = 0:04:49.363346, epoch 67, iter = 250, loss = 0.42701072335243223, perplexity = 1.532669096986787, 0:00:13.076733 per 50 iters\n",
            "time = 0:04:49.580181, epoch 67, iter = 300, loss = 0.3766240686178207, perplexity = 1.4573563403949397, 0:00:13.009929 per 50 iters\n",
            "time = 0:04:49.794081, epoch 67, iter = 350, loss = 0.37175774335861206, perplexity = 1.4502815983833643, 0:00:12.833832 per 50 iters\n",
            "time = 0:04:50.010237, epoch 67, iter = 400, loss = 0.3961545181274414, perplexity = 1.4860989290350717, 0:00:12.969170 per 50 iters\n",
            "time = 0:04:50.224831, epoch 67, iter = 450, loss = 0.39357702910900116, perplexity = 1.4822734575384149, 0:00:12.875445 per 50 iters\n",
            "time = 0:04:50.445448, epoch 67, iter = 500, loss = 0.3955303943157196, perplexity = 1.485171708687134, 0:00:13.236825 per 50 iters\n",
            "time = 0:04:50.661398, epoch 67, iter = 550, loss = 0.3876341849565506, perplexity = 1.47349066063434, 0:00:12.956839 per 50 iters\n",
            "time = 0:04:50.875957, epoch 67, iter = 600, loss = 0.41923129111528395, perplexity = 1.5207920598071332, 0:00:12.873400 per 50 iters\n",
            "time = 0:04:51.092774, epoch 67, iter = 650, loss = 0.41335409224033354, perplexity = 1.5118802762385408, 0:00:13.008912 per 50 iters\n",
            "time = 0:04:51.308725, epoch 67, iter = 700, loss = 0.39551900506019594, perplexity = 1.4851547937833716, 0:00:12.956812 per 50 iters\n",
            "time = 0:04:51.523924, epoch 67, iter = 750, loss = 0.42019213080406187, perplexity = 1.5222539994088968, 0:00:12.911681 per 50 iters\n",
            "time = 0:04:51.740851, epoch 67, iter = 800, loss = 0.42906558692455293, perplexity = 1.5358217609201021, 0:00:13.015526 per 50 iters\n",
            "time = 0:04:51.959784, epoch 67, iter = 850, loss = 0.435346862077713, perplexity = 1.5454990409985054, 0:00:13.135838 per 50 iters\n",
            "time = 0:04:52.179920, epoch 67, iter = 900, loss = 0.4134908539056778, perplexity = 1.5120870576424827, 0:00:13.208009 per 50 iters\n",
            "time = 0:04:52.393421, epoch 67, iter = 950, loss = 0.43124370634555814, perplexity = 1.5391706098972937, 0:00:12.809915 per 50 iters\n",
            "time = 0:04:52.612949, epoch 67, iter = 1000, loss = 0.43858445703983306, perplexity = 1.5505108496329738, 0:00:13.171517 per 50 iters\n",
            "\n",
            "time = 0:04:52.858725, epoch 68, iter = 50, loss = 0.3761910280585289, perplexity = 1.4567253826152224, 0:00:14.746399 per 50 iters\n",
            "time = 0:04:53.074680, epoch 68, iter = 100, loss = 0.3622354245185852, perplexity = 1.4365370982084296, 0:00:12.957161 per 50 iters\n",
            "time = 0:04:53.290947, epoch 68, iter = 150, loss = 0.36699643194675446, perplexity = 1.443392769003736, 0:00:12.975850 per 50 iters\n",
            "time = 0:04:53.508130, epoch 68, iter = 200, loss = 0.359965760409832, perplexity = 1.433280338788782, 0:00:13.030840 per 50 iters\n",
            "time = 0:04:53.726578, epoch 68, iter = 250, loss = 0.3879998904466629, perplexity = 1.4740296228032685, 0:00:13.106638 per 50 iters\n",
            "time = 0:04:53.944274, epoch 68, iter = 300, loss = 0.366839519739151, perplexity = 1.4431663008261881, 0:00:13.061599 per 50 iters\n",
            "time = 0:04:54.159331, epoch 68, iter = 350, loss = 0.3894985529780388, perplexity = 1.4762403519237792, 0:00:12.903288 per 50 iters\n",
            "time = 0:04:54.370039, epoch 68, iter = 400, loss = 0.38478097528219224, perplexity = 1.469292474826573, 0:00:12.642307 per 50 iters\n",
            "time = 0:04:54.588072, epoch 68, iter = 450, loss = 0.3893854933977127, perplexity = 1.4760734582437727, 0:00:13.081830 per 50 iters\n",
            "time = 0:04:54.798918, epoch 68, iter = 500, loss = 0.4310428023338318, perplexity = 1.5388614154072806, 0:00:12.650558 per 50 iters\n",
            "time = 0:04:55.015343, epoch 68, iter = 550, loss = 0.4036207336187363, perplexity = 1.4972359879860135, 0:00:12.985173 per 50 iters\n",
            "time = 0:04:55.232531, epoch 68, iter = 600, loss = 0.3726045650243759, perplexity = 1.4515102484126434, 0:00:13.031096 per 50 iters\n",
            "time = 0:04:55.448920, epoch 68, iter = 650, loss = 0.4032853555679321, perplexity = 1.4967339320927384, 0:00:12.983207 per 50 iters\n",
            "time = 0:04:55.665618, epoch 68, iter = 700, loss = 0.3983688372373581, perplexity = 1.4893932723104244, 0:00:13.001026 per 50 iters\n",
            "time = 0:04:55.885220, epoch 68, iter = 750, loss = 0.4295397651195526, perplexity = 1.536550186798722, 0:00:13.176003 per 50 iters\n",
            "time = 0:04:56.106412, epoch 68, iter = 800, loss = 0.41151238590478895, perplexity = 1.5090983992417688, 0:00:13.270504 per 50 iters\n",
            "time = 0:04:56.323751, epoch 68, iter = 850, loss = 0.43076807975769044, perplexity = 1.5384387135004525, 0:00:13.040169 per 50 iters\n",
            "time = 0:04:56.541386, epoch 68, iter = 900, loss = 0.45370238602161406, perplexity = 1.5741294448279988, 0:00:13.057997 per 50 iters\n",
            "time = 0:04:56.758003, epoch 68, iter = 950, loss = 0.4196887350082397, perplexity = 1.5214878959882194, 0:00:12.996844 per 50 iters\n",
            "time = 0:04:56.978219, epoch 68, iter = 1000, loss = 0.4295447391271591, perplexity = 1.5365578296300466, 0:00:13.212791 per 50 iters\n",
            "\n",
            "time = 0:04:57.226125, epoch 69, iter = 50, loss = 0.39324442207813265, perplexity = 1.4817805249457352, 0:00:14.874169 per 50 iters\n",
            "time = 0:04:57.444497, epoch 69, iter = 100, loss = 0.35415038526058196, perplexity = 1.4249694647716171, 0:00:13.102189 per 50 iters\n",
            "time = 0:04:57.661955, epoch 69, iter = 150, loss = 0.3588138094544411, perplexity = 1.431630220743175, 0:00:13.047326 per 50 iters\n",
            "time = 0:04:57.879148, epoch 69, iter = 200, loss = 0.3687828552722931, perplexity = 1.4459735840419417, 0:00:13.031435 per 50 iters\n",
            "time = 0:04:58.096079, epoch 69, iter = 250, loss = 0.38550784468650817, perplexity = 1.4703608468089306, 0:00:13.015697 per 50 iters\n",
            "time = 0:04:58.311737, epoch 69, iter = 300, loss = 0.4034189289808273, perplexity = 1.4969338693050946, 0:00:12.939369 per 50 iters\n",
            "time = 0:04:58.528501, epoch 69, iter = 350, loss = 0.3867671883106232, perplexity = 1.472213702812828, 0:00:13.005710 per 50 iters\n",
            "time = 0:04:58.748015, epoch 69, iter = 400, loss = 0.3856122213602066, perplexity = 1.4705143261929516, 0:00:13.170678 per 50 iters\n",
            "time = 0:04:58.960475, epoch 69, iter = 450, loss = 0.38789222478866575, perplexity = 1.473870928977113, 0:00:12.747477 per 50 iters\n",
            "time = 0:04:59.178523, epoch 69, iter = 500, loss = 0.38133646070957183, perplexity = 1.4642401818293378, 0:00:13.082749 per 50 iters\n",
            "time = 0:04:59.394910, epoch 69, iter = 550, loss = 0.3873631238937378, perplexity = 1.473091308816633, 0:00:12.983049 per 50 iters\n",
            "time = 0:04:59.611251, epoch 69, iter = 600, loss = 0.3871738308668137, perplexity = 1.4728124892939798, 0:00:12.980354 per 50 iters\n",
            "time = 0:04:59.829619, epoch 69, iter = 650, loss = 0.39803181409835814, perplexity = 1.48889139689115, 0:00:13.101939 per 50 iters\n",
            "time = 0:05:00.045214, epoch 69, iter = 700, loss = 0.41598725616931914, perplexity = 1.5158665508008178, 0:00:12.935540 per 50 iters\n",
            "time = 0:05:00.261128, epoch 69, iter = 750, loss = 0.41482119262218475, perplexity = 1.5140999842382121, 0:00:12.954655 per 50 iters\n",
            "time = 0:05:00.480527, epoch 69, iter = 800, loss = 0.4188841968774796, perplexity = 1.5202642932439405, 0:00:13.163795 per 50 iters\n",
            "time = 0:05:00.698589, epoch 69, iter = 850, loss = 0.40406594395637513, perplexity = 1.4979027213330263, 0:00:13.083574 per 50 iters\n",
            "time = 0:05:00.915387, epoch 69, iter = 900, loss = 0.4315318188071251, perplexity = 1.5396141280189635, 0:00:13.007659 per 50 iters\n",
            "time = 0:05:01.127775, epoch 69, iter = 950, loss = 0.4108513242006302, perplexity = 1.5081011217495197, 0:00:12.743061 per 50 iters\n",
            "time = 0:05:01.343386, epoch 69, iter = 1000, loss = 0.4059531831741333, perplexity = 1.5007322912909764, 0:00:12.936545 per 50 iters\n",
            "\n",
            "time = 0:05:01.587949, epoch 70, iter = 50, loss = 0.37940243899822235, perplexity = 1.4614110462137528, 0:00:14.673599 per 50 iters\n",
            "time = 0:05:01.805175, epoch 70, iter = 100, loss = 0.34854763120412824, perplexity = 1.4170080351150252, 0:00:13.032581 per 50 iters\n",
            "time = 0:05:02.022152, epoch 70, iter = 150, loss = 0.3532168805599213, perplexity = 1.423639869766103, 0:00:13.018426 per 50 iters\n",
            "time = 0:05:02.236846, epoch 70, iter = 200, loss = 0.35838536262512205, perplexity = 1.4310169746953836, 0:00:12.881520 per 50 iters\n",
            "time = 0:05:02.455142, epoch 70, iter = 250, loss = 0.35317266404628755, perplexity = 1.4235769227660506, 0:00:13.097506 per 50 iters\n",
            "time = 0:05:02.672736, epoch 70, iter = 300, loss = 0.3767222398519516, perplexity = 1.4574994178883767, 0:00:13.055420 per 50 iters\n",
            "time = 0:05:02.890802, epoch 70, iter = 350, loss = 0.3813564920425415, perplexity = 1.4642695128057357, 0:00:13.083837 per 50 iters\n",
            "time = 0:05:03.107971, epoch 70, iter = 400, loss = 0.3705135726928711, perplexity = 1.4484783225856335, 0:00:13.029086 per 50 iters\n",
            "time = 0:05:03.322496, epoch 70, iter = 450, loss = 0.3765269058942795, perplexity = 1.4572147465626695, 0:00:12.871321 per 50 iters\n",
            "time = 0:05:03.537527, epoch 70, iter = 500, loss = 0.42476288676261903, perplexity = 1.529227776522549, 0:00:12.901746 per 50 iters\n",
            "time = 0:05:03.757213, epoch 70, iter = 550, loss = 0.4012224888801575, perplexity = 1.493649551950064, 0:00:13.181000 per 50 iters\n",
            "time = 0:05:03.974724, epoch 70, iter = 600, loss = 0.39151379466056824, perplexity = 1.4792183326820372, 0:00:13.050565 per 50 iters\n",
            "time = 0:05:04.193773, epoch 70, iter = 650, loss = 0.40083429992198943, perplexity = 1.4930698462115874, 0:00:13.142730 per 50 iters\n",
            "time = 0:05:04.413068, epoch 70, iter = 700, loss = 0.4079164782166481, perplexity = 1.503681565759243, 0:00:13.157553 per 50 iters\n",
            "time = 0:05:04.625872, epoch 70, iter = 750, loss = 0.4572372394800186, perplexity = 1.5797036078605784, 0:00:12.768059 per 50 iters\n",
            "time = 0:05:04.843396, epoch 70, iter = 800, loss = 0.4113798189163208, perplexity = 1.5088983558715459, 0:00:13.051277 per 50 iters\n",
            "time = 0:05:05.059681, epoch 70, iter = 850, loss = 0.41498206943273547, perplexity = 1.5143435874090565, 0:00:12.977005 per 50 iters\n",
            "time = 0:05:05.273767, epoch 70, iter = 900, loss = 0.39007350683212283, perplexity = 1.4770893660522564, 0:00:12.844927 per 50 iters\n",
            "time = 0:05:05.488726, epoch 70, iter = 950, loss = 0.4110659262537956, perplexity = 1.5084247980761882, 0:00:12.897425 per 50 iters\n",
            "time = 0:05:05.706234, epoch 70, iter = 1000, loss = 0.4172335600852966, perplexity = 1.517756958986049, 0:00:13.050258 per 50 iters\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Bu7W7ZhBk0"
      },
      "source": [
        "def translate(model, src, max_len=80, custom_sentence=False):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    if custom_sentence == True:\n",
        "        src = tokenize_ku(src)\n",
        "        src = torch.autograd.Variable(torch.LongTensor([[JA_TEXT.vocab.stoi[tok] for tok in src]])).to(device)\n",
        "    \n",
        "    src_mask = (src != input_pad).unsqueeze(-2)\n",
        "    e_outputs = model.encoder(src, src_mask)\n",
        "\n",
        "    outputs = torch.zeros(max_len).type_as(src.data)\n",
        "    outputs[0] = torch.LongTensor([EN_TEXT.vocab.stoi['<sos>']])\n",
        "    \n",
        "    for i in range(1, max_len):    \n",
        "        trg_mask = np.triu(np.ones((1, i, i)), k=1).astype('uint8')\n",
        "        trg_mask = torch.autograd.Variable(torch.from_numpy(trg_mask) == 0).to(device)\n",
        "\n",
        "        out = model.out(\n",
        "            model.decoder(\n",
        "                outputs[:i].unsqueeze(0),\n",
        "                e_outputs,\n",
        "                src_mask,\n",
        "                trg_mask\n",
        "            )\n",
        "        )\n",
        "        out = F.softmax(out, dim=-1)\n",
        "        val, ix = out[:, -1].data.topk(1)\n",
        "\n",
        "        outputs[i] = ix[0][0]\n",
        "        if ix[0][0] == EN_TEXT.vocab.stoi['<eos>']:\n",
        "            break\n",
        "\n",
        "    return ' '.join([EN_TEXT.vocab.itos[ix] for ix in outputs[:i]])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gpMa0IkYnYm"
      },
      "source": [
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6I9mQPPh3Zv"
      },
      "source": [
        "\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiOI6SUoh88f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3faaeb12-9c84-4094-eb2e-9f272f0c811e"
      },
      "source": [
        "data_length = len(test_df[\"en\"]);\n",
        "total_score = 0;\n",
        "print(data_length)\n",
        "for i in range(data_length):\n",
        "  print(i)\n",
        "  reference = tokenize_en(test_df[\"en\"][i]);\n",
        "  candidate = tokenize_en(translate(model, test_df[\"ku\"][i] , custom_sentence=True))\n",
        "  candidate = candidate[3:]\n",
        "  score = sentence_bleu(reference, candidate)\n",
        "  total_score += score;\n",
        "\n",
        "  print(total_score/data_length)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "37496\n",
            "0.430764465033567\n",
            "37497\n",
            "0.4307776323599959\n",
            "37498\n",
            "0.43079249893559096\n",
            "37499\n",
            "0.430805424557002\n",
            "37500\n",
            "0.4308183501784131\n",
            "37501\n",
            "0.430832079063471\n",
            "37502\n",
            "0.43084478365263373\n",
            "37503\n",
            "0.43085665638699466\n",
            "37504\n",
            "0.43087086054949175\n",
            "37505\n",
            "0.4308845894345497\n",
            "37506\n",
            "0.4308956617921421\n",
            "37507\n",
            "0.43091009699239186\n",
            "37508\n",
            "0.43091009699239186\n",
            "37509\n",
            "0.430922697861947\n",
            "37510\n",
            "0.43093941804158936\n",
            "37511\n",
            "0.4309547892825372\n",
            "37512\n",
            "0.43096862419002424\n",
            "37513\n",
            "0.43098459936514794\n",
            "37514\n",
            "0.43099682366313863\n",
            "37515\n",
            "0.4310094245326938\n",
            "37516\n",
            "0.43102214649170817\n",
            "37517\n",
            "0.43103420213829796\n",
            "37518\n",
            "0.4310458817557029\n",
            "37519\n",
            "0.4310580202638464\n",
            "37520\n",
            "0.4310580202638464\n",
            "37521\n",
            "0.43107208020297\n",
            "37522\n",
            "0.4310848929260454\n",
            "37523\n",
            "0.4310848929260454\n",
            "37524\n",
            "0.4310848929260454\n",
            "37525\n",
            "0.43110121941383733\n",
            "37526\n",
            "0.43110121941383733\n",
            "37527\n",
            "0.43111767198425627\n",
            "37528\n",
            "0.43111767198425627\n",
            "37529\n",
            "0.431130376573419\n",
            "37530\n",
            "0.4311453216033242\n",
            "37531\n",
            "0.43115714455573195\n",
            "37532\n",
            "0.43117007017714304\n",
            "37533\n",
            "0.43117007017714304\n",
            "37534\n",
            "0.4311854414180909\n",
            "37535\n",
            "0.43119651377568335\n",
            "37536\n",
            "0.43119651377568335\n",
            "37537\n",
            "0.4312098108451326\n",
            "37538\n",
            "0.43122578602025635\n",
            "37539\n",
            "0.431239965629226\n",
            "37540\n",
            "0.431239965629226\n",
            "37541\n",
            "0.4312566858088684\n",
            "37542\n",
            "0.43126850876127615\n",
            "37543\n",
            "0.43126850876127615\n",
            "37544\n",
            "0.4312829439615259\n",
            "37545\n",
            "0.43129564855068864\n",
            "37546\n",
            "0.431312368730331\n",
            "37547\n",
            "0.4313238614135397\n",
            "37548\n",
            "0.43133775089765813\n",
            "37549\n",
            "0.4313515858051451\n",
            "37550\n",
            "0.43136602100539484\n",
            "37551\n",
            "0.43136602100539484\n",
            "37552\n",
            "0.4313813922463427\n",
            "37553\n",
            "0.43139455957277156\n",
            "37554\n",
            "0.43140966796059715\n",
            "37555\n",
            "0.43142390935581854\n",
            "37556\n",
            "0.4314406295354609\n",
            "37557\n",
            "0.4314537968618898\n",
            "37558\n",
            "0.4314574777471087\n",
            "37559\n",
            "0.43146790944389996\n",
            "37560\n",
            "0.43148234464414964\n",
            "37561\n",
            "0.4314957781116442\n",
            "37562\n",
            "0.4315117532867679\n",
            "37563\n",
            "0.4315117532867679\n",
            "37564\n",
            "0.43152876436120824\n",
            "37565\n",
            "0.4315477621531287\n",
            "37566\n",
            "0.4315613393145114\n",
            "37567\n",
            "0.43157850575735485\n",
            "37568\n",
            "0.4315916730837837\n",
            "37569\n",
            "0.4315916730837837\n",
            "37570\n",
            "0.43160573302290733\n",
            "37571\n",
            "0.4316224532025497\n",
            "37572\n",
            "0.4316345917106932\n",
            "37573\n",
            "0.4316490269109429\n",
            "37574\n",
            "0.4316490269109429\n",
            "37575\n",
            "0.43166346211119266\n",
            "37576\n",
            "0.4316747582658532\n",
            "37577\n",
            "0.4316877619912496\n",
            "37578\n",
            "0.43169905814591014\n",
            "37579\n",
            "0.4317104751322462\n",
            "37580\n",
            "0.4317271953118885\n",
            "37581\n",
            "0.4317271953118885\n",
            "37582\n",
            "0.4317395085197219\n",
            "37583\n",
            "0.4317557136125676\n",
            "37584\n",
            "0.4317557136125676\n",
            "37585\n",
            "0.4317716887876913\n",
            "37586\n",
            "0.43179019270819563\n",
            "37587\n",
            "0.4318067101815331\n",
            "37588\n",
            "0.43182114538178284\n",
            "37589\n",
            "0.4318365166227307\n",
            "37590\n",
            "0.43184985838884193\n",
            "37591\n",
            "0.4318630257152708\n",
            "37592\n",
            "0.4318743814823159\n",
            "37593\n",
            "0.43188594028707444\n",
            "37594\n",
            "0.4319015001674947\n",
            "37595\n",
            "0.4319015001674947\n",
            "37596\n",
            "0.4319159353677444\n",
            "37597\n",
            "0.4319295125291271\n",
            "37598\n",
            "0.4319477921182287\n",
            "37599\n",
            "0.4319626586938238\n",
            "37600\n",
            "0.4319767186329474\n",
            "37601\n",
            "0.4319897623088156\n",
            "37602\n",
            "0.4320056084806243\n",
            "37603\n",
            "0.43201845828866947\n",
            "37604\n",
            "0.43203466338151514\n",
            "37605\n",
            "0.43204839226657304\n",
            "37606\n",
            "0.432060071883978\n",
            "37607\n",
            "0.43207906967589843\n",
            "37608\n",
            "0.4320917742650612\n",
            "37609\n",
            "0.43210810075285305\n",
            "37610\n",
            "0.43212007629104293\n",
            "37611\n",
            "0.43213311996691117\n",
            "37612\n",
            "0.4321471799060348\n",
            "37613\n",
            "0.4321471799060348\n",
            "37614\n",
            "0.4321471799060348\n",
            "37615\n",
            "0.43216617769795523\n",
            "37616\n",
            "0.4321812860857809\n",
            "37617\n",
            "0.4321924675438142\n",
            "37618\n",
            "0.4322096339866576\n",
            "37619\n",
            "0.4322261514599951\n",
            "37620\n",
            "0.43223998636748207\n",
            "37621\n",
            "0.43225315369391093\n",
            "37622\n",
            "0.4322652093405008\n",
            "37623\n",
            "0.43227503068890805\n",
            "37624\n",
            "0.4322852483269269\n",
            "37625\n",
            "0.43229817394833797\n",
            "37626\n",
            "0.43231450043612984\n",
            "37627\n",
            "0.4323312206157722\n",
            "37628\n",
            "0.4323312206157722\n",
            "37629\n",
            "0.43234972453627657\n",
            "37630\n",
            "0.4323618074891491\n",
            "37631\n",
            "0.43237497481557796\n",
            "37632\n",
            "0.43237497481557796\n",
            "37633\n",
            "0.43237497481557796\n",
            "37634\n",
            "0.4323906334938527\n",
            "37635\n",
            "0.4323906334938527\n",
            "37636\n",
            "0.4323906334938527\n",
            "37637\n",
            "0.4323906334938527\n",
            "37638\n",
            "0.43240380082028157\n",
            "37639\n",
            "0.4324191720612294\n",
            "37640\n",
            "0.43243403863682445\n",
            "37641\n",
            "0.4324479281209429\n",
            "37642\n",
            "0.4324607408440183\n",
            "37643\n",
            "0.4324607408440183\n",
            "37644\n",
            "0.4324739081704472\n",
            "37645\n",
            "0.4324866127596099\n",
            "37646\n",
            "0.4324997800860388\n",
            "37647\n",
            "0.4325141167467394\n",
            "37648\n",
            "0.4325276939081221\n",
            "37649\n",
            "0.4325403984972848\n",
            "37650\n",
            "0.43255483369753456\n",
            "37651\n",
            "0.4325682671650291\n",
            "37652\n",
            "0.4325842423401528\n",
            "37653\n",
            "0.4325979712252107\n",
            "37654\n",
            "0.43261203116433433\n",
            "37655\n",
            "0.43262357573456495\n",
            "37656\n",
            "0.43263700920205944\n",
            "37657\n",
            "0.4326488321544672\n",
            "37658\n",
            "0.4326659985973107\n",
            "37659\n",
            "0.43268043379756044\n",
            "37660\n",
            "0.43269449373668406\n",
            "37661\n",
            "0.43269449373668406\n",
            "37662\n",
            "0.4327066322448275\n",
            "37663\n",
            "0.43272229092310227\n",
            "37664\n",
            "0.43272229092310227\n",
            "37665\n",
            "0.43273672612335196\n",
            "37666\n",
            "0.43273672612335196\n",
            "37667\n",
            "0.43273672612335196\n",
            "37668\n",
            "0.43273672612335196\n",
            "37669\n",
            "0.43273672612335196\n",
            "37670\n",
            "0.4327504550084099\n",
            "37671\n",
            "0.43276140317039075\n",
            "37672\n",
            "0.43276140317039075\n",
            "37673\n",
            "0.43277513205544865\n",
            "37674\n",
            "0.43278590622835245\n",
            "37675\n",
            "0.43278590622835245\n",
            "37676\n",
            "0.4328021113211981\n",
            "37677\n",
            "0.4328134873123073\n",
            "37678\n",
            "0.43282813026667133\n",
            "37679\n",
            "0.43284284589301586\n",
            "37680\n",
            "0.4328542628793519\n",
            "37681\n",
            "0.43286832281847554\n",
            "37682\n",
            "0.4328836940594234\n",
            "37683\n",
            "0.4328836940594234\n",
            "37684\n",
            "0.4329004142390658\n",
            "37685\n",
            "0.43291358156549464\n",
            "37686\n",
            "0.43291358156549464\n",
            "37687\n",
            "0.43292409382191094\n",
            "37688\n",
            "0.43292409382191094\n",
            "37689\n",
            "0.43292409382191094\n",
            "37690\n",
            "0.4329352200611801\n",
            "37691\n",
            "0.43295087873945487\n",
            "37692\n",
            "0.4329680451822983\n",
            "37693\n",
            "0.4329800797472987\n",
            "37694\n",
            "0.4329914967336347\n",
            "37695\n",
            "0.4330104945255552\n",
            "37696\n",
            "0.4330226330336986\n",
            "37697\n",
            "0.4330384777883203\n",
            "37698\n",
            "0.43304955014591273\n",
            "37699\n",
            "0.4330631769503955\n",
            "37700\n",
            "0.43307531545853895\n",
            "37701\n",
            "0.43308937539766257\n",
            "37702\n",
            "0.4331031441574111\n",
            "37703\n",
            "0.43311947064520295\n",
            "37704\n",
            "0.43313592321562194\n",
            "37705\n",
            "0.43314862780478464\n",
            "37706\n",
            "0.4331621504985788\n",
            "37707\n",
            "0.4331621504985788\n",
            "37708\n",
            "0.43317701707417383\n",
            "37709\n",
            "0.4331904505416684\n",
            "37710\n",
            "0.43320200934642694\n",
            "37711\n",
            "0.4332164445466766\n",
            "37712\n",
            "0.4332313111222717\n",
            "37713\n",
            "0.4332437404837411\n",
            "37714\n",
            "0.4332437404837411\n",
            "37715\n",
            "0.43325531858445615\n",
            "37716\n",
            "0.43325531858445615\n",
            "37717\n",
            "0.4332688957458389\n",
            "37718\n",
            "0.4332823292133334\n",
            "37719\n",
            "0.4332823292133334\n",
            "37720\n",
            "0.43330000865080676\n",
            "37721\n",
            "0.43330000865080676\n",
            "37722\n",
            "0.43331585340542844\n",
            "37723\n",
            "0.43333257358507077\n",
            "37724\n",
            "0.43334630247012873\n",
            "37725\n",
            "0.43336116904572375\n",
            "37726\n",
            "0.43336116904572375\n",
            "37727\n",
            "0.43336116904572375\n",
            "37728\n",
            "0.43337348225355715\n",
            "37729\n",
            "0.4333879174538069\n",
            "37730\n",
            "0.4334013509213014\n",
            "37731\n",
            "0.43341599387566543\n",
            "37732\n",
            "0.4334287158346798\n",
            "37733\n",
            "0.4334287158346798\n",
            "37734\n",
            "0.4334469954237814\n",
            "37735\n",
            "0.43346143062403114\n",
            "37736\n",
            "0.433477757111823\n",
            "37737\n",
            "0.4334910541812723\n",
            "37738\n",
            "0.43350548938152206\n",
            "37739\n",
            "0.43351892284901655\n",
            "37740\n",
            "0.4335333580492663\n",
            "37741\n",
            "0.4335333580492663\n",
            "37742\n",
            "0.4335333580492663\n",
            "37743\n",
            "0.43354872929021415\n",
            "37744\n",
            "0.43356202635966345\n",
            "37745\n",
            "0.43357575524472136\n",
            "37746\n",
            "0.43358773078291124\n",
            "37747\n",
            "0.43359841402639554\n",
            "37748\n",
            "0.43359841402639554\n",
            "37749\n",
            "0.43359841402639554\n",
            "37750\n",
            "0.43361513420603787\n",
            "37751\n",
            "0.4336289691135249\n",
            "37752\n",
            "0.4336289691135249\n",
            "37753\n",
            "0.43364434035447275\n",
            "37754\n",
            "0.43364434035447275\n",
            "37755\n",
            "0.43364434035447275\n",
            "37756\n",
            "0.43365949952751126\n",
            "37757\n",
            "0.433673934727761\n",
            "37758\n",
            "0.4336876636128189\n",
            "37759\n",
            "0.43370209881306865\n",
            "37760\n",
            "0.43371731105563216\n",
            "37761\n",
            "0.43373268229658\n",
            "37762\n",
            "0.4337464111816379\n",
            "37763\n",
            "0.4337631313612803\n",
            "37764\n",
            "0.433779106536404\n",
            "37765\n",
            "0.4337967859738774\n",
            "37766\n",
            "0.4338090991817108\n",
            "37767\n",
            "0.4338267786191841\n",
            "37768\n",
            "0.4338395913422596\n",
            "37769\n",
            "0.433851729850403\n",
            "37770\n",
            "0.43386330795111805\n",
            "37771\n",
            "0.4338743803087105\n",
            "37772\n",
            "0.4338858916132574\n",
            "37773\n",
            "0.4338858916132574\n",
            "37774\n",
            "0.4338858916132574\n",
            "37775\n",
            "0.43389752533736864\n",
            "37776\n",
            "0.43391289657831644\n",
            "37777\n",
            "0.4339266254633744\n",
            "37778\n",
            "0.433940685402498\n",
            "37779\n",
            "0.433940685402498\n",
            "37780\n",
            "0.43395512060274777\n",
            "37781\n",
            "0.4339718407823901\n",
            "37782\n",
            "0.43398352039979504\n",
            "37783\n",
            "0.4340002405794374\n",
            "37784\n",
            "0.4340120635318452\n",
            "37785\n",
            "0.43402743477279304\n",
            "37786\n",
            "0.4340428060137409\n",
            "37787\n",
            "0.4340562394812354\n",
            "37788\n",
            "0.43406753563589595\n",
            "37789\n",
            "0.4340803118030409\n",
            "37790\n",
            "0.43409703198268323\n",
            "37791\n",
            "0.4341128981058695\n",
            "37792\n",
            "0.4341235813493538\n",
            "37793\n",
            "0.4341374708334722\n",
            "37794\n",
            "0.4341584953463049\n",
            "37795\n",
            "0.4341584953463049\n",
            "37796\n",
            "0.4341748218340968\n",
            "37797\n",
            "0.4341907970092205\n",
            "37798\n",
            "0.4342048569483441\n",
            "37799\n",
            "0.4342170812463348\n",
            "37800\n",
            "0.4342170812463348\n",
            "37801\n",
            "0.434228714970446\n",
            "37802\n",
            "0.43424374056946907\n",
            "37803\n",
            "0.4342620201585707\n",
            "37804\n",
            "0.43427739139951854\n",
            "37805\n",
            "0.43428961569750923\n",
            "37806\n",
            "0.4343025413189203\n",
            "37807\n",
            "0.4343155849947885\n",
            "37808\n",
            "0.4343155849947885\n",
            "37809\n",
            "0.43432875232121737\n",
            "37810\n",
            "0.4343472562417217\n",
            "37811\n",
            "0.4343649356791951\n",
            "37812\n",
            "0.4343783691466896\n",
            "37813\n",
            "0.43438972491373473\n",
            "37814\n",
            "0.43439993214171907\n",
            "37815\n",
            "0.43441530338266693\n",
            "37816\n",
            "0.43441530338266693\n",
            "37817\n",
            "0.43441530338266693\n",
            "37818\n",
            "0.43441530338266693\n",
            "37819\n",
            "0.4344269830000719\n",
            "37820\n",
            "0.43443990862148296\n",
            "37821\n",
            "0.4344512047761435\n",
            "37822\n",
            "0.43446592040248805\n",
            "37823\n",
            "0.4344812916434359\n",
            "37824\n",
            "0.4344955330386573\n",
            "37825\n",
            "0.4345092619237152\n",
            "37826\n",
            "0.4345201310324247\n",
            "37827\n",
            "0.4345201310324247\n",
            "37828\n",
            "0.43453263228254974\n",
            "37829\n",
            "0.43453263228254974\n",
            "37830\n",
            "0.43454749885814475\n",
            "37831\n",
            "0.43456174025336614\n",
            "37832\n",
            "0.43456174025336614\n",
            "37833\n",
            "0.4345738787615096\n",
            "37834\n",
            "0.4345898539366333\n",
            "37835\n",
            "0.4345898539366333\n",
            "37836\n",
            "0.4345898539366333\n",
            "37837\n",
            "0.43460220362844526\n",
            "37838\n",
            "0.43461817880356896\n",
            "37839\n",
            "0.43463489898321134\n",
            "37840\n",
            "0.43463489898321134\n",
            "37841\n",
            "0.4346482239722808\n",
            "37842\n",
            "0.4346482239722808\n",
            "37843\n",
            "0.4346645504600727\n",
            "37844\n",
            "0.4346774760814837\n",
            "37845\n",
            "0.43469258446930936\n",
            "37846\n",
            "0.43470769285713495\n",
            "37847\n",
            "0.43471930396943065\n",
            "37848\n",
            "0.43473282666322477\n",
            "37849\n",
            "0.43474427337639276\n",
            "37850\n",
            "0.4347591399519878\n",
            "37851\n",
            "0.43477586013163017\n",
            "37852\n",
            "0.43479258031127255\n",
            "37853\n",
            "0.43481157810319304\n",
            "37854\n",
            "0.43482520490767573\n",
            "37855\n",
            "0.43483893379273364\n",
            "37856\n",
            "0.43485538636315263\n",
            "37857\n",
            "0.4348688198306471\n",
            "37858\n",
            "0.43488346278501117\n",
            "37859\n",
            "0.43489549143110323\n",
            "37860\n",
            "0.4349071710485082\n",
            "37861\n",
            "0.4349071710485082\n",
            "37862\n",
            "0.4349196722986332\n",
            "37863\n",
            "0.43493410749888295\n",
            "37864\n",
            "0.43495008267400664\n",
            "37865\n",
            "0.4349654539149545\n",
            "37866\n",
            "0.43497934339907296\n",
            "37867\n",
            "0.43499531857419665\n",
            "37868\n",
            "0.43500729411238653\n",
            "37869\n",
            "0.43502083132092406\n",
            "37870\n",
            "0.43502083132092406\n",
            "37871\n",
            "0.4350365920155269\n",
            "37872\n",
            "0.4350542714530003\n",
            "37873\n",
            "0.4350671970744114\n",
            "37874\n",
            "0.43508036440084025\n",
            "37875\n",
            "0.43508036440084025\n",
            "37876\n",
            "0.43509479960108993\n",
            "37877\n",
            "0.43509479960108993\n",
            "37878\n",
            "0.4351137973930104\n",
            "37879\n",
            "0.43512503546783093\n",
            "37880\n",
            "0.43513960750992053\n",
            "37881\n",
            "0.4351544740855156\n",
            "37882\n",
            "0.4351544740855156\n",
            "37883\n",
            "0.43516772719710906\n",
            "37884\n",
            "0.43517927176733967\n",
            "37885\n",
            "0.4351917730174647\n",
            "37886\n",
            "0.43520733289788494\n",
            "37887\n",
            "0.4352240530775273\n",
            "37888\n",
            "0.43523619158567073\n",
            "37889\n",
            "0.43523619158567073\n",
            "37890\n",
            "0.4352525180734626\n",
            "37891\n",
            "0.43526533079653806\n",
            "37892\n",
            "0.43528130597166176\n",
            "37893\n",
            "0.43529802615130414\n",
            "37894\n",
            "0.43531313453912973\n",
            "37895\n",
            "0.43532377372706327\n",
            "37896\n",
            "0.43532377372706327\n",
            "37897\n",
            "0.43532377372706327\n",
            "37898\n",
            "0.4353409401699067\n",
            "37899\n",
            "0.4353551197788764\n",
            "37900\n",
            "0.43536983540522095\n",
            "37901\n",
            "0.4353838953443446\n",
            "37902\n",
            "0.43539706267077344\n",
            "37903\n",
            "0.4354099882921845\n",
            "37904\n",
            "0.43542564697045927\n",
            "37905\n",
            "0.4354397069095829\n",
            "37906\n",
            "0.4354397069095829\n",
            "37907\n",
            "0.435454732508606\n",
            "37908\n",
            "0.435454732508606\n",
            "37909\n",
            "0.4354687924477296\n",
            "37910\n",
            "0.43548902213848795\n",
            "37911\n",
            "0.43548902213848795\n",
            "37912\n",
            "0.435501523388613\n",
            "37913\n",
            "0.4355140739542916\n",
            "37914\n",
            "0.43552442808661895\n",
            "37915\n",
            "0.43553539646689826\n",
            "37916\n",
            "0.43553539646689826\n",
            "37917\n",
            "0.435547219419306\n",
            "37918\n",
            "0.435547219419306\n",
            "37919\n",
            "0.4355603867457349\n",
            "37920\n",
            "0.4355603867457349\n",
            "37921\n",
            "0.43557575798668274\n",
            "37922\n",
            "0.43558933514806547\n",
            "37923\n",
            "0.43558933514806547\n",
            "37924\n",
            "0.4356060553277078\n",
            "37925\n",
            "0.43561922265413666\n",
            "37926\n",
            "0.43563283491097515\n",
            "37927\n",
            "0.4356468948500988\n",
            "37928\n",
            "0.43566180257779596\n",
            "37929\n",
            "0.43567496990422483\n",
            "37930\n",
            "0.43568869878928274\n",
            "37931\n",
            "0.4357057098637231\n",
            "37932\n",
            "0.4357057098637231\n",
            "37933\n",
            "0.43572014506397283\n",
            "37934\n",
            "0.4357341355691765\n",
            "37935\n",
            "0.43575516008200915\n",
            "37936\n",
            "0.43576808570342024\n",
            "37937\n",
            "0.43576808570342024\n",
            "37938\n",
            "0.4357802242115637\n",
            "37939\n",
            "0.4357802242115637\n",
            "37940\n",
            "0.4357942841506873\n",
            "37941\n",
            "0.43580846375965704\n",
            "37942\n",
            "0.435820965009782\n",
            "37943\n",
            "0.435820965009782\n",
            "37944\n",
            "0.43583366959894476\n",
            "37945\n",
            "0.4358493282772195\n",
            "37946\n",
            "0.43586146678536297\n",
            "37947\n",
            "0.43586146678536297\n",
            "37948\n",
            "0.43587818696500535\n",
            "37949\n",
            "0.4358935582059532\n",
            "37950\n",
            "0.4359047396639865\n",
            "37951\n",
            "0.43591744425314927\n",
            "37952\n",
            "0.4359300451227044\n",
            "37953\n",
            "0.4359402523506888\n",
            "37954\n",
            "0.43596127686352143\n",
            "37955\n",
            "0.4359776033513133\n",
            "37956\n",
            "0.4359958829404149\n",
            "37957\n",
            "0.4360089266162831\n",
            "37958\n",
            "0.43602074956869086\n",
            "37959\n",
            "0.4360325725210986\n",
            "37960\n",
            "0.4360485476962223\n",
            "37961\n",
            "0.43606125228538506\n",
            "37962\n",
            "0.4360742560107814\n",
            "37963\n",
            "0.43608778442034873\n",
            "37964\n",
            "0.4361022196205985\n",
            "37965\n",
            "0.43611565308809297\n",
            "37966\n",
            "0.4361319795758849\n",
            "37967\n",
            "0.43614595298819747\n",
            "37968\n",
            "0.43616311943104097\n",
            "37969\n",
            "0.43616311943104097\n",
            "37970\n",
            "0.43617798600663604\n",
            "37971\n",
            "0.4361933572475839\n",
            "37972\n",
            "0.4362067907150784\n",
            "37973\n",
            "0.4362192919652034\n",
            "37974\n",
            "0.43622833250732046\n",
            "37975\n",
            "0.4362410370964832\n",
            "37976\n",
            "0.43625614548430885\n",
            "37977\n",
            "0.43625614548430885\n",
            "37978\n",
            "0.4362715167252567\n",
            "37979\n",
            "0.4362715167252567\n",
            "37980\n",
            "0.4362849501927512\n",
            "37981\n",
            "0.43630060887102595\n",
            "37982\n",
            "0.4363150440712757\n",
            "37983\n",
            "0.4363284775387702\n",
            "37984\n",
            "0.43634118212793294\n",
            "37985\n",
            "0.43634118212793294\n",
            "37986\n",
            "0.43634118212793294\n",
            "37987\n",
            "0.43634118212793294\n",
            "37988\n",
            "0.4363565533688808\n",
            "37989\n",
            "0.43637371981172424\n",
            "37990\n",
            "0.4363877797508479\n",
            "37991\n",
            "0.4364037549259716\n",
            "37992\n",
            "0.43641839788033565\n",
            "37993\n",
            "0.4364324578194593\n",
            "37994\n",
            "0.43644562514588814\n",
            "37995\n",
            "0.43644562514588814\n",
            "37996\n",
            "0.43645915355545545\n",
            "37997\n",
            "0.43647587373509783\n",
            "37998\n",
            "0.4364882480525392\n",
            "37999\n",
            "0.4364882480525392\n",
            "38000\n",
            "0.4364882480525392\n",
            "38001\n",
            "0.4364882480525392\n",
            "38002\n",
            "0.4364882480525392\n",
            "38003\n",
            "0.43650056126037257\n",
            "38004\n",
            "0.43651191702741765\n",
            "38005\n",
            "0.4365244182775427\n",
            "38006\n",
            "0.43654209771501606\n",
            "38007\n",
            "0.4365542362231595\n",
            "38008\n",
            "0.4365542362231595\n",
            "38009\n",
            "0.4365675332926088\n",
            "38010\n",
            "0.43658425347225116\n",
            "38011\n",
            "0.43660325126417165\n",
            "38012\n",
            "0.4366161768855827\n",
            "38013\n",
            "0.4366161768855827\n",
            "38014\n",
            "0.4366306120858324\n",
            "38015\n",
            "0.4366459833267803\n",
            "38016\n",
            "0.4366587960498557\n",
            "38017\n",
            "0.43667093455799916\n",
            "38018\n",
            "0.43667093455799916\n",
            "38019\n",
            "0.43667093455799916\n",
            "38020\n",
            "0.4366843680254937\n",
            "38021\n",
            "0.43670108820513603\n",
            "38022\n",
            "0.4367145216726306\n",
            "38023\n",
            "0.4367145216726306\n",
            "38024\n",
            "0.4367285816117542\n",
            "38025\n",
            "0.43674322456611825\n",
            "38026\n",
            "0.43674322456611825\n",
            "38027\n",
            "0.43674322456611825\n",
            "38028\n",
            "0.4367580911417133\n",
            "38029\n",
            "0.4367723325369347\n",
            "38030\n",
            "0.4367723325369347\n",
            "38031\n",
            "0.43679083645743905\n",
            "38032\n",
            "0.4368055520837836\n",
            "38033\n",
            "0.4368055520837836\n",
            "38034\n",
            "0.4368170966540142\n",
            "38035\n",
            "0.4368305301215087\n",
            "38036\n",
            "0.4368305301215087\n",
            "38037\n",
            "0.43684323471067144\n",
            "38038\n",
            "0.4368597917471026\n",
            "38039\n",
            "0.4368597917471026\n",
            "38040\n",
            "0.4368597917471026\n",
            "38041\n",
            "0.4368597917471026\n",
            "38042\n",
            "0.4368769581899461\n",
            "38043\n",
            "0.43689182476554117\n",
            "38044\n",
            "0.43690779994066486\n",
            "38045\n",
            "0.43692266651625994\n",
            "38046\n",
            "0.43693537110542263\n",
            "38047\n",
            "0.4369513462805464\n",
            "38048\n",
            "0.4369513462805464\n",
            "38049\n",
            "0.43696384753067136\n",
            "38050\n",
            "0.4369772809981659\n",
            "38051\n",
            "0.43698876089038846\n",
            "38052\n",
            "0.43700473606551216\n",
            "38053\n",
            "0.43700473606551216\n",
            "38054\n",
            "0.43701907272621277\n",
            "38055\n",
            "0.43703280161127067\n",
            "38056\n",
            "0.43704477714946055\n",
            "38057\n",
            "0.4370611036372524\n",
            "38058\n",
            "0.43707621202507807\n",
            "38059\n",
            "0.43707621202507807\n",
            "38060\n",
            "0.4370912704671365\n",
            "38061\n",
            "0.4371052438794491\n",
            "38062\n",
            "0.4371229233169225\n",
            "38063\n",
            "0.4371349789635123\n",
            "38064\n",
            "0.4371349789635123\n",
            "38065\n",
            "0.43715008735133787\n",
            "38066\n",
            "0.43716301297274895\n",
            "38067\n",
            "0.4371774481729987\n",
            "38068\n",
            "0.4371915081121223\n",
            "38069\n",
            "0.4372044337335334\n",
            "38070\n",
            "0.4372044337335334\n",
            "38071\n",
            "0.43721980497448126\n",
            "38072\n",
            "0.43723310204393057\n",
            "38073\n",
            "0.43723310204393057\n",
            "38074\n",
            "0.43724612167605437\n",
            "38075\n",
            "0.43724612167605437\n",
            "38076\n",
            "0.43726305764457923\n",
            "38077\n",
            "0.4372761418922464\n",
            "38078\n",
            "0.43729020183137\n",
            "38079\n",
            "0.4373061770064937\n",
            "38080\n",
            "0.4373192817785341\n",
            "38081\n",
            "0.43733084058329263\n",
            "38082\n",
            "0.43734225756962863\n",
            "38083\n",
            "0.4373569005239927\n",
            "38084\n",
            "0.4373715434783567\n",
            "38085\n",
            "0.4373835190165466\n",
            "38086\n",
            "0.4373970474261139\n",
            "38087\n",
            "0.437411914001709\n",
            "38088\n",
            "0.43742508132813784\n",
            "38089\n",
            "0.43743745564557923\n",
            "38090\n",
            "0.4374490002158098\n",
            "38091\n",
            "0.43746593618433466\n",
            "38092\n",
            "0.43746593618433466\n",
            "38093\n",
            "0.4374791035107635\n",
            "38094\n",
            "0.4374922708371924\n",
            "38095\n",
            "0.43750670603744213\n",
            "38096\n",
            "0.437522466732045\n",
            "38097\n",
            "0.4375319656280053\n",
            "38098\n",
            "0.43754467021716803\n",
            "38099\n",
            "0.43755544439007177\n",
            "38100\n",
            "0.43755544439007177\n",
            "38101\n",
            "0.4375665706293409\n",
            "38102\n",
            "0.4375665706293409\n",
            "38103\n",
            "0.43758134571397256\n",
            "38104\n",
            "0.4375971918857812\n",
            "38105\n",
            "0.4376139120654236\n",
            "38106\n",
            "0.4376258100879669\n",
            "38107\n",
            "0.43764104706941076\n",
            "38108\n",
            "0.4376534525174564\n",
            "38109\n",
            "0.437671732106558\n",
            "38110\n",
            "0.437671732106558\n",
            "38111\n",
            "0.437671732106558\n",
            "38112\n",
            "0.4376880585943499\n",
            "38113\n",
            "0.43769935474901045\n",
            "38114\n",
            "0.4377139977033745\n",
            "38115\n",
            "0.43772843290362423\n",
            "38116\n",
            "0.43772843290362423\n",
            "38117\n",
            "0.43774249284274785\n",
            "38118\n",
            "0.43774249284274785\n",
            "38119\n",
            "0.43775541846415894\n",
            "38120\n",
            "0.43776914734921685\n",
            "38121\n",
            "0.4377840139248119\n",
            "38122\n",
            "0.4377953100794725\n",
            "38123\n",
            "0.4378090389645304\n",
            "38124\n",
            "0.4378280367564508\n",
            "38125\n",
            "0.43783791745105344\n",
            "38126\n",
            "0.43784904369032257\n",
            "38127\n",
            "0.4378627725753805\n",
            "38128\n",
            "0.43787814381632834\n",
            "38129\n",
            "0.4378908484054911\n",
            "38130\n",
            "0.4378908484054911\n",
            "38131\n",
            "0.43790826191100546\n",
            "38132\n",
            "0.43792423708612915\n",
            "38133\n",
            "0.43792423708612915\n",
            "38134\n",
            "0.43792423708612915\n",
            "38135\n",
            "0.437940563573921\n",
            "38136\n",
            "0.437940563573921\n",
            "38137\n",
            "0.437940563573921\n",
            "38138\n",
            "0.4379526192205109\n",
            "38139\n",
            "0.4379693394001532\n",
            "38140\n",
            "0.4379693394001532\n",
            "38141\n",
            "0.4379865058429967\n",
            "38142\n",
            "0.43799900709312173\n",
            "38143\n",
            "0.4380116420654773\n",
            "38144\n",
            "0.43802354008802064\n",
            "38145\n",
            "0.43802354008802064\n",
            "38146\n",
            "0.43803686507709005\n",
            "38147\n",
            "0.4380501094838436\n",
            "38148\n",
            "0.4380620075063869\n",
            "38149\n",
            "0.4380620075063869\n",
            "38150\n",
            "0.43807606744551053\n",
            "38151\n",
            "0.4380909340211056\n",
            "38152\n",
            "0.4380909340211056\n",
            "38153\n",
            "0.4381052385726222\n",
            "38154\n",
            "0.4381186720401167\n",
            "38155\n",
            "0.438129184296533\n",
            "38156\n",
            "0.43814324423565665\n",
            "38157\n",
            "0.43815996441529903\n",
            "38158\n",
            "0.438172465665424\n",
            "38159\n",
            "0.438172465665424\n",
            "38160\n",
            "0.438172465665424\n",
            "38161\n",
            "0.43818947673986436\n",
            "38162\n",
            "0.43818947673986436\n",
            "38163\n",
            "0.43820252041573254\n",
            "38164\n",
            "0.4382188469035245\n",
            "38165\n",
            "0.43823134815364945\n",
            "38166\n",
            "0.43824344487629124\n",
            "38167\n",
            "0.43825687834378574\n",
            "38168\n",
            "0.4382713135440355\n",
            "38169\n",
            "0.43828269971501277\n",
            "38170\n",
            "0.4382958670414416\n",
            "38171\n",
            "0.4382958670414416\n",
            "38172\n",
            "0.43831354647891496\n",
            "38173\n",
            "0.4383253694313227\n",
            "38174\n",
            "0.4383363042173935\n",
            "38175\n",
            "0.4383485285153842\n",
            "38176\n",
            "0.4383485285153842\n",
            "38177\n",
            "0.43836066702352766\n",
            "38178\n",
            "0.43837439590858557\n",
            "38179\n",
            "0.4383861461009081\n",
            "38180\n",
            "0.4384021212760318\n",
            "38181\n",
            "0.43841380089343673\n",
            "38182\n",
            "0.43843106739876475\n",
            "38183\n",
            "0.43844338060659815\n",
            "38184\n",
            "0.4384580235609622\n",
            "38185\n",
            "0.43847339480191005\n",
            "38186\n",
            "0.4384873399564192\n",
            "38187\n",
            "0.4384998412065442\n",
            "38188\n",
            "0.4385130085329731\n",
            "38189\n",
            "0.43852933502076497\n",
            "38190\n",
            "0.4385420396099277\n",
            "38191\n",
            "0.43855690618552273\n",
            "38192\n",
            "0.4385690446936662\n",
            "38193\n",
            "0.4385836167357558\n",
            "38194\n",
            "0.43859959191087955\n",
            "38195\n",
            "0.43859959191087955\n",
            "38196\n",
            "0.43861251753229064\n",
            "38197\n",
            "0.4386261847129328\n",
            "38198\n",
            "0.4386364276935766\n",
            "38199\n",
            "0.4386501170188468\n",
            "38200\n",
            "0.4386635504863413\n",
            "38201\n",
            "0.43867798568659105\n",
            "38202\n",
            "0.43867798568659105\n",
            "38203\n",
            "0.43869131067566053\n",
            "38204\n",
            "0.438704744143155\n",
            "38205\n",
            "0.438704744143155\n",
            "38206\n",
            "0.43871664216569833\n",
            "38207\n",
            "0.4387286177038882\n",
            "38208\n",
            "0.4387286177038882\n",
            "38209\n",
            "0.4387423465889461\n",
            "38210\n",
            "0.4387423465889461\n",
            "38211\n",
            "0.438756075474004\n",
            "38212\n",
            "0.4387701354131277\n",
            "38213\n",
            "0.43878271100498367\n",
            "38214\n",
            "0.43879563662639476\n",
            "38215\n",
            "0.43879563662639476\n",
            "38216\n",
            "0.43880761216458464\n",
            "38217\n",
            "0.43881951018712795\n",
            "38218\n",
            "0.43881951018712795\n",
            "38219\n",
            "0.43883069164516125\n",
            "38220\n",
            "0.438843396234324\n",
            "38221\n",
            "0.4388568297018185\n",
            "38222\n",
            "0.43886923514986415\n",
            "38223\n",
            "0.43888296403492205\n",
            "38224\n",
            "0.43889893921004575\n",
            "38225\n",
            "0.43891661864751913\n",
            "38226\n",
            "0.4389300521150137\n",
            "38227\n",
            "0.4389415533652676\n",
            "38228\n",
            "0.4389551801697503\n",
            "38229\n",
            "0.43896525035688494\n",
            "38230\n",
            "0.43897795494604763\n",
            "38231\n",
            "0.4389897778984554\n",
            "38232\n",
            "0.4390074573359288\n",
            "38233\n",
            "0.43902282857687663\n",
            "38234\n",
            "0.4390418263687971\n",
            "38235\n",
            "0.4390418263687971\n",
            "38236\n",
            "0.4390574423217671\n",
            "38237\n",
            "0.43906997634084977\n",
            "38238\n",
            "0.4390831436672786\n",
            "38239\n",
            "0.4390831436672786\n",
            "38240\n",
            "0.4390831436672786\n",
            "38241\n",
            "0.43909687255233654\n",
            "38242\n",
            "0.43910901106047995\n",
            "38243\n",
            "0.4391225882218627\n",
            "38244\n",
            "0.43913551384327376\n",
            "38245\n",
            "0.43915223402291614\n",
            "38246\n",
            "0.4391694004657596\n",
            "38247\n",
            "0.4391841531128403\n",
            "38248\n",
            "0.4391841531128403\n",
            "38249\n",
            "0.4391973204392692\n",
            "38250\n",
            "0.4392121870148642\n",
            "38251\n",
            "0.4392121870148642\n",
            "38252\n",
            "0.4392254840843135\n",
            "38253\n",
            "0.43923891755180805\n",
            "38254\n",
            "0.43925428879275585\n",
            "38255\n",
            "0.4392723570216074\n",
            "38256\n",
            "0.43928772826255524\n",
            "38257\n",
            "0.439302163462805\n",
            "38258\n",
            "0.43931533078923385\n",
            "38259\n",
            "0.4393274692973773\n",
            "38260\n",
            "0.43934211225174136\n",
            "38261\n",
            "0.4393522498017423\n",
            "38262\n",
            "0.4393522498017423\n",
            "38263\n",
            "0.4393522498017423\n",
            "38264\n",
            "0.4393522498017423\n",
            "38265\n",
            "0.43936475105186734\n",
            "38266\n",
            "0.43936475105186734\n",
            "38267\n",
            "0.4393789924470887\n",
            "38268\n",
            "0.43939799023900916\n",
            "38269\n",
            "0.4394079952435144\n",
            "38270\n",
            "0.4394243217313063\n",
            "38271\n",
            "0.43944052682415197\n",
            "38272\n",
            "0.43944951032530116\n",
            "38273\n",
            "0.4394635702644248\n",
            "38274\n",
            "0.4394635702644248\n",
            "38275\n",
            "0.43948008773776226\n",
            "38276\n",
            "0.43949381662282017\n",
            "38277\n",
            "0.4395094753010949\n",
            "38278\n",
            "0.4395094753010949\n",
            "38279\n",
            "0.4395206567591282\n",
            "38280\n",
            "0.43953143093203195\n",
            "38281\n",
            "0.4395445151796991\n",
            "38282\n",
            "0.4395445151796991\n",
            "38283\n",
            "0.43956049035482286\n",
            "38284\n",
            "0.4395745502939465\n",
            "38285\n",
            "0.43958992153489435\n",
            "38286\n",
            "0.4396062480226862\n",
            "38287\n",
            "0.4396177925929168\n",
            "38288\n",
            "0.4396177925929168\n",
            "38289\n",
            "0.43963376776804053\n",
            "38290\n",
            "0.4396494264463153\n",
            "38291\n",
            "0.43966479768726313\n",
            "38292\n",
            "0.4396782311547576\n",
            "38293\n",
            "0.4396904554527483\n",
            "38294\n",
            "0.43970601533316855\n",
            "38295\n",
            "0.4397223418209604\n",
            "38296\n",
            "0.4397366784816611\n",
            "38297\n",
            "0.4397533986613035\n",
            "38298\n",
            "0.4397665659877323\n",
            "38299\n",
            "0.43978143256332736\n",
            "38300\n",
            "0.43979911200080074\n",
            "38301\n",
            "0.4398154384885926\n",
            "38302\n",
            "0.43982538036689006\n",
            "38303\n",
            "0.4398415264238079\n",
            "38304\n",
            "0.4398592058612813\n",
            "38305\n",
            "0.43986948522964064\n",
            "38306\n",
            "0.43986948522964064\n",
            "38307\n",
            "0.4398839204298904\n",
            "38308\n",
            "0.4398839204298904\n",
            "38309\n",
            "0.439899028817716\n",
            "38310\n",
            "0.4399026170371175\n",
            "38311\n",
            "0.4399161070678313\n",
            "38312\n",
            "0.43993208224295505\n",
            "38313\n",
            "0.4399453528504435\n",
            "38314\n",
            "0.43995612702334724\n",
            "38315\n",
            "0.43995612702334724\n",
            "38316\n",
            "0.43995612702334724\n",
            "38317\n",
            "0.43996754400968324\n",
            "38318\n",
            "0.4399807113361121\n",
            "38319\n",
            "0.43999321258623714\n",
            "38320\n",
            "0.4400083209740627\n",
            "38321\n",
            "0.4400250411537051\n",
            "38322\n",
            "0.4400250411537051\n",
            "38323\n",
            "0.4400440389456256\n",
            "38324\n",
            "0.4400577678306835\n",
            "38325\n",
            "0.44007220303093325\n",
            "38326\n",
            "0.44007220303093325\n",
            "38327\n",
            "0.4400832227867646\n",
            "38328\n",
            "0.4400965198562139\n",
            "38329\n",
            "0.4401107612514353\n",
            "38330\n",
            "0.44012465073555374\n",
            "38331\n",
            "0.4401378180619826\n",
            "38332\n",
            "0.4401378180619826\n",
            "38333\n",
            "0.44015246101634664\n",
            "38334\n",
            "0.44015246101634664\n",
            "38335\n",
            "0.44016732759194166\n",
            "38336\n",
            "0.4401798288420667\n",
            "38337\n",
            "0.44019261956896993\n",
            "38338\n",
            "0.4402093397486123\n",
            "38339\n",
            "0.44022605992825464\n",
            "38340\n",
            "0.4402381984363981\n",
            "38341\n",
            "0.4402530650119932\n",
            "38342\n",
            "0.44026793158758826\n",
            "38343\n",
            "0.44028236678783794\n",
            "38344\n",
            "0.44028236678783794\n",
            "38345\n",
            "0.44028236678783794\n",
            "38346\n",
            "0.44029467999567135\n",
            "38347\n",
            "0.44029467999567135\n",
            "38348\n",
            "0.44029467999567135\n",
            "38349\n",
            "0.44030873993479497\n",
            "38350\n",
            "0.4403213408043501\n",
            "38351\n",
            "0.44033211497725383\n",
            "38352\n",
            "0.4403484414650457\n",
            "38353\n",
            "0.4403633080406408\n",
            "38354\n",
            "0.4403768364502081\n",
            "38355\n",
            "0.4403768364502081\n",
            "38356\n",
            "0.44039072593432654\n",
            "38357\n",
            "0.44039072593432654\n",
            "38358\n",
            "0.44040744611396887\n",
            "38359\n",
            "0.4404199473640939\n",
            "38360\n",
            "0.4404199473640939\n",
            "38361\n",
            "0.440434813939689\n",
            "38362\n",
            "0.440434813939689\n",
            "38363\n",
            "0.44044678947787885\n",
            "38364\n",
            "0.4404621607188267\n",
            "38365\n",
            "0.4404753280452556\n",
            "38366\n",
            "0.4404753280452556\n",
            "38367\n",
            "0.4404842745002501\n",
            "38368\n",
            "0.44049964574119793\n",
            "38369\n",
            "0.44051370568032155\n",
            "38370\n",
            "0.44051370568032155\n",
            "38371\n",
            "0.44052788528929127\n",
            "38372\n",
            "0.44054212668451265\n",
            "38373\n",
            "0.44055370478522765\n",
            "38374\n",
            "0.44057042496487003\n",
            "38375\n",
            "0.4405829608196502\n",
            "38376\n",
            "0.4405955957920058\n",
            "38377\n",
            "0.4405955957920058\n",
            "38378\n",
            "0.4406119222797977\n",
            "38379\n",
            "0.4406263574800474\n",
            "38380\n",
            "0.4406400094495579\n",
            "38381\n",
            "0.44065317677598675\n",
            "38382\n",
            "0.44066567802611173\n",
            "38383\n",
            "0.44066567802611173\n",
            "38384\n",
            "0.4406805446017068\n",
            "38385\n",
            "0.4406805446017068\n",
            "38386\n",
            "0.44069954239362724\n",
            "38387\n",
            "0.4407149136345751\n",
            "38388\n",
            "0.4407264582048057\n",
            "38389\n",
            "0.440739755274255\n",
            "38390\n",
            "0.4407529226006839\n",
            "38391\n",
            "0.44076707181374686\n",
            "38392\n",
            "0.4407792103218903\n",
            "38393\n",
            "0.4407921359433014\n",
            "38394\n",
            "0.44080619588242503\n",
            "38395\n",
            "0.44082106245802005\n",
            "38396\n",
            "0.4408332009661635\n",
            "38397\n",
            "0.4408499211458059\n",
            "38398\n",
            "0.44086435634605564\n",
            "38399\n",
            "0.44087841628517926\n",
            "38400\n",
            "0.44089352467300486\n",
            "38401\n",
            "0.4409088959139527\n",
            "38402\n",
            "0.4409220632403816\n",
            "38403\n",
            "0.4409220632403816\n",
            "38404\n",
            "0.44093974267785496\n",
            "38405\n",
            "0.44095188118599843\n",
            "38406\n",
            "0.44096686622972864\n",
            "38407\n",
            "0.44098029969722313\n",
            "38408\n",
            "0.44099107387012687\n",
            "38409\n",
            "0.4410055090703766\n",
            "38410\n",
            "0.4410155792575112\n",
            "38411\n",
            "0.4410298206527326\n",
            "38412\n",
            "0.4410298206527326\n",
            "38413\n",
            "0.4410298206527326\n",
            "38414\n",
            "0.4410298206527326\n",
            "38415\n",
            "0.44104519189368047\n",
            "38416\n",
            "0.4410596270939302\n",
            "38417\n",
            "0.4410596270939302\n",
            "38418\n",
            "0.4410596270939302\n",
            "38419\n",
            "0.4410596270939302\n",
            "38420\n",
            "0.4410719859916314\n",
            "38421\n",
            "0.4410844872417564\n",
            "38422\n",
            "0.4410967115397471\n",
            "38423\n",
            "0.4411117371387702\n",
            "38424\n",
            "0.44112466276018125\n",
            "38425\n",
            "0.4411427309890328\n",
            "38426\n",
            "0.4411583896673075\n",
            "38427\n",
            "0.4411583896673075\n",
            "38428\n",
            "0.4411583896673075\n",
            "38429\n",
            "0.441170528175451\n",
            "38430\n",
            "0.4411828413832844\n",
            "38431\n",
            "0.44119422755426163\n",
            "38432\n",
            "0.4412038809544791\n",
            "38433\n",
            "0.4412173144219736\n",
            "38434\n",
            "0.4412279104480116\n",
            "38435\n",
            "0.4412404116981366\n",
            "38436\n",
            "0.44125233528048896\n",
            "38437\n",
            "0.4412663952196126\n",
            "38438\n",
            "0.44128063661483397\n",
            "38439\n",
            "0.44129436549989187\n",
            "38440\n",
            "0.44129436549989187\n",
            "38441\n",
            "0.44131069198768375\n",
            "38442\n",
            "0.44132329285723887\n",
            "38443\n",
            "0.4413339320451724\n",
            "38444\n",
            "0.44134575499758016\n",
            "38445\n",
            "0.4413630215029082\n",
            "38446\n",
            "0.4413770814420318\n",
            "38447\n",
            "0.4413909163495188\n",
            "38448\n",
            "0.4413909163495188\n",
            "38449\n",
            "0.4414022125041794\n",
            "38450\n",
            "0.441416272443303\n",
            "38451\n",
            "0.44142877369342803\n",
            "38452\n",
            "0.44143945693691233\n",
            "38453\n",
            "0.44145543211203603\n",
            "38454\n",
            "0.4414685163597032\n",
            "38455\n",
            "0.44149351885995325\n",
            "38456\n",
            "0.441509177538228\n",
            "38457\n",
            "0.441509177538228\n",
            "38458\n",
            "0.441522103159639\n",
            "38459\n",
            "0.44153378277704397\n",
            "38460\n",
            "0.44154915401799183\n",
            "38461\n",
            "0.4415633954132132\n",
            "38462\n",
            "0.44157728489733167\n",
            "38463\n",
            "0.44159496433480505\n",
            "38464\n",
            "0.4416076689239678\n",
            "38465\n",
            "0.44161998213180115\n",
            "38466\n",
            "0.44163314945823\n",
            "38467\n",
            "0.4416468783432879\n",
            "38468\n",
            "0.4416468783432879\n",
            "38469\n",
            "0.441661744918883\n",
            "38470\n",
            "0.4416777200940067\n",
            "38471\n",
            "0.4416915767033761\n",
            "38472\n",
            "0.44170185607173545\n",
            "38473\n",
            "0.44171953550920884\n",
            "38474\n",
            "0.4417298148775682\n",
            "38475\n",
            "0.4417298148775682\n",
            "38476\n",
            "0.44174231612769316\n",
            "38477\n",
            "0.44175467551443065\n",
            "38478\n",
            "0.4417651072112219\n",
            "38479\n",
            "0.4417761795688143\n",
            "38480\n",
            "0.4417910461444094\n",
            "38481\n",
            "0.4418070213195331\n",
            "38482\n",
            "0.44182075020459105\n",
            "38483\n",
            "0.4418348101437147\n",
            "38484\n",
            "0.441847123351548\n",
            "38485\n",
            "0.4418619899271431\n",
            "38486\n",
            "0.4418754233946376\n",
            "38487\n",
            "0.4418863917749169\n",
            "38488\n",
            "0.4418863917749169\n",
            "38489\n",
            "0.44190236695004065\n",
            "38490\n",
            "0.44191723352563567\n",
            "38491\n",
            "0.4419326047665835\n",
            "38492\n",
            "0.4419489312543754\n",
            "38493\n",
            "0.44196594232881575\n",
            "38494\n",
            "0.44197967121387366\n",
            "38495\n",
            "0.4419941064141234\n",
            "38496\n",
            "0.44201310420604384\n",
            "38497\n",
            "0.44202683309110175\n",
            "38498\n",
            "0.4420422043320496\n",
            "38499\n",
            "0.44205663953229934\n",
            "38500\n",
            "0.4420687780404428\n",
            "38501\n",
            "0.4420687780404428\n",
            "38502\n",
            "0.44208414928139067\n",
            "38503\n",
            "0.4420998079596654\n",
            "38504\n",
            "0.4421157831347891\n",
            "38505\n",
            "0.44213021833503885\n",
            "38506\n",
            "0.44213021833503885\n",
            "38507\n",
            "0.4421455895759867\n",
            "38508\n",
            "0.4421571341462173\n",
            "38509\n",
            "0.44216810252649663\n",
            "38510\n",
            "0.44218183141155454\n",
            "38511\n",
            "0.4421949987379834\n",
            "38512\n",
            "0.44221541319395213\n",
            "38513\n",
            "0.44221541319395213\n",
            "38514\n",
            "0.4422274418400442\n",
            "38515\n",
            "0.4422394173782341\n",
            "38516\n",
            "0.44225539255335783\n",
            "38517\n",
            "0.44226945249248145\n",
            "38518\n",
            "0.44228456088030704\n",
            "38519\n",
            "0.4422999321212549\n",
            "38520\n",
            "0.44231479869685\n",
            "38521\n",
            "0.4423248037013552\n",
            "38522\n",
            "0.4423392389016049\n",
            "38523\n",
            "0.4423531283857234\n",
            "38524\n",
            "0.4423667055471061\n",
            "38525\n",
            "0.4423667055471061\n",
            "38526\n",
            "0.442380434432164\n",
            "38527\n",
            "0.442392935682289\n",
            "38528\n",
            "0.44240830692323685\n",
            "38529\n",
            "0.44240830692323685\n",
            "38530\n",
            "0.44242062013107025\n",
            "38531\n",
            "0.44243216470130087\n",
            "38532\n",
            "0.44243216470130087\n",
            "38533\n",
            "0.4424431330815802\n",
            "38534\n",
            "0.4424557339511353\n",
            "38535\n",
            "0.4424557339511353\n",
            "38536\n",
            "0.4424557339511353\n",
            "38537\n",
            "0.44246890127756416\n",
            "38538\n",
            "0.44246890127756416\n",
            "38539\n",
            "0.44246890127756416\n",
            "38540\n",
            "0.4424837678531592\n",
            "38541\n",
            "0.4424837678531592\n",
            "38542\n",
            "0.4424936485477618\n",
            "38543\n",
            "0.4424936485477618\n",
            "38544\n",
            "0.44250808374801154\n",
            "38545\n",
            "0.44250808374801154\n",
            "38546\n",
            "0.44250808374801154\n",
            "38547\n",
            "0.4425244102358034\n",
            "38548\n",
            "0.44253691148592844\n",
            "38549\n",
            "0.4425510910948981\n",
            "38550\n",
            "0.4425510910948981\n",
            "38551\n",
            "0.44256425842132696\n",
            "38552\n",
            "0.44256425842132696\n",
            "38553\n",
            "0.4425794519301982\n",
            "38554\n",
            "0.4425794519301982\n",
            "38555\n",
            "0.4425923775516093\n",
            "38556\n",
            "0.44260554487803816\n",
            "38557\n",
            "0.4426194900325473\n",
            "38558\n",
            "0.4426194900325473\n",
            "38559\n",
            "0.44263292350004185\n",
            "38560\n",
            "0.4426467584075288\n",
            "38561\n",
            "0.4426574416510131\n",
            "38562\n",
            "0.4426746080938566\n",
            "38563\n",
            "0.4426897164816822\n",
            "38564\n",
            "0.44270415168193195\n",
            "38565\n",
            "0.44271692784907685\n",
            "38566\n",
            "0.44272853896137254\n",
            "38567\n",
            "0.44274259890049616\n",
            "38568\n",
            "0.4427533730733999\n",
            "38569\n",
            "0.4427645545314332\n",
            "38570\n",
            "0.4427778516008825\n",
            "38571\n",
            "0.44279887611371516\n",
            "38572\n",
            "0.44281485128883885\n",
            "38573\n",
            "0.4428279560608792\n",
            "38574\n",
            "0.44284153322226194\n",
            "38575\n",
            "0.4428579857926809\n",
            "38576\n",
            "0.4428579857926809\n",
            "38577\n",
            "0.44287115311910974\n",
            "38578\n",
            "0.44288365436923477\n",
            "38579\n",
            "0.44289571001582456\n",
            "38580\n",
            "0.44289571001582456\n",
            "38581\n",
            "0.44290671940010956\n",
            "38582\n",
            "0.4429198036477767\n",
            "38583\n",
            "0.44293353253283463\n",
            "38584\n",
            "0.44293353253283463\n",
            "38585\n",
            "0.4429462371219974\n",
            "38586\n",
            "0.44296110369759245\n",
            "38587\n",
            "0.44297528330656216\n",
            "38588\n",
            "0.44297528330656216\n",
            "38589\n",
            "0.44298845063299097\n",
            "38590\n",
            "0.4430001302503959\n",
            "38591\n",
            "0.4430178096878693\n",
            "38592\n",
            "0.4430301228957027\n",
            "38593\n",
            "0.443040806139187\n",
            "38594\n",
            "0.4430535107283497\n",
            "38595\n",
            "0.44306694419584425\n",
            "38596\n",
            "0.4430815871502083\n",
            "38597\n",
            "0.4430940884003333\n",
            "38598\n",
            "0.4431039097487406\n",
            "38599\n",
            "0.4431164109988656\n",
            "38600\n",
            "0.44313084619911536\n",
            "38601\n",
            "0.4431457127747104\n",
            "38602\n",
            "0.44315888010113924\n",
            "38603\n",
            "0.44317260898619715\n",
            "38604\n",
            "0.4431851102363222\n",
            "38605\n",
            "0.4431978148254849\n",
            "38606\n",
            "0.4432129232133105\n",
            "38607\n",
            "0.44322542446343555\n",
            "38608\n",
            "0.44324139963855924\n",
            "38609\n",
            "0.443254104227722\n",
            "38610\n",
            "0.4432660022502653\n",
            "38611\n",
            "0.4432760724373999\n",
            "38612\n",
            "0.44328736859206047\n",
            "38613\n",
            "0.44330223516765555\n",
            "38614\n",
            "0.4433152191455\n",
            "38615\n",
            "0.443326665858668\n",
            "38616\n",
            "0.4433407257977916\n",
            "38617\n",
            "0.44335583418561725\n",
            "38618\n",
            "0.44337026938586693\n",
            "38619\n",
            "0.4433829739750297\n",
            "38620\n",
            "0.44339834521597754\n",
            "38621\n",
            "0.4434110498051403\n",
            "38622\n",
            "0.44342737629293216\n",
            "38623\n",
            "0.44344274753388\n",
            "38624\n",
            "0.44345872270900377\n",
            "38625\n",
            "0.44345872270900377\n",
            "38626\n",
            "0.44345872270900377\n",
            "38627\n",
            "0.4434740939499516\n",
            "38628\n",
            "0.44348623245809504\n",
            "38629\n",
            "0.4434989370472578\n",
            "38630\n",
            "0.44351337224750753\n",
            "38631\n",
            "0.4435262978689186\n",
            "38632\n",
            "0.4435426243567105\n",
            "38633\n",
            "0.4435551256068355\n",
            "38634\n",
            "0.4435688149321057\n",
            "38635\n",
            "0.4435864943695791\n",
            "38636\n",
            "0.44359855001616894\n",
            "38637\n",
            "0.44359855001616894\n",
            "38638\n",
            "0.44359855001616894\n",
            "38639\n",
            "0.4436139212571168\n",
            "38640\n",
            "0.4436139212571168\n",
            "38641\n",
            "0.4436316006945901\n",
            "38642\n",
            "0.443644768021019\n",
            "38643\n",
            "0.4436592032212687\n",
            "38644\n",
            "0.4436592032212687\n",
            "38645\n",
            "0.4436755297090606\n",
            "38646\n",
            "0.4436861257350986\n",
            "38647\n",
            "0.4437032921779421\n",
            "38648\n",
            "0.44371645950437094\n",
            "38649\n",
            "0.44373132607996596\n",
            "38650\n",
            "0.44374550568893567\n",
            "38651\n",
            "0.44375748122712555\n",
            "38652\n",
            "0.4437687773817861\n",
            "38653\n",
            "0.4437687773817861\n",
            "38654\n",
            "0.4437815901048615\n",
            "38655\n",
            "0.44379502357235606\n",
            "38656\n",
            "0.44380699911054594\n",
            "38657\n",
            "0.44382105904966956\n",
            "38658\n",
            "0.44383592562526464\n",
            "38659\n",
            "0.44385079220085966\n",
            "38660\n",
            "0.4438646271083467\n",
            "38661\n",
            "0.4438646271083467\n",
            "38662\n",
            "0.44387645006075443\n",
            "38663\n",
            "0.44387645006075443\n",
            "38664\n",
            "0.4438891546499172\n",
            "38665\n",
            "0.44390452589086504\n",
            "38666\n",
            "0.44391939246646006\n",
            "38667\n",
            "0.4439334524055837\n",
            "38668\n",
            "0.44394463386361704\n",
            "38669\n",
            "0.44395666250970905\n",
            "38670\n",
            "0.4439693670988718\n",
            "38671\n",
            "0.4439865335417153\n",
            "38672\n",
            "0.44399681291007465\n",
            "38673\n",
            "0.4440112481103244\n",
            "38674\n",
            "0.44402417373173547\n",
            "38675\n",
            "0.44402417373173547\n",
            "38676\n",
            "0.44403620237782754\n",
            "38677\n",
            "0.4440481779160174\n",
            "38678\n",
            "0.44406645750511897\n",
            "38679\n",
            "0.44407962483154784\n",
            "38680\n",
            "0.4440914477839556\n",
            "38681\n",
            "0.44410631435955067\n",
            "38682\n",
            "0.4441200432446086\n",
            "38683\n",
            "0.4441341031837322\n",
            "38684\n",
            "0.4441457142960279\n",
            "38685\n",
            "0.4441586399174389\n",
            "38686\n",
            "0.44417156553885\n",
            "38687\n",
            "0.44417156553885\n",
            "38688\n",
            "0.4441858069340714\n",
            "38689\n",
            "0.44420024213432113\n",
            "38690\n",
            "0.4442169623139635\n",
            "38691\n",
            "0.44422988793537455\n",
            "38692\n",
            "0.4442466081150169\n",
            "38693\n",
            "0.44425815268524754\n",
            "38694\n",
            "0.4442735239261954\n",
            "38695\n",
            "0.44428669125262427\n",
            "38696\n",
            "0.4442983708700292\n",
            "38697\n",
            "0.4443137421109771\n",
            "38698\n",
            "0.4443286086865721\n",
            "38699\n",
            "0.4443457751294156\n",
            "38700\n",
            "0.4443598350685392\n",
            "38701\n",
            "0.44437520630948707\n",
            "38702\n",
            "0.44438734481763054\n",
            "38703\n",
            "0.44439888938786115\n",
            "38704\n",
            "0.4444106395801837\n",
            "38705\n",
            "0.4444252116222733\n",
            "38706\n",
            "0.4444400781978683\n",
            "38707\n",
            "0.4444400781978683\n",
            "38708\n",
            "0.44445312187373653\n",
            "38709\n",
            "0.44445312187373653\n",
            "38710\n",
            "0.44446230293251715\n",
            "38711\n",
            "0.4444767381327669\n",
            "38712\n",
            "0.44449239681104163\n",
            "38713\n",
            "0.4445042570015558\n",
            "38714\n",
            "0.4445170697246313\n",
            "38715\n",
            "0.44452957097475626\n",
            "38716\n",
            "0.4445449422157041\n",
            "38717\n",
            "0.4445557163886079\n",
            "38718\n",
            "0.4445710876295557\n",
            "38719\n",
            "0.44458506104186835\n",
            "38720\n",
            "0.44460054408102473\n",
            "38721\n",
            "0.44460054408102473\n",
            "38722\n",
            "0.4446159153219726\n",
            "38723\n",
            "0.4446294437315399\n",
            "38724\n",
            "0.44464287719903445\n",
            "38725\n",
            "0.4446567121065214\n",
            "38726\n",
            "0.4446567121065214\n",
            "38727\n",
            "0.4446715786821165\n",
            "38728\n",
            "0.44468474600854535\n",
            "38729\n",
            "0.44468474600854535\n",
            "38730\n",
            "0.444705770521378\n",
            "38731\n",
            "0.4447177460595679\n",
            "38732\n",
            "0.4447177460595679\n",
            "38733\n",
            "0.4447316026689373\n",
            "38734\n",
            "0.444744722375852\n",
            "38735\n",
            "0.444744722375852\n",
            "38736\n",
            "0.44475742696501475\n",
            "38737\n",
            "0.4447705112126819\n",
            "38738\n",
            "0.44478420053795215\n",
            "38739\n",
            "0.444800527025744\n",
            "38740\n",
            "0.4448158982666919\n",
            "38741\n",
            "0.4448318734418156\n",
            "38742\n",
            "0.4448454506031983\n",
            "38743\n",
            "0.44486313004067163\n",
            "38744\n",
            "0.44486313004067163\n",
            "38745\n",
            "0.444880809478145\n",
            "38746\n",
            "0.444880809478145\n",
            "38747\n",
            "0.4448956760537401\n",
            "38748\n",
            "0.44490798926157343\n",
            "38749\n",
            "0.44492318277044474\n",
            "38750\n",
            "0.44493661623793923\n",
            "38751\n",
            "0.44493661623793923\n",
            "38752\n",
            "0.44495105143818897\n",
            "38753\n",
            "0.4449665630703372\n",
            "38754\n",
            "0.44497824268774216\n",
            "38755\n",
            "0.4449918198491249\n",
            "38756\n",
            "0.4449918198491249\n",
            "38757\n",
            "0.4450047370338544\n",
            "38758\n",
            "0.44501836383833715\n",
            "38759\n",
            "0.4450310684274999\n",
            "38760\n",
            "0.4450453729790165\n",
            "38761\n",
            "0.4450453729790165\n",
            "38762\n",
            "0.4450594329181401\n",
            "38763\n",
            "0.44507283854410157\n",
            "38764\n",
            "0.44507283854410157\n",
            "38765\n",
            "0.4450882097850494\n",
            "38766\n",
            "0.44510720757696987\n",
            "38767\n",
            "0.44512093646202777\n",
            "38768\n",
            "0.4451372629498197\n",
            "38769\n",
            "0.4451504302762485\n",
            "38770\n",
            "0.44516313486541126\n",
            "38771\n",
            "0.445175322025865\n",
            "38772\n",
            "0.4451844618204159\n",
            "38773\n",
            "0.4451971664095786\n",
            "38774\n",
            "0.4451971664095786\n",
            "38775\n",
            "0.44521122634870225\n",
            "38776\n",
            "0.44522465981619674\n",
            "38777\n",
            "0.4452400310571446\n",
            "38778\n",
            "0.44525319838357347\n",
            "38779\n",
            "0.4452685696245213\n",
            "38780\n",
            "0.44528240453200835\n",
            "38781\n",
            "0.4452945430401518\n",
            "38782\n",
            "0.4453105182152755\n",
            "38783\n",
            "0.4453253847908706\n",
            "38784\n",
            "0.4453253847908706\n",
            "38785\n",
            "0.44534057829974183\n",
            "38786\n",
            "0.44535491496044244\n",
            "38787\n",
            "0.44535491496044244\n",
            "38788\n",
            "0.4453659873180349\n",
            "38789\n",
            "0.4453827074976773\n",
            "38790\n",
            "0.44539688710664693\n",
            "38791\n",
            "0.4454096090656613\n",
            "38792\n",
            "0.4454228621772548\n",
            "38793\n",
            "0.44543556676641755\n",
            "38794\n",
            "0.4454498081616389\n",
            "38795\n",
            "0.4454632416291334\n",
            "38796\n",
            "0.4454632416291334\n",
            "38797\n",
            "0.4454764089555623\n",
            "38798\n",
            "0.4454898424230568\n",
            "38799\n",
            "0.4455019569656182\n",
            "38800\n",
            "0.4455019569656182\n",
            "38801\n",
            "0.44551732820656603\n",
            "38802\n",
            "0.445529007823971\n",
            "38803\n",
            "0.44554253051776516\n",
            "38804\n",
            "0.44555925069740754\n",
            "38805\n",
            "0.4455742762964306\n",
            "38806\n",
            "0.44558752940802404\n",
            "38807\n",
            "0.4456031880862988\n",
            "38808\n",
            "0.4456143034441473\n",
            "38809\n",
            "0.4456280323292052\n",
            "38810\n",
            "0.44563921378723853\n",
            "38811\n",
            "0.44565327372636215\n",
            "38812\n",
            "0.4456657749764872\n",
            "38813\n",
            "0.44568345441396057\n",
            "38814\n",
            "0.44568345441396057\n",
            "38815\n",
            "0.4456996004708784\n",
            "38816\n",
            "0.4456996004708784\n",
            "38817\n",
            "0.44571313767941595\n",
            "38818\n",
            "0.44571313767941595\n",
            "38819\n",
            "0.44572657114691044\n",
            "38820\n",
            "0.44572657114691044\n",
            "38821\n",
            "0.4457388843547438\n",
            "38822\n",
            "0.44575454303301854\n",
            "38823\n",
            "0.4457679765005131\n",
            "38824\n",
            "0.44577979945292084\n",
            "38825\n",
            "0.4457917749911107\n",
            "38826\n",
            "0.44580583493023435\n",
            "38827\n",
            "0.4458230013730778\n",
            "38828\n",
            "0.4458332086010622\n",
            "38829\n",
            "0.445853092357657\n",
            "38830\n",
            "0.445866416155019\n",
            "38831\n",
            "0.4458843831573174\n",
            "38832\n",
            "0.4458990261116814\n",
            "38833\n",
            "0.4459109496940338\n",
            "38834\n",
            "0.4459246785790917\n",
            "38835\n",
            "0.4459246785790917\n",
            "38836\n",
            "0.4459381120465862\n",
            "38837\n",
            "0.4459552784894297\n",
            "38838\n",
            "0.44596710144183743\n",
            "38839\n",
            "0.4459830766169611\n",
            "38840\n",
            "0.44599632972855463\n",
            "38841\n",
            "0.4460126562163465\n",
            "38842\n",
            "0.4460126562163465\n",
            "38843\n",
            "0.4460250305337879\n",
            "38844\n",
            "0.4460374048512293\n",
            "38845\n",
            "0.4460374048512293\n",
            "38846\n",
            "0.4460374048512293\n",
            "38847\n",
            "0.4460497180590626\n",
            "38848\n",
            "0.44606301512851193\n",
            "38849\n",
            "0.4460764485960064\n",
            "38850\n",
            "0.4460931687756488\n",
            "38851\n",
            "0.44610484839305375\n",
            "38852\n",
            "0.44612156857269614\n",
            "38853\n",
            "0.4461360037729459\n",
            "38854\n",
            "0.4461360037729459\n",
            "38855\n",
            "0.44614850502307085\n",
            "38856\n",
            "0.44616522520271323\n",
            "38857\n",
            "0.4461803335905389\n",
            "38858\n",
            "0.44619705377018126\n",
            "38859\n",
            "0.4462111137093049\n",
            "38860\n",
            "0.44622744019709676\n",
            "38861\n",
            "0.44624087366459125\n",
            "38862\n",
            "0.44624087366459125\n",
            "38863\n",
            "0.4462549336037149\n",
            "38864\n",
            "0.4462680533106296\n",
            "38865\n",
            "0.4462827511812748\n",
            "38866\n",
            "0.4462958191245519\n",
            "38867\n",
            "0.44631119036549977\n",
            "38868\n",
            "0.4463258333198638\n",
            "38869\n",
            "0.4463421598076557\n",
            "38870\n",
            "0.4463565950079054\n",
            "38871\n",
            "0.44636890821573877\n",
            "38872\n",
            "0.4463824853771215\n",
            "38873\n",
            "0.44639692057737124\n",
            "38874\n",
            "0.4464094218274962\n",
            "38875\n",
            "0.4464094218274962\n",
            "38876\n",
            "0.4464231507125542\n",
            "38877\n",
            "0.44643658418004867\n",
            "38878\n",
            "0.4464503130651066\n",
            "38879\n",
            "0.4464614393043757\n",
            "38880\n",
            "0.4464708417523532\n",
            "38881\n",
            "0.4464843644461473\n",
            "38882\n",
            "0.4464992310217424\n",
            "38883\n",
            "0.4465129599068003\n",
            "38884\n",
            "0.44652566449596304\n",
            "38885\n",
            "0.4465383690851258\n",
            "38886\n",
            "0.4465518025526203\n",
            "38887\n",
            "0.4465518025526203\n",
            "38888\n",
            "0.4465518025526203\n",
            "38889\n",
            "0.44656817645967806\n",
            "38890\n",
            "0.44656817645967806\n",
            "38891\n",
            "0.4465828194140421\n",
            "38892\n",
            "0.4465828194140421\n",
            "38893\n",
            "0.44659464236644986\n",
            "38894\n",
            "0.44660768604231804\n",
            "38895\n",
            "0.4466287105551507\n",
            "38896\n",
            "0.4466427704942743\n",
            "38897\n",
            "0.4466556961156854\n",
            "38898\n",
            "0.44667013131593514\n",
            "38899\n",
            "0.4466868514955775\n",
            "38900\n",
            "0.4466868514955775\n",
            "38901\n",
            "0.4467005803806354\n",
            "38902\n",
            "0.4467154469562305\n",
            "38903\n",
            "0.4467278524042761\n",
            "38904\n",
            "0.4467420937994975\n",
            "38905\n",
            "0.4467420937994975\n",
            "38906\n",
            "0.44675806897462117\n",
            "38907\n",
            "0.4467719584587396\n",
            "38908\n",
            "0.446789637896213\n",
            "38909\n",
            "0.446789637896213\n",
            "38910\n",
            "0.44679995430794145\n",
            "38911\n",
            "0.4468120928160849\n",
            "38912\n",
            "0.4468120928160849\n",
            "38913\n",
            "0.44682695939168\n",
            "38914\n",
            "0.4468439704661203\n",
            "38915\n",
            "0.4468562836739537\n",
            "38916\n",
            "0.4468690598410986\n",
            "38917\n",
            "0.4468690598410986\n",
            "38918\n",
            "0.44688768125271444\n",
            "38919\n",
            "0.4469008485791433\n",
            "38920\n",
            "0.4469143712729375\n",
            "38921\n",
            "0.44692524038164694\n",
            "38922\n",
            "0.4469396755818967\n",
            "38923\n",
            "0.4469541107821464\n",
            "38924\n",
            "0.44696897735774144\n",
            "38925\n",
            "0.4469849525328652\n",
            "38926\n",
            "0.4469849525328652\n",
            "38927\n",
            "0.4470032321219668\n",
            "38928\n",
            "0.4470199523016091\n",
            "38929\n",
            "0.4470340122407328\n",
            "38930\n",
            "0.44705117868357624\n",
            "38931\n",
            "0.44705117868357624\n",
            "38932\n",
            "0.447065613883826\n",
            "38933\n",
            "0.447078115133951\n",
            "38934\n",
            "0.44709483531359334\n",
            "38935\n",
            "0.4471082687810879\n",
            "38936\n",
            "0.4471082687810879\n",
            "38937\n",
            "0.4471082687810879\n",
            "38938\n",
            "0.4471217022485824\n",
            "38939\n",
            "0.4471217022485824\n",
            "38940\n",
            "0.44713410769662804\n",
            "38941\n",
            "0.4471464209044614\n",
            "38942\n",
            "0.44715958823089025\n",
            "38943\n",
            "0.447172292820053\n",
            "38944\n",
            "0.4471838373902836\n",
            "38945\n",
            "0.4471955638207205\n",
            "38946\n",
            "0.4472092531459907\n",
            "38947\n",
            "0.44722368834624043\n",
            "38948\n",
            "0.4472355112986482\n",
            "38949\n",
            "0.4472501114994045\n",
            "38950\n",
            "0.4472632788258334\n",
            "38951\n",
            "0.4472632788258334\n",
            "38952\n",
            "0.44727865006678125\n",
            "38953\n",
            "0.447290473019189\n",
            "38954\n",
            "0.44730347674458537\n",
            "38955\n",
            "0.4473191354228601\n",
            "38956\n",
            "0.4473313597208508\n",
            "38957\n",
            "0.44734733489597456\n",
            "38958\n",
            "0.4473613948350982\n",
            "38959\n",
            "0.44737811501474056\n",
            "38960\n",
            "0.44739483519438294\n",
            "38961\n",
            "0.44739483519438294\n",
            "38962\n",
            "0.44739483519438294\n",
            "38963\n",
            "0.44740970176997796\n",
            "38964\n",
            "0.44740970176997796\n",
            "38965\n",
            "0.4474250730109258\n",
            "38966\n",
            "0.4474250730109258\n",
            "38967\n",
            "0.4474250730109258\n",
            "38968\n",
            "0.447438116686794\n",
            "38969\n",
            "0.44745120093446117\n",
            "38970\n",
            "0.44746412655587225\n",
            "38971\n",
            "0.44747899313146733\n",
            "38972\n",
            "0.4474920773791345\n",
            "38973\n",
            "0.44750651257938423\n",
            "38974\n",
            "0.44750651257938423\n",
            "38975\n",
            "0.44751792956572023\n",
            "38976\n",
            "0.4475350960085637\n",
            "38977\n",
            "0.4475514224963556\n",
            "38978\n",
            "0.447565311980474\n",
            "38979\n",
            "0.4475801785560691\n",
            "38980\n",
            "0.44759302836411424\n",
            "38981\n",
            "0.44760675724917215\n",
            "38982\n",
            "0.4476207024036813\n",
            "38983\n",
            "0.4476331552921644\n",
            "38984\n",
            "0.44764704477628287\n",
            "38985\n",
            "0.4476611047154065\n",
            "38986\n",
            "0.4476749941995249\n",
            "38987\n",
            "0.44769096937464864\n",
            "38988\n",
            "0.447703691333663\n",
            "38989\n",
            "0.44771761408624516\n",
            "38990\n",
            "0.4477324806618402\n",
            "38991\n",
            "0.44774540628325127\n",
            "38992\n",
            "0.447761381458375\n",
            "38993\n",
            "0.447761381458375\n",
            "38994\n",
            "0.4477769835071847\n",
            "38995\n",
            "0.44779258555599444\n",
            "38996\n",
            "0.4478051527780675\n",
            "38997\n",
            "0.44781574880410546\n",
            "38998\n",
            "0.44783246898374784\n",
            "38999\n",
            "0.44783246898374784\n",
            "39000\n",
            "0.44784528170682325\n",
            "39001\n",
            "0.44784528170682325\n",
            "39002\n",
            "0.4478593416459469\n",
            "39003\n",
            "0.4478593416459469\n",
            "39004\n",
            "0.4478716548537803\n",
            "39005\n",
            "0.447884359442943\n",
            "39006\n",
            "0.4478955131207417\n",
            "39007\n",
            "0.4478955131207417\n",
            "39008\n",
            "0.4479103796963368\n",
            "39009\n",
            "0.4479215611543701\n",
            "39010\n",
            "0.44793247933479524\n",
            "39011\n",
            "0.44793247933479524\n",
            "39012\n",
            "0.44794620821985315\n",
            "39013\n",
            "0.4479576252061892\n",
            "39014\n",
            "0.44797206040643894\n",
            "39015\n",
            "0.44798498602785\n",
            "39016\n",
            "0.44800035726879783\n",
            "39017\n",
            "0.4480120368862028\n",
            "39018\n",
            "0.44802474147536553\n",
            "39019\n",
            "0.44803831863674826\n",
            "39020\n",
            "0.44805599807422164\n",
            "39021\n",
            "0.4480716567524964\n",
            "39022\n",
            "0.44808436134165913\n",
            "39023\n",
            "0.4480957171087042\n",
            "39024\n",
            "0.44810521600466446\n",
            "39025\n",
            "0.44810521600466446\n",
            "39026\n",
            "0.44811814162607555\n",
            "39027\n",
            "0.44813802538267034\n",
            "39028\n",
            "0.4481547455623127\n",
            "39029\n",
            "0.4481684744473706\n",
            "39030\n",
            "0.4481684744473706\n",
            "39031\n",
            "0.44818290964762036\n",
            "39032\n",
            "0.44819607697404923\n",
            "39033\n",
            "0.44819607697404923\n",
            "39034\n",
            "0.44821051217429897\n",
            "39035\n",
            "0.44822723235394135\n",
            "39036\n",
            "0.44824234074176694\n",
            "39037\n",
            "0.4482555080681958\n",
            "39038\n",
            "0.4482677955429568\n",
            "39039\n",
            "0.4482792125292928\n",
            "39040\n",
            "0.4482942381283159\n",
            "39041\n",
            "0.4483102133034396\n",
            "39042\n",
            "0.44832271455356465\n",
            "39043\n",
            "0.44832271455356465\n",
            "39044\n",
            "0.44832271455356465\n",
            "39045\n",
            "0.4483417123454851\n",
            "39046\n",
            "0.4483588787883286\n",
            "39047\n",
            "0.4483588787883286\n",
            "39048\n",
            "0.44837425002927644\n",
            "39049\n",
            "0.44839252961837806\n",
            "39050\n",
            "0.44840625850343596\n",
            "39051\n",
            "0.4484189630925987\n",
            "39052\n",
            "0.4484349382677224\n",
            "39053\n",
            "0.44844810559415127\n",
            "39054\n",
            "0.448458879767055\n",
            "39055\n",
            "0.448458879767055\n",
            "39056\n",
            "0.44847738368755935\n",
            "39057\n",
            "0.44849410386720173\n",
            "39058\n",
            "0.4485083452624231\n",
            "39059\n",
            "0.44852306088876764\n",
            "39060\n",
            "0.4485379274643627\n",
            "39061\n",
            "0.448551604832996\n",
            "39062\n",
            "0.4485687712758395\n",
            "39063\n",
            "0.4485816968972505\n",
            "39064\n",
            "0.4485816968972505\n",
            "39065\n",
            "0.4485935198496583\n",
            "39066\n",
            "0.4485935198496583\n",
            "39067\n",
            "0.4485935198496583\n",
            "39068\n",
            "0.4486106862925018\n",
            "39069\n",
            "0.44862250924490954\n",
            "39070\n",
            "0.44863623812996745\n",
            "39071\n",
            "0.44865295830960983\n",
            "39072\n",
            "0.4486689334847335\n",
            "39073\n",
            "0.44868011494276683\n",
            "39074\n",
            "0.4486928195319296\n",
            "39075\n",
            "0.4487078451309527\n",
            "39076\n",
            "0.4487078451309527\n",
            "39077\n",
            "0.4487217346150711\n",
            "39078\n",
            "0.4487217346150711\n",
            "39079\n",
            "0.4487357945541947\n",
            "39080\n",
            "0.4487506611297898\n",
            "39081\n",
            "0.4487643900148477\n",
            "39082\n",
            "0.4487767032226811\n",
            "39083\n",
            "0.44878838284008604\n",
            "39084\n",
            "0.4488028180403357\n",
            "39085\n",
            "0.4488162515078303\n",
            "39086\n",
            "0.4488295485772796\n",
            "39087\n",
            "0.4488455237524033\n",
            "39088\n",
            "0.4488645215443237\n",
            "39089\n",
            "0.4488812417239661\n",
            "39090\n",
            "0.4488812417239661\n",
            "39091\n",
            "0.4488941673453772\n",
            "39092\n",
            "0.44890733467180605\n",
            "39093\n",
            "0.44891823637191186\n",
            "39094\n",
            "0.44893196525696977\n",
            "39095\n",
            "0.4489453987244643\n",
            "39096\n",
            "0.4489564710820568\n",
            "39097\n",
            "0.4489564710820568\n",
            "39098\n",
            "0.4489774955948894\n",
            "39099\n",
            "0.44898980880272277\n",
            "39100\n",
            "0.44898980880272277\n",
            "39101\n",
            "0.4490051800436706\n",
            "39102\n",
            "0.4490051800436706\n",
            "39103\n",
            "0.449017554361112\n",
            "39104\n",
            "0.449017554361112\n",
            "39105\n",
            "0.4490347208039555\n",
            "39106\n",
            "0.4490478405108702\n",
            "39107\n",
            "0.44905952012827516\n",
            "39108\n",
            "0.4490708162829357\n",
            "39109\n",
            "0.4490708162829357\n",
            "39110\n",
            "0.4490875364625781\n",
            "39111\n",
            "0.4491052159000515\n",
            "39112\n",
            "0.4491183832264803\n",
            "39113\n",
            "0.44913244316560397\n",
            "39114\n",
            "0.449145368787015\n",
            "39115\n",
            "0.4491564950262842\n",
            "39116\n",
            "0.4491564950262842\n",
            "39117\n",
            "0.4491564950262842\n",
            "39118\n",
            "0.4491564950262842\n",
            "39119\n",
            "0.4491687193242749\n",
            "39120\n",
            "0.4491827792633985\n",
            "39121\n",
            "0.44919815050434636\n",
            "39122\n",
            "0.4492098301217513\n",
            "39123\n",
            "0.44922389006087493\n",
            "39124\n",
            "0.44924288785279537\n",
            "39125\n",
            "0.44925366202569916\n",
            "39126\n",
            "0.4492653185835298\n",
            "39127\n",
            "0.44928232965797016\n",
            "39128\n",
            "0.44929657105319154\n",
            "39129\n",
            "0.44929657105319154\n",
            "39130\n",
            "0.4493070833096079\n",
            "39131\n",
            "0.449320008931019\n",
            "39132\n",
            "0.4493316885484239\n",
            "39133\n",
            "0.4493476637235476\n",
            "39134\n",
            "0.449360667448944\n",
            "39135\n",
            "0.4493728917469347\n",
            "39136\n",
            "0.44938934431735367\n",
            "39137\n",
            "0.4494045378262249\n",
            "39138\n",
            "0.4494163607786327\n",
            "39139\n",
            "0.44942979424612717\n",
            "39140\n",
            "0.4494442294463769\n",
            "39141\n",
            "0.4494577338053432\n",
            "39142\n",
            "0.44946860291405266\n",
            "39143\n",
            "0.4494830381143024\n",
            "39144\n",
            "0.4494830381143024\n",
            "39145\n",
            "0.4494979046898975\n",
            "39146\n",
            "0.4495075580901149\n",
            "39147\n",
            "0.44952099155760944\n",
            "39148\n",
            "0.4495399893495299\n",
            "39149\n",
            "0.4495399893495299\n",
            "39150\n",
            "0.4495544245497796\n",
            "39151\n",
            "0.4495678580172741\n",
            "39152\n",
            "0.4495678580172741\n",
            "39153\n",
            "0.44958129148476866\n",
            "39154\n",
            "0.44959330674336523\n",
            "39155\n",
            "0.4496064740697941\n",
            "39156\n",
            "0.4496199075372886\n",
            "39157\n",
            "0.44963414893250997\n",
            "39158\n",
            "0.44963414893250997\n",
            "39159\n",
            "0.4496485841327597\n",
            "39160\n",
            "0.4496485841327597\n",
            "39161\n",
            "0.4496485841327597\n",
            "39162\n",
            "0.4496623130178176\n",
            "39163\n",
            "0.44967637295694124\n",
            "39164\n",
            "0.449692031635216\n",
            "39165\n",
            "0.4497060915743396\n",
            "39166\n",
            "0.44972052677458935\n",
            "39167\n",
            "0.4497336941010182\n",
            "39168\n",
            "0.4497336941010182\n",
            "39169\n",
            "0.4497336941010182\n",
            "39170\n",
            "0.4497466197224293\n",
            "39171\n",
            "0.4497597870488581\n",
            "39172\n",
            "0.44977228829898314\n",
            "39173\n",
            "0.4497828005553995\n",
            "39174\n",
            "0.4497950248533902\n",
            "39175\n",
            "0.4498052320813746\n",
            "39176\n",
            "0.44981763752942017\n",
            "39177\n",
            "0.4498291820996508\n",
            "39178\n",
            "0.44984280890413353\n",
            "39179\n",
            "0.449853678012843\n",
            "39180\n",
            "0.4498694387074459\n",
            "39181\n",
            "0.449882364328857\n",
            "39182\n",
            "0.4499000437663303\n",
            "39183\n",
            "0.44991186671873806\n",
            "39184\n",
            "0.44992400522688153\n",
            "39185\n",
            "0.44992400522688153\n",
            "39186\n",
            "0.4499352624957512\n",
            "39187\n",
            "0.4499352624957512\n",
            "39188\n",
            "0.4499506337366991\n",
            "39189\n",
            "0.44996565933572213\n",
            "39190\n",
            "0.4499805259113172\n",
            "39191\n",
            "0.4499934515327283\n",
            "39192\n",
            "0.45001244932464873\n",
            "39193\n",
            "0.45002488629886483\n",
            "39194\n",
            "0.4500378119202759\n",
            "39195\n",
            "0.4500537870953996\n",
            "39196\n",
            "0.4500678470345233\n",
            "39197\n",
            "0.450081473839006\n",
            "39198\n",
            "0.4500959090392557\n",
            "39199\n",
            "0.45011034423950547\n",
            "39200\n",
            "0.4501240731245634\n",
            "39201\n",
            "0.4501240731245634\n",
            "39202\n",
            "0.45014395688115816\n",
            "39203\n",
            "0.45015497663698956\n",
            "39204\n",
            "0.45016830162605903\n",
            "39205\n",
            "0.45019089393538025\n",
            "39206\n",
            "0.4502085733728536\n",
            "39207\n",
            "0.4502270772933579\n",
            "39208\n",
            "0.4502437974730003\n",
            "39209\n",
            "0.45025916871394817\n",
            "39210\n",
            "0.4502732286530718\n",
            "39211\n",
            "0.45029345834383017\n",
            "39212\n",
            "0.45029345834383017\n",
            "39213\n",
            "0.45030662567025903\n",
            "39214\n",
            "0.4503168328982434\n",
            "39215\n",
            "0.45033355307788575\n",
            "39216\n",
            "0.4503492117561605\n",
            "39217\n",
            "0.4503590331045678\n",
            "39218\n",
            "0.4503590331045678\n",
            "39219\n",
            "0.45037367605893186\n",
            "39220\n",
            "0.45038943675353477\n",
            "39221\n",
            "0.45040061821156807\n",
            "39222\n",
            "0.45041354383297916\n",
            "39223\n",
            "0.45042935680257695\n",
            "39224\n",
            "0.45044607698221933\n",
            "39225\n",
            "0.4504627971618617\n",
            "39226\n",
            "0.4504627971618617\n",
            "39227\n",
            "0.45047447677926666\n",
            "39228\n",
            "0.4504879102467612\n",
            "39229\n",
            "0.4504997331991689\n",
            "39230\n",
            "0.4505140377506855\n",
            "39231\n",
            "0.45052439188301285\n",
            "39232\n",
            "0.4505367973310585\n",
            "39233\n",
            "0.4505516639066536\n",
            "39234\n",
            "0.45056224291090796\n",
            "39235\n",
            "0.4505754102373368\n",
            "39236\n",
            "0.45059043583635994\n",
            "39237\n",
            "0.4506130281456811\n",
            "39238\n",
            "0.4506130281456811\n",
            "39239\n",
            "0.4506259537670922\n",
            "39240\n",
            "0.45063798241318426\n",
            "39241\n",
            "0.45065395758830795\n",
            "39242\n",
            "0.4506709686627483\n",
            "39243\n",
            "0.4506709686627483\n",
            "39244\n",
            "0.45068264828015325\n",
            "39245\n",
            "0.4506967082192769\n",
            "39246\n",
            "0.4507078896773102\n",
            "39247\n",
            "0.4507078896773102\n",
            "39248\n",
            "0.45071986521550006\n",
            "39249\n",
            "0.45073359410055797\n",
            "39250\n",
            "0.45073359410055797\n",
            "39251\n",
            "0.45074732298561593\n",
            "39252\n",
            "0.45076162753713245\n",
            "39253\n",
            "0.45077568747625607\n",
            "39254\n",
            "0.4507916626513798\n",
            "39255\n",
            "0.4507916626513798\n",
            "39256\n",
            "0.45080630560574386\n",
            "39257\n",
            "0.4508194729321727\n",
            "39258\n",
            "0.45083320181723063\n",
            "39259\n",
            "0.4508503682600741\n",
            "39260\n",
            "0.4508648034603238\n",
            "39261\n",
            "0.45088064963213254\n",
            "39262\n",
            "0.4508914238050363\n",
            "39263\n",
            "0.45090303491733197\n",
            "39264\n",
            "0.45091646838482646\n",
            "39265\n",
            "0.4509305283239501\n",
            "39266\n",
            "0.4509476947667936\n",
            "39267\n",
            "0.4509611282342881\n",
            "39268\n",
            "0.4509737804322765\n",
            "39269\n",
            "0.4509894391105512\n",
            "39270\n",
            "0.45100349904967485\n",
            "39271\n",
            "0.4510186074375005\n",
            "39272\n",
            "0.4510306630840903\n",
            "39273\n",
            "0.451042773655321\n",
            "39274\n",
            "0.45105650254037893\n",
            "39275\n",
            "0.4510656787695242\n",
            "39276\n",
            "0.4510656787695242\n",
            "39277\n",
            "0.4510656787695242\n",
            "39278\n",
            "0.4510833582069976\n",
            "39279\n",
            "0.45109872944794543\n",
            "39280\n",
            "0.4511148011541993\n",
            "39281\n",
            "0.45112837831558195\n",
            "39282\n",
            "0.4511426197108033\n",
            "39283\n",
            "0.45115726266516737\n",
            "39284\n",
            "0.451172371052993\n",
            "39285\n",
            "0.4511860999380509\n",
            "39286\n",
            "0.4512020751131746\n",
            "39287\n",
            "0.4512020751131746\n",
            "39288\n",
            "0.45121651031342436\n",
            "39289\n",
            "0.4512272844863281\n",
            "39290\n",
            "0.45123998907549084\n",
            "39291\n",
            "0.4512548556510859\n",
            "39292\n",
            "0.4512684328124686\n",
            "39293\n",
            "0.4512799773826992\n",
            "39294\n",
            "0.4512966975623416\n",
            "39295\n",
            "0.4513084477546641\n",
            "39296\n",
            "0.451322176639722\n",
            "39297\n",
            "0.45133661183997176\n",
            "39298\n",
            "0.4513535478084966\n",
            "39299\n",
            "0.451367437292615\n",
            "39300\n",
            "0.4513794128308049\n",
            "39301\n",
            "0.4513961330104473\n",
            "39302\n",
            "0.45140930033687615\n",
            "39303\n",
            "0.45142381686541544\n",
            "39304\n",
            "0.45143725033290993\n",
            "39305\n",
            "0.45143725033290993\n",
            "39306\n",
            "0.45143725033290993\n",
            "39307\n",
            "0.4514504176593388\n",
            "39308\n",
            "0.45146578890028666\n",
            "39309\n",
            "0.45147776443847654\n",
            "39310\n",
            "0.4514954438759499\n",
            "39311\n",
            "0.4514954438759499\n",
            "39312\n",
            "0.4514954438759499\n",
            "39313\n",
            "0.4515108151168978\n",
            "39314\n",
            "0.4515254580712618\n",
            "39315\n",
            "0.4515417845590537\n",
            "39316\n",
            "0.4515543351247323\n",
            "39317\n",
            "0.4515706616125242\n",
            "39318\n",
            "0.45158382893895305\n",
            "39319\n",
            "0.451595868348945\n",
            "39320\n",
            "0.45161097673677064\n",
            "39321\n",
            "0.45162441020426514\n",
            "39322\n",
            "0.45163542996009653\n",
            "39323\n",
            "0.4516531093975699\n",
            "39324\n",
            "0.4516531093975699\n",
            "39325\n",
            "0.45166402757799506\n",
            "39326\n",
            "0.45167616608613853\n",
            "39327\n",
            "0.45167616608613853\n",
            "39328\n",
            "0.4516957315999408\n",
            "39329\n",
            "0.451708775275809\n",
            "39330\n",
            "0.45172571124433386\n",
            "39331\n",
            "0.45173914471182836\n",
            "39332\n",
            "0.45173914471182836\n",
            "39333\n",
            "0.4517509676642361\n",
            "39334\n",
            "0.4517644011317306\n",
            "39335\n",
            "0.45178037630685436\n",
            "39336\n",
            "0.45179461770207574\n",
            "39337\n",
            "0.45180603468841174\n",
            "39338\n",
            "0.4518216933666865\n",
            "39339\n",
            "0.4518381459371055\n",
            "39340\n",
            "0.4518381459371055\n",
            "39341\n",
            "0.45185104603890264\n",
            "39342\n",
            "0.4518659126144977\n",
            "39343\n",
            "0.4518818877896214\n",
            "39344\n",
            "0.45189459237878415\n",
            "39345\n",
            "0.4519062719961891\n",
            "39346\n",
            "0.4519203319353127\n",
            "39347\n",
            "0.4519203319353127\n",
            "39348\n",
            "0.45193552544418397\n",
            "39349\n",
            "0.45193552544418397\n",
            "39350\n",
            "0.45194694243052\n",
            "39351\n",
            "0.45195975515359543\n",
            "39352\n",
            "0.4519729224800243\n",
            "39353\n",
            "0.4519880308678499\n",
            "39354\n",
            "0.45200000640603977\n",
            "39355\n",
            "0.45200000640603977\n",
            "39356\n",
            "0.45201633289383164\n",
            "39357\n",
            "0.45201633289383164\n",
            "39358\n",
            "0.4520323080689554\n",
            "39359\n",
            "0.45204398768636034\n",
            "39360\n",
            "0.45205804762548396\n",
            "39361\n",
            "0.45207291420107903\n",
            "39362\n",
            "0.45208828544202684\n",
            "39363\n",
            "0.4521017189095214\n",
            "39364\n",
            "0.45211792400236706\n",
            "39365\n",
            "0.45213084962377814\n",
            "39366\n",
            "0.45214355421294083\n",
            "39367\n",
            "0.4521576141520645\n",
            "39368\n",
            "0.4521576141520645\n",
            "39369\n",
            "0.45216891030672507\n",
            "39370\n",
            "0.45218141155685004\n",
            "39371\n",
            "0.4521958467570998\n",
            "39372\n",
            "0.4522130131999433\n",
            "39373\n",
            "0.4522130131999433\n",
            "39374\n",
            "0.4522270731390669\n",
            "39375\n",
            "0.45224244438001476\n",
            "39376\n",
            "0.45225441991820464\n",
            "39377\n",
            "0.45225441991820464\n",
            "39378\n",
            "0.4522660995356096\n",
            "39379\n",
            "0.45227926686203845\n",
            "39380\n",
            "0.4522969462995118\n",
            "39381\n",
            "0.4523091581554528\n",
            "39382\n",
            "0.4523207027256834\n",
            "39383\n",
            "0.4523377138001238\n",
            "39384\n",
            "0.4523517737392474\n",
            "39385\n",
            "0.452365833678371\n",
            "39386\n",
            "0.45238107065981487\n",
            "39387\n",
            "0.45239739714760674\n",
            "39388\n",
            "0.4524141173272491\n",
            "39389\n",
            "0.4524274143966984\n",
            "39390\n",
            "0.4524433895718221\n",
            "39391\n",
            "0.45245936474694587\n",
            "39392\n",
            "0.45245936474694587\n",
            "39393\n",
            "0.4524730936320038\n",
            "39394\n",
            "0.4524839953321096\n",
            "39395\n",
            "0.4524957455244321\n",
            "39396\n",
            "0.4524957455244321\n",
            "39397\n",
            "0.45251018072468185\n",
            "39398\n",
            "0.4525237578860646\n",
            "39399\n",
            "0.45253819308631427\n",
            "39400\n",
            "0.45255050629414767\n",
            "39401\n",
            "0.45255050629414767\n",
            "39402\n",
            "0.45256232924655543\n",
            "39403\n",
            "0.45258039747540696\n",
            "39404\n",
            "0.45259412636046487\n",
            "39405\n",
            "0.45259412636046487\n",
            "39406\n",
            "0.45260755982795936\n",
            "39407\n",
            "0.45262655761987985\n",
            "39408\n",
            "0.45263999108737435\n",
            "39409\n",
            "0.4526553623283222\n",
            "39410\n",
            "0.4526720825079646\n",
            "39411\n",
            "0.45268453539644765\n",
            "39412\n",
            "0.45268453539644765\n",
            "39413\n",
            "0.4526968942941489\n",
            "39414\n",
            "0.452708250061194\n",
            "39415\n",
            "0.45272007301360173\n",
            "39416\n",
            "0.45272967351648474\n",
            "39417\n",
            "0.45272967351648474\n",
            "39418\n",
            "0.45274373345560837\n",
            "39419\n",
            "0.4527574623406663\n",
            "39420\n",
            "0.45276875849532683\n",
            "39421\n",
            "0.4527836250709219\n",
            "39422\n",
            "0.45279516964115246\n",
            "39423\n",
            "0.4528078742303152\n",
            "39424\n",
            "0.45282057881947796\n",
            "39425\n",
            "0.45283350444088905\n",
            "39426\n",
            "0.45284371166887344\n",
            "39427\n",
            "0.45285663729028447\n",
            "39428\n",
            "0.45287563508220496\n",
            "39429\n",
            "0.452890278036569\n",
            "39430\n",
            "0.45290028304107427\n",
            "39431\n",
            "0.4529143429801979\n",
            "39432\n",
            "0.4529277764476924\n",
            "39433\n",
            "0.4529437516228161\n",
            "39434\n",
            "0.45295414417558955\n",
            "39435\n",
            "0.45296767258515686\n",
            "39436\n",
            "0.45296767258515686\n",
            "39437\n",
            "0.45298364776028055\n",
            "39438\n",
            "0.45299708122777504\n",
            "39439\n",
            "0.4530115164280248\n",
            "39440\n",
            "0.45302540591214324\n",
            "39441\n",
            "0.4530384495880114\n",
            "39442\n",
            "0.45305368656945527\n",
            "39443\n",
            "0.45306934524773\n",
            "39444\n",
            "0.45308445363555566\n",
            "39445\n",
            "0.45309888883580535\n",
            "39446\n",
            "0.45311007029383865\n",
            "39447\n",
            "0.4531227748830014\n",
            "39448\n",
            "0.45313721008325114\n",
            "39449\n",
            "0.45313721008325114\n",
            "39450\n",
            "0.4531508994085214\n",
            "39451\n",
            "0.45316761958816376\n",
            "39452\n",
            "0.4531783937610675\n",
            "39453\n",
            "0.4531934193600906\n",
            "39454\n",
            "0.4532093945352143\n",
            "39455\n",
            "0.45322382973546405\n",
            "39456\n",
            "0.45323755862052195\n",
            "39457\n",
            "0.4532529298614698\n",
            "39458\n",
            "0.45326736506171955\n",
            "39459\n",
            "0.45328000003407515\n",
            "39460\n",
            "0.4532925012842001\n",
            "39461\n",
            "0.45330520587336287\n",
            "39462\n",
            "0.45330520587336287\n",
            "39463\n",
            "0.4533186393408574\n",
            "39464\n",
            "0.45333031895826237\n",
            "39465\n",
            "0.45334375242575686\n",
            "39466\n",
            "0.45335472080603617\n",
            "39467\n",
            "0.45336654375844393\n",
            "39468\n",
            "0.45338118671280797\n",
            "39469\n",
            "0.45339476387419064\n",
            "39470\n",
            "0.45340573225446995\n",
            "39471\n",
            "0.4534220587422619\n",
            "39472\n",
            "0.4534369253178569\n",
            "39473\n",
            "0.4534546047553303\n",
            "39474\n",
            "0.45346947133092536\n",
            "39475\n",
            "0.45348043971120466\n",
            "39476\n",
            "0.4535014642240373\n",
            "39477\n",
            "0.4535014642240373\n",
            "39478\n",
            "0.4535140906274002\n",
            "39479\n",
            "0.4535140906274002\n",
            "39480\n",
            "0.4535308108070426\n",
            "39481\n",
            "0.4535467859821663\n",
            "39482\n",
            "0.45356036314354903\n",
            "39483\n",
            "0.45356036314354903\n",
            "39484\n",
            "0.4535757343844969\n",
            "39485\n",
            "0.4535871513708329\n",
            "39486\n",
            "0.4535871513708329\n",
            "39487\n",
            "0.45360121130995656\n",
            "39488\n",
            "0.4536188907474299\n",
            "39489\n",
            "0.4536346514420328\n",
            "39490\n",
            "0.4536487113811564\n",
            "39491\n",
            "0.4536608498892999\n",
            "39492\n",
            "0.4536768250644236\n",
            "39493\n",
            "0.45369466597470565\n",
            "39494\n",
            "0.45370992934063176\n",
            "39495\n",
            "0.4537230966670606\n",
            "39496\n",
            "0.4537375318673103\n",
            "39497\n",
            "0.4537481278933483\n",
            "39498\n",
            "0.45376484807299067\n",
            "39499\n",
            "0.45377971464858574\n",
            "39500\n",
            "0.4537941498488355\n",
            "39501\n",
            "0.4538085850490852\n",
            "39502\n",
            "0.45382530522872755\n",
            "39503\n",
            "0.45382530522872755\n",
            "39504\n",
            "0.45384033082775066\n",
            "39505\n",
            "0.45385543921557625\n",
            "39506\n",
            "0.45385543921557625\n",
            "39507\n",
            "0.4538700821699403\n",
            "39508\n",
            "0.4538812636279736\n",
            "39509\n",
            "0.45389827470241395\n",
            "39510\n",
            "0.45391261136311456\n",
            "39511\n",
            "0.45393160915503505\n",
            "39512\n",
            "0.4539464757306301\n",
            "39513\n",
            "0.4539587889384635\n",
            "39514\n",
            "0.45397365551405855\n",
            "39515\n",
            "0.4539877154531822\n",
            "39516\n",
            "0.45400443563282455\n",
            "39517\n",
            "0.45401816451788246\n",
            "39518\n",
            "0.4540335357588303\n",
            "39519\n",
            "0.45404759569795394\n",
            "39520\n",
            "0.4540629669389018\n",
            "39521\n",
            "0.4540766958239597\n",
            "39522\n",
            "0.4540766958239597\n",
            "39523\n",
            "0.4540766958239597\n",
            "39524\n",
            "0.45409075576308333\n",
            "39525\n",
            "0.4541040088746768\n",
            "39526\n",
            "0.4541040088746768\n",
            "39527\n",
            "0.45411831342619335\n",
            "39528\n",
            "0.45413174689368785\n",
            "39529\n",
            "0.4541471181346357\n",
            "39530\n",
            "0.45415982272379846\n",
            "39531\n",
            "0.45417179826198834\n",
            "39532\n",
            "0.4541856877461068\n",
            "39533\n",
            "0.45420201423389867\n",
            "39534\n",
            "0.45421544770139316\n",
            "39535\n",
            "0.45421544770139316\n",
            "39536\n",
            "0.45422950764051684\n",
            "39537\n",
            "0.4542420088906418\n",
            "39538\n",
            "0.4542420088906418\n",
            "39539\n",
            "0.45425368850804676\n",
            "39540\n",
            "0.45426855508364183\n",
            "39541\n",
            "0.45428261502276546\n",
            "39542\n",
            "0.4542966749618891\n",
            "39543\n",
            "0.45431091635711046\n",
            "39544\n",
            "0.4543214286135268\n",
            "39545\n",
            "0.4543351574985847\n",
            "39546\n",
            "0.4543505287395326\n",
            "39547\n",
            "0.4543649639397823\n",
            "39548\n",
            "0.45437788956119335\n",
            "39549\n",
            "0.4543913230286879\n",
            "39550\n",
            "0.45440449035511676\n",
            "39551\n",
            "0.4544168035629501\n",
            "39552\n",
            "0.45443240561175985\n",
            "39553\n",
            "0.4544468408120096\n",
            "39554\n",
            "0.45446583860393003\n",
            "39555\n",
            "0.45446583860393003\n",
            "39556\n",
            "0.4544821650917219\n",
            "39557\n",
            "0.4545004446808235\n",
            "39558\n",
            "0.45451487988107325\n",
            "39559\n",
            "0.4545302511220211\n",
            "39560\n",
            "0.45454496674836564\n",
            "39561\n",
            "0.4545580104242338\n",
            "39562\n",
            "0.4545778941808286\n",
            "39563\n",
            "0.4545908198022397\n",
            "39564\n",
            "0.4546098175941602\n",
            "39565\n",
            "0.4546231425832296\n",
            "39566\n",
            "0.4546360682046407\n",
            "39567\n",
            "0.4546360682046407\n",
            "39568\n",
            "0.4546509347802357\n",
            "39569\n",
            "0.4546509347802357\n",
            "39570\n",
            "0.4546658013558308\n",
            "39571\n",
            "0.4546834807933042\n",
            "39572\n",
            "0.4546972096783621\n",
            "39573\n",
            "0.4547108219352005\n",
            "39574\n",
            "0.4547248818743242\n",
            "39575\n",
            "0.4547408570494479\n",
            "39576\n",
            "0.4547545859345058\n",
            "39577\n",
            "0.45477159700894615\n",
            "39578\n",
            "0.45478452263035724\n",
            "39579\n",
            "0.45478452263035724\n",
            "39580\n",
            "0.45479692807840283\n",
            "39581\n",
            "0.4548120364662284\n",
            "39582\n",
            "0.4548260964053521\n",
            "39583\n",
            "0.4548260964053521\n",
            "39584\n",
            "0.4548385976554771\n",
            "39585\n",
            "0.4548385976554771\n",
            "39586\n",
            "0.454852326540535\n",
            "39587\n",
            "0.4548667617407847\n",
            "39588\n",
            "0.4548806512249032\n",
            "39589\n",
            "0.4548920682112392\n",
            "39590\n",
            "0.4549070532549694\n",
            "39591\n",
            "0.45491733262332873\n",
            "39592\n",
            "0.4549329913016035\n",
            "39593\n",
            "0.454944741493926\n",
            "39594\n",
            "0.45495817496142055\n",
            "39595\n",
            "0.4549704881692539\n",
            "39596\n",
            "0.45498216778665884\n",
            "39597\n",
            "0.4549966029869086\n",
            "39598\n",
            "0.45500891619474193\n",
            "39599\n",
            "0.45502272421209705\n",
            "39600\n",
            "0.45504040364957044\n",
            "39601\n",
            "0.4550557748905183\n",
            "39602\n",
            "0.455067597842926\n",
            "39603\n",
            "0.455080099093051\n",
            "39604\n",
            "0.4550939885771695\n",
            "39605\n",
            "0.45510669316633223\n",
            "39606\n",
            "0.4551198604927611\n",
            "39607\n",
            "0.45513154011016604\n",
            "39608\n",
            "0.45513154011016604\n",
            "39609\n",
            "0.4551467336190373\n",
            "39610\n",
            "0.4551601670865318\n",
            "39611\n",
            "0.45517287167569453\n",
            "39612\n",
            "0.4551905511131679\n",
            "39613\n",
            "0.4551905511131679\n",
            "39614\n",
            "0.45520823055064125\n",
            "39615\n",
            "0.45520823055064125\n",
            "39616\n",
            "0.4552219594356992\n",
            "39617\n",
            "0.45523626398721573\n",
            "39618\n",
            "0.45523626398721573\n",
            "39619\n",
            "0.4552505053824371\n",
            "39620\n",
            "0.45526456532156073\n",
            "39621\n",
            "0.45526456532156073\n",
            "39622\n",
            "0.45527706657168576\n",
            "39623\n",
            "0.45527706657168576\n",
            "39624\n",
            "0.4552885464639083\n",
            "39625\n",
            "0.45530260640303194\n",
            "39626\n",
            "0.45531977284587544\n",
            "39627\n",
            "0.45533320631336993\n",
            "39628\n",
            "0.455348072888965\n",
            "39629\n",
            "0.4553631812767906\n",
            "39630\n",
            "0.4553766147442851\n",
            "39631\n",
            "0.45538859028247497\n",
            "39632\n",
            "0.4554036550042091\n",
            "39633\n",
            "0.45541963017933285\n",
            "39634\n",
            "0.4554338097883025\n",
            "39635\n",
            "0.4554486763638976\n",
            "39636\n",
            "0.4554579648217429\n",
            "39637\n",
            "0.4554739399968666\n",
            "39638\n",
            "0.45548453602290456\n",
            "39639\n",
            "0.45549977300434846\n",
            "39640\n",
            "0.45551549249416845\n",
            "39641\n",
            "0.45552892596166294\n",
            "39642\n",
            "0.4555407001585893\n",
            "39643\n",
            "0.45555476009771295\n",
            "39644\n",
            "0.45556716649907547\n",
            "39645\n",
            "0.4555836190694944\n",
            "39646\n",
            "0.4555973479545523\n",
            "39647\n",
            "0.4555973479545523\n",
            "39648\n",
            "0.4555973479545523\n",
            "39649\n",
            "0.4555973479545523\n",
            "39650\n",
            "0.4556096611623857\n",
            "39651\n",
            "0.45562154831417984\n",
            "39652\n",
            "0.45562154831417984\n",
            "39653\n",
            "0.4556369195551277\n",
            "39654\n",
            "0.4556513547553774\n",
            "39655\n",
            "0.4556638560055024\n",
            "39656\n",
            "0.4556638560055024\n",
            "39657\n",
            "0.4556638560055024\n",
            "39658\n",
            "0.4556638560055024\n",
            "39659\n",
            "0.4556756205711758\n",
            "39660\n",
            "0.4556878741491318\n",
            "39661\n",
            "0.4556878741491318\n",
            "39662\n",
            "0.4557016030341897\n",
            "39663\n",
            "0.4557169742751376\n",
            "39664\n",
            "0.4557314094753873\n",
            "39665\n",
            "0.4557314094753873\n",
            "39666\n",
            "0.4557496890644889\n",
            "39667\n",
            "0.45576868685640937\n",
            "39668\n",
            "0.45576868685640937\n",
            "39669\n",
            "0.45578355343200444\n",
            "39670\n",
            "0.45579952860712813\n",
            "39671\n",
            "0.4558134180912466\n",
            "39672\n",
            "0.4558134180912466\n",
            "39673\n",
            "0.4558134180912466\n",
            "39674\n",
            "0.4558134180912466\n",
            "39675\n",
            "0.4558298706616655\n",
            "39676\n",
            "0.4558418461998554\n",
            "39677\n",
            "0.4558418461998554\n",
            "39678\n",
            "0.4558555750849133\n",
            "39679\n",
            "0.45586963502403693\n",
            "39680\n",
            "0.4558830684915315\n",
            "39681\n",
            "0.4558944854778675\n",
            "39682\n",
            "0.45590654112445733\n",
            "39683\n",
            "0.45590654112445733\n",
            "39684\n",
            "0.45592043060857573\n",
            "39685\n",
            "0.4559360892868505\n",
            "39686\n",
            "0.4559501492259741\n",
            "39687\n",
            "0.4559643288349438\n",
            "39688\n",
            "0.45597600845234876\n",
            "39689\n",
            "0.4559878314047565\n",
            "39690\n",
            "0.4560049978476\n",
            "39691\n",
            "0.4560201062354256\n",
            "39692\n",
            "0.4560201062354256\n",
            "39693\n",
            "0.4560351318344487\n",
            "39694\n",
            "0.45605185201409104\n",
            "39695\n",
            "0.4560650193405199\n",
            "39696\n",
            "0.4560814719109389\n",
            "39697\n",
            "0.4560991513484122\n",
            "39698\n",
            "0.4561161624228526\n",
            "39699\n",
            "0.45612813796104246\n",
            "39700\n",
            "0.4561437966393172\n",
            "39701\n",
            "0.4561567222607283\n",
            "39702\n",
            "0.45616944421974265\n",
            "39703\n",
            "0.45616944421974265\n",
            "39704\n",
            "0.45616944421974265\n",
            "39705\n",
            "0.4561803624001678\n",
            "39706\n",
            "0.4561970825798102\n",
            "39707\n",
            "0.4561970825798102\n",
            "39708\n",
            "0.4562095838299352\n",
            "39709\n",
            "0.45622364376905883\n",
            "39710\n",
            "0.45622364376905883\n",
            "39711\n",
            "0.4562354667214666\n",
            "39712\n",
            "0.4562489894152607\n",
            "39713\n",
            "0.45626169400442346\n",
            "39714\n",
            "0.4562761292046732\n",
            "39715\n",
            "0.45629227526159105\n",
            "39716\n",
            "0.4563063352007147\n",
            "39717\n",
            "0.45632090724280433\n",
            "39718\n",
            "0.4563343407102988\n",
            "39719\n",
            "0.4563456368649594\n",
            "39720\n",
            "0.45636264793939973\n",
            "39721\n",
            "0.4563780191803476\n",
            "39722\n",
            "0.4563780191803476\n",
            "39723\n",
            "0.45639185408783456\n",
            "39724\n",
            "0.4564055829728925\n",
            "39725\n",
            "0.45642326241036585\n",
            "39726\n",
            "0.45643360568331925\n",
            "39727\n",
            "0.4564500582537382\n",
            "39728\n",
            "0.45646481090081886\n",
            "39729\n",
            "0.45646481090081886\n",
            "39730\n",
            "0.4564807860759426\n",
            "39731\n",
            "0.4564938703236098\n",
            "39732\n",
            "0.45650703765003864\n",
            "39733\n",
            "0.45650703765003864\n",
            "39734\n",
            "0.4565260354419591\n",
            "39735\n",
            "0.4565425924783903\n",
            "39736\n",
            "0.4565555180998013\n",
            "39737\n",
            "0.4565689515672959\n",
            "39738\n",
            "0.4565828410514143\n",
            "39739\n",
            "0.45659627451890883\n",
            "39740\n",
            "0.45659627451890883\n",
            "39741\n",
            "0.45660944184533764\n",
            "39742\n",
            "0.4566223674667487\n",
            "39743\n",
            "0.45663642740587235\n",
            "39744\n",
            "0.456650487344996\n",
            "39745\n",
            "0.4566650038735353\n",
            "39746\n",
            "0.4566788933576537\n",
            "39747\n",
            "0.4566919370335219\n",
            "39748\n",
            "0.4567052341029712\n",
            "39749\n",
            "0.45671665108930726\n",
            "39750\n",
            "0.45672935567847\n",
            "39751\n",
            "0.4567456821662619\n",
            "39752\n",
            "0.45675872584213006\n",
            "39753\n",
            "0.4567723030035128\n",
            "39754\n",
            "0.45679130079543323\n",
            "39755\n",
            "0.45679130079543323\n",
            "39756\n",
            "0.4568027806876558\n",
            "39757\n",
            "0.4568027806876558\n",
            "39758\n",
            "0.4568178890754814\n",
            "39759\n",
            "0.4568178890754814\n",
            "39760\n",
            "0.4568178890754814\n",
            "39761\n",
            "0.45682986461367125\n",
            "39762\n",
            "0.45684392455279493\n",
            "39763\n",
            "0.45684392455279493\n",
            "39764\n",
            "0.4568601296456406\n",
            "39765\n",
            "0.4568726308957656\n",
            "39766\n",
            "0.4568846865423554\n",
            "39767\n",
            "0.45689955311795044\n",
            "39768\n",
            "0.45691817452956635\n",
            "39769\n",
            "0.45691817452956635\n",
            "39770\n",
            "0.45693190341462425\n",
            "39771\n",
            "0.456941592848131\n",
            "39772\n",
            "0.45695502631562557\n",
            "39773\n",
            "0.45695502631562557\n",
            "39774\n",
            "0.45697013470345116\n",
            "39775\n",
            "0.45698325441036586\n",
            "39776\n",
            "0.4569956598584115\n",
            "39777\n",
            "0.4570119863462034\n",
            "39778\n",
            "0.45702629089771996\n",
            "39779\n",
            "0.45703826643590983\n",
            "39780\n",
            "0.45705232637503346\n",
            "39781\n",
            "0.45706280603491345\n",
            "39782\n",
            "0.45707331829132974\n",
            "39783\n",
            "0.45707331829132974\n",
            "39784\n",
            "0.45709434280416245\n",
            "39785\n",
            "0.45710877800441213\n",
            "39786\n",
            "0.45712414924536\n",
            "39787\n",
            "0.45712414924536\n",
            "39788\n",
            "0.45713597219776775\n",
            "39789\n",
            "0.45714828540560115\n",
            "39790\n",
            "0.45714828540560115\n",
            "39791\n",
            "0.4571607866557261\n",
            "39792\n",
            "0.457172762193916\n",
            "39793\n",
            "0.45718813343486386\n",
            "39794\n",
            "0.4572035046758117\n",
            "39795\n",
            "0.4572183712514068\n",
            "39796\n",
            "0.45723128843613636\n",
            "39797\n",
            "0.45724726361126006\n",
            "39798\n",
            "0.45726018923267114\n",
            "39799\n",
            "0.4572720121850789\n",
            "39800\n",
            "0.45728493780649\n",
            "39801\n",
            "0.45728493780649\n",
            "39802\n",
            "0.45730030904743785\n",
            "39803\n",
            "0.45731347637386666\n",
            "39804\n",
            "0.4573272052589246\n",
            "39805\n",
            "0.4573406387264191\n",
            "39806\n",
            "0.4573566139015428\n",
            "39807\n",
            "0.4573703427866007\n",
            "39808\n",
            "0.4573703427866007\n",
            "39809\n",
            "0.45738498574096476\n",
            "39810\n",
            "0.4573981530673936\n",
            "39811\n",
            "0.4574135243083415\n",
            "39812\n",
            "0.45742889554928934\n",
            "39813\n",
            "0.45742889554928934\n",
            "39814\n",
            "0.45742889554928934\n",
            "39815\n",
            "0.45742889554928934\n",
            "39816\n",
            "0.4574425223537721\n",
            "39817\n",
            "0.4574569575540218\n",
            "39818\n",
            "0.4574683133210669\n",
            "39819\n",
            "0.4574803689676567\n",
            "39820\n",
            "0.4574803689676567\n",
            "39821\n",
            "0.4574803689676567\n",
            "39822\n",
            "0.4574803689676567\n",
            "39823\n",
            "0.45749178595399276\n",
            "39824\n",
            "0.45750946539146614\n",
            "39825\n",
            "0.45752258509838084\n",
            "39826\n",
            "0.45752258509838084\n",
            "39827\n",
            "0.4575387901912265\n",
            "39828\n",
            "0.4575525190762844\n",
            "39829\n",
            "0.4575525190762844\n",
            "39830\n",
            "0.4575525190762844\n",
            "39831\n",
            "0.4575525190762844\n",
            "39832\n",
            "0.4575627263042688\n",
            "39833\n",
            "0.4575775928798638\n",
            "39834\n",
            "0.4575935680549876\n",
            "39835\n",
            "0.45760724935220626\n",
            "39836\n",
            "0.45761960873894375\n",
            "39837\n",
            "0.45763304220643825\n",
            "39838\n",
            "0.45764849288796916\n",
            "39839\n",
            "0.45766677247707077\n",
            "39840\n",
            "0.4576803008866381\n",
            "39841\n",
            "0.4576803008866381\n",
            "39842\n",
            "0.45769346821306695\n",
            "39843\n",
            "0.4577059694631919\n",
            "39844\n",
            "0.4577192225747854\n",
            "39845\n",
            "0.4577192225747854\n",
            "39846\n",
            "0.45773295145984333\n",
            "39847\n",
            "0.45774652862122606\n",
            "39848\n",
            "0.4577592332103888\n",
            "39849\n",
            "0.4577773014392403\n",
            "39850\n",
            "0.45779103032429824\n",
            "39851\n",
            "0.45779103032429824\n",
            "39852\n",
            "0.4578064015652461\n",
            "39853\n",
            "0.45782000840366127\n",
            "39854\n",
            "0.45782000840366127\n",
            "39855\n",
            "0.45783465135802537\n",
            "39856\n",
            "0.457848711297149\n",
            "39857\n",
            "0.45786699088625055\n",
            "39858\n",
            "0.4578818574618456\n",
            "39859\n",
            "0.457898577641488\n",
            "39860\n",
            "0.45791128223065075\n",
            "39861\n",
            "0.45792501111570866\n",
            "39862\n",
            "0.4579405709961289\n",
            "39863\n",
            "0.45795070854612985\n",
            "39864\n",
            "0.45795070854612985\n",
            "39865\n",
            "0.4579630217539632\n",
            "39866\n",
            "0.4579755230040882\n",
            "39867\n",
            "0.4579918494918801\n",
            "39868\n",
            "0.4580059094310037\n",
            "39869\n",
            "0.4580202460917044\n",
            "39870\n",
            "0.458034306030828\n",
            "39871\n",
            "0.4580477394983225\n",
            "39872\n",
            "0.45806082374598966\n",
            "39873\n",
            "0.45807150698947396\n",
            "39874\n",
            "0.4580832571817965\n",
            "39875\n",
            "0.4580981237573915\n",
            "39876\n",
            "0.4581127667117556\n",
            "39877\n",
            "0.4581127667117556\n",
            "39878\n",
            "0.4581243443139982\n",
            "39879\n",
            "0.4581243443139982\n",
            "39880\n",
            "0.4581390969610789\n",
            "39881\n",
            "0.4581539635366739\n",
            "39882\n",
            "0.4581706837163163\n",
            "39883\n",
            "0.4581706837163163\n",
            "39884\n",
            "0.4581844126013742\n",
            "39885\n",
            "0.45820038777649796\n",
            "39886\n",
            "0.4582157590174458\n",
            "39887\n",
            "0.4582279833154365\n",
            "39888\n",
            "0.4582409089368476\n",
            "39889\n",
            "0.45825383455825863\n",
            "39890\n",
            "0.45827233847876303\n",
            "39891\n",
            "0.45829001791623636\n",
            "39892\n",
            "0.45830162902853205\n",
            "39893\n",
            "0.4583160642287818\n",
            "39894\n",
            "0.4583160642287818\n",
            "39895\n",
            "0.45832964139016447\n",
            "39896\n",
            "0.45834293845961377\n",
            "39897\n",
            "0.45834293845961377\n",
            "39898\n",
            "0.4583612180487154\n",
            "39899\n",
            "0.45837229040630784\n",
            "39900\n",
            "0.45838370739264384\n",
            "39901\n",
            "0.45839728455402656\n",
            "39902\n",
            "0.45841215112962164\n",
            "39903\n",
            "0.4584248557187844\n",
            "39904\n",
            "0.4584248557187844\n",
            "39905\n",
            "0.458438915657908\n",
            "39906\n",
            "0.4584536683049887\n",
            "39907\n",
            "0.4584696434801124\n",
            "39908\n",
            "0.4584811022111533\n",
            "39909\n",
            "0.4584811022111533\n",
            "39910\n",
            "0.4584949916952717\n",
            "39911\n",
            "0.45850842516276624\n",
            "39912\n",
            "0.45852440033788994\n",
            "39913\n",
            "0.4585397715788378\n",
            "39914\n",
            "0.4585506406875473\n",
            "39915\n",
            "0.4585655072631423\n",
            "39916\n",
            "0.45857923614820023\n",
            "39917\n",
            "0.45859296503325814\n",
            "39918\n",
            "0.45861013147610163\n",
            "39919\n",
            "0.4586244360276182\n",
            "39920\n",
            "0.45864160247046165\n",
            "39921\n",
            "0.4586532820878666\n",
            "39922\n",
            "0.45866717157198506\n",
            "39923\n",
            "0.45868060503947955\n",
            "39924\n",
            "0.45868060503947955\n",
            "39925\n",
            "0.45869433392453746\n",
            "39926\n",
            "0.45869433392453746\n",
            "39927\n",
            "0.45870608411686\n",
            "39928\n",
            "0.45871878870602273\n",
            "39929\n",
            "0.4587341599469706\n",
            "39930\n",
            "0.45874840134219197\n",
            "39931\n",
            "0.45874840134219197\n",
            "39932\n",
            "0.4587624612813156\n",
            "39933\n",
            "0.4587775903254923\n",
            "39934\n",
            "0.45879091531456173\n",
            "39935\n",
            "0.45880464419961964\n",
            "39936\n",
            "0.45881519792530817\n",
            "39937\n",
            "0.4588309586199111\n",
            "39938\n",
            "0.45884400229577926\n",
            "39939\n",
            "0.4588555136003262\n",
            "39940\n",
            "0.4588555136003262\n",
            "39941\n",
            "0.4588670581705568\n",
            "39942\n",
            "0.45888192474615186\n",
            "39943\n",
            "0.4588963599464016\n",
            "39944\n",
            "0.4588963599464016\n",
            "39945\n",
            "0.4589126864341935\n",
            "39946\n",
            "0.45892611990168797\n",
            "39947\n",
            "0.4589365254208656\n",
            "39948\n",
            "0.4589513919964607\n",
            "39949\n",
            "0.4589643176178717\n",
            "39950\n",
            "0.4589754712956704\n",
            "39951\n",
            "0.4589921914753128\n",
            "39952\n",
            "0.45900891165495517\n",
            "39953\n",
            "0.45902264054001307\n",
            "39954\n",
            "0.45903580786644194\n",
            "39955\n",
            "0.4590527438349668\n",
            "39956\n",
            "0.45906524508509183\n",
            "39957\n",
            "0.459079190239601\n",
            "39958\n",
            "0.4590948489178757\n",
            "39959\n",
            "0.45910640005641445\n",
            "39960\n",
            "0.45910640005641445\n",
            "39961\n",
            "0.45911848300928704\n",
            "39962\n",
            "0.45913165033571585\n",
            "39963\n",
            "0.45914499210182713\n",
            "39964\n",
            "0.4591576966909899\n",
            "39965\n",
            "0.4591766944829103\n",
            "39966\n",
            "0.4591898618093392\n",
            "39967\n",
            "0.45920472838493426\n",
            "39968\n",
            "0.4592200996258821\n",
            "39969\n",
            "0.4592316441961127\n",
            "39970\n",
            "0.45924809676653167\n",
            "39971\n",
            "0.45926481694617405\n",
            "39972\n",
            "0.4592794599005381\n",
            "39973\n",
            "0.4592954350756618\n",
            "39974\n",
            "0.4592954350756618\n",
            "39975\n",
            "0.45930741061385166\n",
            "39976\n",
            "0.4593214705529753\n",
            "39977\n",
            "0.45933254291056774\n",
            "39978\n",
            "0.45934750388186074\n",
            "39979\n",
            "0.45935668494064136\n",
            "39980\n",
            "0.45937436437811474\n",
            "39981\n",
            "0.45938779784560924\n",
            "39982\n",
            "0.4594026644212043\n",
            "39983\n",
            "0.4594158317476332\n",
            "39984\n",
            "0.45942618587996054\n",
            "39985\n",
            "0.45944226716363445\n",
            "39986\n",
            "0.45944226716363445\n",
            "39987\n",
            "0.45945413989799544\n",
            "39988\n",
            "0.45946691606514034\n",
            "39989\n",
            "0.4594815162658967\n",
            "39990\n",
            "0.45949688750684453\n",
            "39991\n",
            "0.4595113227070942\n",
            "39992\n",
            "0.45952382395721925\n",
            "39993\n",
            "0.45953755284227715\n",
            "39994\n",
            "0.45954909741250777\n",
            "39995\n",
            "0.4595644686534556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUmr2rZBf5xE"
      },
      "source": [
        "#Bleu Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN60tVBAiMJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4415b7c-e43c-4a39-ab03-0ca51f14181f"
      },
      "source": [
        "print(f'BLEU score = {(total_score/data_length)*100}')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score = 45.95644686534556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4_EKSAiiNrw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aaeb7f0b-460d-48fa-92db-e8f55bab8d4e"
      },
      "source": [
        "translate(model, 'من تۆم خۆشدەوێت' , custom_sentence=True)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<sos> i love you and i love you ,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T-Gx6ADf5zO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7768653d-d6b9-40c1-9153-ddf5598b1e12"
      },
      "source": [
        "translate(model, 'من بۆ بازاڕ دەچم' , custom_sentence=True)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<sos> i 'm going to go to the marketing game ,\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mDIsK3jgD8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e912f253-bb37-4726-de46-a893729975a8"
      },
      "source": [
        "translate(model, 'ڕۆژێک لە ڕۆژان، نەخۆشیەکی ترسناک بوو بە هەڕەشە' , custom_sentence=True)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<sos> once upon one time , there was a dread disease'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gNe8huXgS_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bcdc6e5d-d068-4bba-9332-88e76b04e580"
      },
      "source": [
        "translate(model, 'دوێنێ ئەمریکا رایگەیاند، ئێران نایەوێت تۆمەتی خەمساردی لەدانوستانەکانی ڤیەننا بخاتە سەر شانی خۆی و رەتیشیکردەوە هیچ رێککەوتنێکیان لەبارەی ئاڵوگۆڕی زیندانیان کردبێت' , custom_sentence=True)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<sos> the us ( associate - gods ever , iran was seen by iran and worked no keep back on the with no leaves of the become such as had any complete .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnj0BG0Fgdmi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4ed392d-ed24-4e37-9dc1-fccfa93dff9d"
      },
      "source": [
        "translate(model, 'ئێوە لە کوێ بوون دوێنێ' , custom_sentence=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<sos> where you were , like , yesterday ,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdDbA12AgqmV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a6c4f11-7524-45e1-bc28-fac8f3f92fa7"
      },
      "source": [
        "translate(model, 'ئەوان دەڕۆن بۆ بازاڕ' , custom_sentence=True)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<sos> they go in markets all market products'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSDxl8gkROuI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2903deee-bd60-4e9c-9708-fc64f242621c"
      },
      "source": [
        "translate(model, 'ناتوانم بچم بۆ ماڵی مامم' , custom_sentence=True)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<sos> i ca n't go to my paternal house\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgcbKA3RRX7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "326423e5-1997-4ee3-d499-4f7e30e39488"
      },
      "source": [
        "translate(model,'ئێوە هەمیشە لە دڵخۆشیدا بژین' , custom_sentence=True)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<sos> you are always happiness .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLAuiMuARo3y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}